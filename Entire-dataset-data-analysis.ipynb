{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis for entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libaries\n",
    "%matplotlib inline\n",
    "import numpy as np              \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_info=pd.read_csv('corpus-files\\student_information.csv')\n",
    "course=pd.read_csv('corpus-files\\course.csv')\n",
    "answer_df=pd.read_csv('answer.csv',index_col = 'answer_id', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "course_=course.drop(columns=['class_id','semester','section'])\n",
    "\n",
    "student=student_info.drop(columns=['birth_year','language_used_at_home','non_native_language_1','yrs_of_study_lang1',\n",
    "                                  'study_in_classroom_lang1','ways_of_study_lang1','non_native_language_2','study_in_classroom_lang2',\n",
    "                                  'ways_of_study_lang2','non_native_language_3','yrs_of_study_lang3','study_in_classroom_lang3',\n",
    "                                  'ways_of_study_lang3','yrs_of_english_learning','yrs_in_english_environment','yrs_of_study_lang2'])\n",
    "answer_=answer_df[['question_id','anon_id','course_id','version','text_len','text','tokens']].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function removes all of the rows that contain a string in the passed column\n",
    "def rmStr (df, col):\n",
    "    row_index=0\n",
    "    row_ind=[]\n",
    "    for i in df[col]:\n",
    "        try:\n",
    "            int(i)\n",
    "        except:\n",
    "            row_ind.append(row_index)\n",
    "        row_index+=1\n",
    "    return df.drop(labels=row_ind,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleaning the answer df\n",
    "col='course_id'\n",
    "answer=rmStr(answer_, col) #removes strings from answer_.course_id "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary Search Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#binary search for strings\n",
    "def binarySearchArr(arr, x):\n",
    "    l = 0\n",
    "    r = len(arr)\n",
    "    while (l <= r):\n",
    "        m = l + ((r - l) // 2)\n",
    " \n",
    "        res = (x == arr[m])\n",
    "        # Check if x is present at mid\n",
    "        if (res == True):\n",
    "            return m\n",
    " \n",
    "        # If x greater, ignore left half\n",
    "    #problem is here\n",
    "        elif (res == False):\n",
    "            if (x>arr[m]):\n",
    "                l = m+1\n",
    "            elif (x<arr[m]):\n",
    "                r=m-1\n",
    "        # If x is smaller, ignore right half\n",
    "    return -1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that finds the unique values in a list\n",
    "def get_uniques(x):\n",
    "    return list(x.unique())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seperating anon_ids by language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a list of all the different languages\n",
    "langs=[]\n",
    "for i in student.native_language:\n",
    "    lang=i\n",
    "    if lang not in langs:\n",
    "        langs.append(lang)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This groups the anon_ids by their native language\n",
    "count=0\n",
    "lang_ids={}\n",
    "for y in langs:\n",
    "    count=0\n",
    "    ids=[]\n",
    "    key=y\n",
    "    for i in student.anon_id:\n",
    "        if (student.at[count, 'native_language'] == y):\n",
    "            val=i\n",
    "            ids.append(val)\n",
    "        count=count+1\n",
    "    lang_ids.update({key: ids})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Arabic', 'Nepali', 'Korean', 'Chinese', 'Russian', 'Turkish', 'French', 'Other', 'Japanese', 'Spanish', 'Thai', 'Portuguese', 'Taiwanese', 'English', 'Mongol', 'Italian', 'Vietnamese', 'Polish', 'German', 'Swedish', 'Hebrew', 'Farsi', 'Romanian', 'Indonesian', 'Suundi', 'Azerbaijani', 'Swahili', 'Hindi', 'Russian,Ukrainian', 'Montenegrin', 'Zulu']\n"
     ]
    }
   ],
   "source": [
    "print(langs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anon_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>native_language</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Arabic</th>\n",
       "      <td>465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Azerbaijani</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chinese</th>\n",
       "      <td>249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>English</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Farsi</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>French</th>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>German</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hebrew</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hindi</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Indonesian</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Italian</th>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Japanese</th>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Korean</th>\n",
       "      <td>245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mongol</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Montenegrin</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nepali</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Other</th>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Polish</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Portuguese</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Romanian</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Russian</th>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Russian,Ukrainian</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Spanish</th>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Suundi</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Swahili</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Swedish</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Taiwanese</th>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Thai</th>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Turkish</th>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vietnamese</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zulu</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   anon_id\n",
       "native_language           \n",
       "Arabic                 465\n",
       "Azerbaijani              2\n",
       "Chinese                249\n",
       "English                  2\n",
       "Farsi                    4\n",
       "French                  13\n",
       "German                   3\n",
       "Hebrew                   6\n",
       "Hindi                    1\n",
       "Indonesian               2\n",
       "Italian                 12\n",
       "Japanese                81\n",
       "Korean                 245\n",
       "Mongol                   3\n",
       "Montenegrin              1\n",
       "Nepali                   1\n",
       "Other                   23\n",
       "Polish                   2\n",
       "Portuguese              20\n",
       "Romanian                 1\n",
       "Russian                 12\n",
       "Russian,Ukrainian        1\n",
       "Spanish                 66\n",
       "Suundi                   1\n",
       "Swahili                  1\n",
       "Swedish                  1\n",
       "Taiwanese               12\n",
       "Thai                    31\n",
       "Turkish                 47\n",
       "Vietnamese               4\n",
       "Zulu                     1"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#shows how many particpants are in each language\n",
    "lang_counts=student.groupby('native_language').count().drop(columns=['gender','course_history','age'])\n",
    "lang_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lang_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merging the two datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_ans=answer[['anon_id','course_id']]\n",
    "student_merge=student.drop(columns=['course_history'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_ans=student_merge.merge(answer,on='anon_id').astype({'course_id':'int64'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "stu_ans_crs=student_ans.merge(course_, on='course_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anon_id</th>\n",
       "      <th>gender</th>\n",
       "      <th>native_language</th>\n",
       "      <th>age</th>\n",
       "      <th>answer_id</th>\n",
       "      <th>question_id</th>\n",
       "      <th>course_id</th>\n",
       "      <th>version</th>\n",
       "      <th>text_len</th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>level_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>do6</td>\n",
       "      <td>Female</td>\n",
       "      <td>Russian</td>\n",
       "      <td>31.0</td>\n",
       "      <td>150</td>\n",
       "      <td>4</td>\n",
       "      <td>117</td>\n",
       "      <td>1</td>\n",
       "      <td>299</td>\n",
       "      <td>Some people prefer eat out and some like doing...</td>\n",
       "      <td>['Some', 'people', 'prefer', 'eat', 'out', 'an...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>do6</td>\n",
       "      <td>Female</td>\n",
       "      <td>Russian</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1221</td>\n",
       "      <td>97</td>\n",
       "      <td>117</td>\n",
       "      <td>1</td>\n",
       "      <td>288</td>\n",
       "      <td>My opinion is that a person does need educatio...</td>\n",
       "      <td>['My', 'opinion', 'is', 'that', 'a', 'person',...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>do6</td>\n",
       "      <td>Female</td>\n",
       "      <td>Russian</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1957</td>\n",
       "      <td>189</td>\n",
       "      <td>117</td>\n",
       "      <td>1</td>\n",
       "      <td>321</td>\n",
       "      <td>There are two national rooms in the Cathedral ...</td>\n",
       "      <td>['There', 'are', 'two', 'national', 'rooms', '...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>do6</td>\n",
       "      <td>Female</td>\n",
       "      <td>Russian</td>\n",
       "      <td>31.0</td>\n",
       "      <td>2164</td>\n",
       "      <td>190</td>\n",
       "      <td>117</td>\n",
       "      <td>1</td>\n",
       "      <td>464</td>\n",
       "      <td>There are two nation rooms in the Cathedral of...</td>\n",
       "      <td>['There', 'are', 'two', 'nation', 'rooms', 'in...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bv5</td>\n",
       "      <td>Male</td>\n",
       "      <td>Arabic</td>\n",
       "      <td>21.0</td>\n",
       "      <td>151</td>\n",
       "      <td>4</td>\n",
       "      <td>117</td>\n",
       "      <td>1</td>\n",
       "      <td>315</td>\n",
       "      <td>\"Not all learning takes place in the classroom...</td>\n",
       "      <td>['``', 'Not', 'all', 'learning', 'takes', 'pla...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46225</th>\n",
       "      <td>cy7</td>\n",
       "      <td>Female</td>\n",
       "      <td>Korean</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47682</td>\n",
       "      <td>6066</td>\n",
       "      <td>1034</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1. emphasis\\n2. appropriate\\n3. requires\\n4. a...</td>\n",
       "      <td>['1', '.', 'emphasis', '2', '.', 'appropriate'...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46226</th>\n",
       "      <td>fp7</td>\n",
       "      <td>Female</td>\n",
       "      <td>Turkish</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47823</td>\n",
       "      <td>6066</td>\n",
       "      <td>1034</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1.emphasis \\n2.appropriate\\n3.requires\\n4.anal...</td>\n",
       "      <td>['1', '.', 'emphasis', '2', '.', 'appropriate'...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46227</th>\n",
       "      <td>fq6</td>\n",
       "      <td>Male</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47824</td>\n",
       "      <td>6066</td>\n",
       "      <td>1034</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1.emphasis\\n2.appropriate\\n3.requires\\n4.analy...</td>\n",
       "      <td>['1', '.', 'emphasis', '2', '.', 'appropriate'...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46228</th>\n",
       "      <td>di6</td>\n",
       "      <td>Male</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47787</td>\n",
       "      <td>6066</td>\n",
       "      <td>1034</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1 emphasis\\n2 normal\\n3 requires\\n4 analyze\\n5...</td>\n",
       "      <td>['1', 'emphasis', '2', 'normal', '3', 'require...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46229</th>\n",
       "      <td>fm3</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Arabic</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47725</td>\n",
       "      <td>6066</td>\n",
       "      <td>1034</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1- emphasis\\n2- appropriate\\n3- requires\\n4- a...</td>\n",
       "      <td>['1', '-', 'emphasis', '2', '-', 'appropriate'...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>46230 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      anon_id   gender native_language   age answer_id question_id  course_id  \\\n",
       "0         do6   Female         Russian  31.0       150           4        117   \n",
       "1         do6   Female         Russian  31.0      1221          97        117   \n",
       "2         do6   Female         Russian  31.0      1957         189        117   \n",
       "3         do6   Female         Russian  31.0      2164         190        117   \n",
       "4         bv5     Male          Arabic  21.0       151           4        117   \n",
       "...       ...      ...             ...   ...       ...         ...        ...   \n",
       "46225     cy7   Female          Korean   NaN     47682        6066       1034   \n",
       "46226     fp7   Female         Turkish   NaN     47823        6066       1034   \n",
       "46227     fq6     Male         Chinese   NaN     47824        6066       1034   \n",
       "46228     di6     Male         Chinese   NaN     47787        6066       1034   \n",
       "46229     fm3  Unknown          Arabic   NaN     47725        6066       1034   \n",
       "\n",
       "      version text_len                                               text  \\\n",
       "0           1      299  Some people prefer eat out and some like doing...   \n",
       "1           1      288  My opinion is that a person does need educatio...   \n",
       "2           1      321  There are two national rooms in the Cathedral ...   \n",
       "3           1      464  There are two nation rooms in the Cathedral of...   \n",
       "4           1      315  \"Not all learning takes place in the classroom...   \n",
       "...       ...      ...                                                ...   \n",
       "46225       1       10  1. emphasis\\n2. appropriate\\n3. requires\\n4. a...   \n",
       "46226       1       10  1.emphasis \\n2.appropriate\\n3.requires\\n4.anal...   \n",
       "46227       1       10  1.emphasis\\n2.appropriate\\n3.requires\\n4.analy...   \n",
       "46228       1       10  1 emphasis\\n2 normal\\n3 requires\\n4 analyze\\n5...   \n",
       "46229       1       10  1- emphasis\\n2- appropriate\\n3- requires\\n4- a...   \n",
       "\n",
       "                                                  tokens  level_id  \n",
       "0      ['Some', 'people', 'prefer', 'eat', 'out', 'an...         5  \n",
       "1      ['My', 'opinion', 'is', 'that', 'a', 'person',...         5  \n",
       "2      ['There', 'are', 'two', 'national', 'rooms', '...         5  \n",
       "3      ['There', 'are', 'two', 'nation', 'rooms', 'in...         5  \n",
       "4      ['``', 'Not', 'all', 'learning', 'takes', 'pla...         5  \n",
       "...                                                  ...       ...  \n",
       "46225  ['1', '.', 'emphasis', '2', '.', 'appropriate'...         3  \n",
       "46226  ['1', '.', 'emphasis', '2', '.', 'appropriate'...         3  \n",
       "46227  ['1', '.', 'emphasis', '2', '.', 'appropriate'...         3  \n",
       "46228  ['1', 'emphasis', '2', 'normal', '3', 'require...         3  \n",
       "46229  ['1', '-', 'emphasis', '2', '-', 'appropriate'...         3  \n",
       "\n",
       "[46230 rows x 12 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stu_ans_crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anon_id</th>\n",
       "      <th>native_language</th>\n",
       "      <th>level_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>do6</td>\n",
       "      <td>Russian</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>do6</td>\n",
       "      <td>Russian</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>do6</td>\n",
       "      <td>Russian</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>do6</td>\n",
       "      <td>Russian</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bv5</td>\n",
       "      <td>Arabic</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46225</th>\n",
       "      <td>cy7</td>\n",
       "      <td>Korean</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46226</th>\n",
       "      <td>fp7</td>\n",
       "      <td>Turkish</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46227</th>\n",
       "      <td>fq6</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46228</th>\n",
       "      <td>di6</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46229</th>\n",
       "      <td>fm3</td>\n",
       "      <td>Arabic</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>46230 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      anon_id native_language  level_id\n",
       "0         do6         Russian         5\n",
       "1         do6         Russian         5\n",
       "2         do6         Russian         5\n",
       "3         do6         Russian         5\n",
       "4         bv5          Arabic         5\n",
       "...       ...             ...       ...\n",
       "46225     cy7          Korean         3\n",
       "46226     fp7         Turkish         3\n",
       "46227     fq6         Chinese         3\n",
       "46228     di6         Chinese         3\n",
       "46229     fm3          Arabic         3\n",
       "\n",
       "[46230 rows x 3 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sac_lvls=stu_ans_crs[['anon_id','native_language','level_id']]\n",
    "sac_lvls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finiding who is in all three levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# allows us to see what levels each anon_id participated in \n",
    "lvl_list=sac_lvls.groupby('anon_id').agg(n_uniq=('level_id','nunique'), lvl_nums=('level_id',get_uniques))\n",
    "lvl_list=lvl_list.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "143"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# will create a list of only the ids that have levels 3, 4, and 5 in their lvl_nums column\n",
    "all_three=[]\n",
    "ind=0\n",
    "for i in lvl_list.anon_id:\n",
    "    if ((3 in lvl_list.iat[ind,2]) and (4 in lvl_list.iat[ind,2]) and (5 in lvl_list.iat[ind,2])):\n",
    "        append=lvl_list.at[ind, 'anon_id']\n",
    "        all_three.append(append)\n",
    "    ind+=1\n",
    "\n",
    "all_three.sort()\n",
    "len(all_three)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_anon=[]\n",
    "for i in sac_lvls.anon_id:\n",
    "    all_anon.append(i)\n",
    "len(all_anon)\n",
    "all_anon.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gets unique ids\n",
    "uanon=[]\n",
    "index=0\n",
    "for i in all_anon:\n",
    "    if all_anon[index] not in uanon:\n",
    "        uanon.append(all_anon[index])\n",
    "    index=index+1\n",
    "uanon.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      anon_id native_language  level_id\n",
      "0         aa0         Spanish         5\n",
      "1         aa0         Spanish         5\n",
      "2         aa0         Spanish         5\n",
      "3         aa0         Spanish         5\n",
      "4         aa0         Spanish         5\n",
      "...       ...             ...       ...\n",
      "46225     hc1          Korean         5\n",
      "46226     hc1          Korean         5\n",
      "46227     hc1          Korean         5\n",
      "46228     hc1          Korean         5\n",
      "46229     hc1          Korean         5\n",
      "\n",
      "[46230 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "sorted_sac=sac_lvls.sort_values(by=['anon_id']).reset_index(drop=True)\n",
    "print(sorted_sac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Japanese': ['ad8', 'am9', 'ay3', 'bs1', 'fw1', 'hb2'], 'Thai': ['af0', 'eu0', 'gy1'], 'Arabic': ['af3', 'ag5', 'ai1', 'am1', 'am7', 'ao4', 'ar2', 'au7', 'aw4', 'aw9', 'ax3', 'ba0', 'bd4', 'bf0', 'bi3', 'bi6', 'bm8', 'bn5', 'bn7', 'br8', 'bs5', 'bv2', 'bw4', 'cb8', 'cj2', 'ck1', 'ck2', 'cl5', 'co0', 'co4', 'cp4', 'cp5', 'cp6', 'cr1', 'cs0', 'cs7', 'ct4', 'cy2', 'db4', 'de1', 'di2', 'dj9', 'do1', 'dp7', 'ds6', 'dv1', 'dw0', 'ed3', 'ek1', 'ek6', 'el2', 'en4', 'eq1', 'et5', 'et8', 'ex9', 'ez6', 'fd3', 'fe2', 'fh1', 'fm5', 'fm9', 'fo0', 'fp1', 'ft9', 'fv4', 'fx8', 'gc0', 'gg0', 'gk4', 'go4', 'gw1', 'hb0'], 'Korean': ['ag9', 'an5', 'as0', 'ay1', 'be7', 'bv9', 'bz5', 'cc4', 'cj8', 'co5', 'cv3', 'cw0', 'dp5', 'ea4', 'eq8', 'es9', 'fj7', 'fp5', 'fs0', 'fu6', 'gc2', 'gg6', 'gq8', 'gz2', 'hb4'], 'Turkish': ['ah4', 'bs8', 'ch1', 'dp2', 'dx4', 'em0', 'fu1'], 'Chinese': ['aq1', 'ar8', 'bf7', 'bl4', 'bl7', 'bp4', 'bz2', 'cb3', 'cf9', 'cz4', 'dk6', 'eq4', 'ev9', 'fi1', 'fj4', 'fw7', 'gb4', 'gx5'], 'Russian': ['ax9', 'cm8'], 'English': ['ay4'], 'Spanish': ['bj2', 'cm9', 'fa2', 'fy1'], 'Suundi': ['cl9'], 'Italian': ['cx8'], 'Farsi': ['db5'], 'Portuguese': ['ff3']}\n"
     ]
    }
   ],
   "source": [
    "lang_dict_all={}\n",
    "for i in all_three:\n",
    "    df_ind=binarySearchArr(all_anon,i)\n",
    "    key=sorted_sac.at[df_ind,'native_language']\n",
    "    val=sorted_sac.at[df_ind,'anon_id']\n",
    "    \n",
    "    if key in lang_dict_all:\n",
    "        lang_dict_all[key].append(val)\n",
    "    else:\n",
    "        lang_dict_all[key]=[val]\n",
    "    \n",
    "print(lang_dict_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Japanese 6\n",
      "Thai 3\n",
      "Arabic 73\n",
      "Korean 25\n",
      "Turkish 7\n",
      "Chinese 18\n",
      "Russian 2\n",
      "English 1\n",
      "Spanish 4\n",
      "Suundi 1\n",
      "Italian 1\n",
      "Farsi 1\n",
      "Portuguese 1\n"
     ]
    }
   ],
   "source": [
    "for key, value in lang_dict_all.items():\n",
    "    print(key,len(value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding Participants in levels 3-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "366"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# will create a list of only the ids that have levels 3 and 4 in their lvl_nums column\n",
    "lvls34=[]\n",
    "ind=0\n",
    "for i in lvl_list.anon_id:\n",
    "    if ((3 in lvl_list.iat[ind,2]) and (4 in lvl_list.iat[ind,2])):\n",
    "        append=lvl_list.at[ind, 'anon_id']\n",
    "        lvls34.append(append)\n",
    "    ind+=1\n",
    "\n",
    "lvls34.sort()\n",
    "len(lvls34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Chinese': ['aa1', 'ag6', 'ai4', 'ap5', 'ap8', 'aq1', 'ar8', 'ax7', 'ba3', 'bf7', 'bl4', 'bl7', 'bp4', 'bu9', 'bz2', 'cb3', 'cf9', 'cl2', 'cl6', 'cq2', 'cs5', 'cz4', 'dg0', 'dk6', 'dl8', 'dm4', 'do7', 'dp1', 'dt4', 'dx1', 'eb6', 'ec5', 'eq4', 'ev5', 'ev9', 'ey8', 'ff6', 'fi1', 'fj4', 'fm2', 'fn8', 'fw7', 'fy3', 'gb4', 'gf2', 'gw5', 'gw8', 'gx5', 'gy3'], 'Arabic': ['aa2', 'ab2', 'ab8', 'ac8', 'ad9', 'ae0', 'af3', 'ag5', 'ai1', 'ak1', 'am1', 'am7', 'ao1', 'ao4', 'ao8', 'aq2', 'aq9', 'ar0', 'ar2', 'at9', 'au7', 'au8', 'aw4', 'aw9', 'ax3', 'ay7', 'az6', 'ba0', 'bb9', 'bd0', 'bd3', 'bd4', 'bf0', 'bg2', 'bh1', 'bi0', 'bi3', 'bi6', 'bj1', 'bj6', 'bm8', 'bn5', 'bn7', 'br8', 'bs5', 'bs9', 'bt7', 'bv2', 'bw4', 'bw5', 'bx5', 'by8', 'ca5', 'cb8', 'ce7', 'ch5', 'cj2', 'ck1', 'ck2', 'cl5', 'cl7', 'cm7', 'co0', 'co4', 'cp4', 'cp5', 'cp6', 'cq4', 'cr1', 'cs0', 'cs6', 'cs7', 'ct4', 'cu0', 'cu4', 'cu6', 'cw4', 'cy1', 'cy2', 'cy3', 'cz6', 'da7', 'db4', 'db6', 'dc1', 'de1', 'de4', 'de7', 'dg5', 'dh1', 'di2', 'dj9', 'dn2', 'do1', 'do3', 'do9', 'dp7', 'dr0', 'dr2', 'ds3', 'ds6', 'ds9', 'dt1', 'dv0', 'dv1', 'dw0', 'dw3', 'dw6', 'dx3', 'dx7', 'ed3', 'ed7', 'ef3', 'ej8', 'ek1', 'ek6', 'el0', 'el2', 'em5', 'en4', 'en8', 'eq1', 'er2', 'es2', 'et5', 'et8', 'ew9', 'ex9', 'ez6', 'fa4', 'fa6', 'fb8', 'fd3', 'fe2', 'fe4', 'fh1', 'fh2', 'fm5', 'fm9', 'fo0', 'fo1', 'fo7', 'fp1', 'fp4', 'fr0', 'fr5', 'fr9', 'fs9', 'ft9', 'fu4', 'fv1', 'fv4', 'fw4', 'fw5', 'fx8', 'fy8', 'gc0', 'gf0', 'gf6', 'gf7', 'gg0', 'gh3', 'gk4', 'gk8', 'gm5', 'go0', 'go2', 'go4', 'gp7', 'gr8', 'gs0', 'gt1', 'gt8', 'gu2', 'gw1', 'ha1', 'ha3', 'ha7', 'hb0', 'hb8'], 'Korean': ['aa9', 'af1', 'ag9', 'ah9', 'an4', 'an5', 'as0', 'as4', 'ay1', 'bc0', 'be2', 'be7', 'bf1', 'bm0', 'br5', 'bv9', 'bz5', 'ca6', 'cc4', 'cf6', 'ch9', 'cj8', 'cn3', 'co5', 'cv3', 'cw0', 'cw6', 'cy5', 'dd1', 'dj6', 'dp5', 'ea4', 'ef4', 'eo2', 'eq8', 'es9', 'et1', 'ex0', 'fc9', 'fh7', 'fi4', 'fj7', 'fk1', 'fl4', 'fl5', 'fo3', 'fp5', 'fp9', 'fs0', 'fu6', 'fv7', 'fv9', 'gb7', 'gc2', 'gd1', 'gg6', 'gl4', 'gq8', 'gv1', 'gz2', 'ha6', 'hb4'], 'Japanese': ['ad8', 'am9', 'ay3', 'bl6', 'bs1', 'cb2', 'cp2', 'df0', 'dz0', 'ew4', 'fw1', 'gh1', 'hb2'], 'Taiwanese': ['ae3', 'ci3', 'da0', 'ea5'], 'Thai': ['af0', 'cf3', 'ci6', 'cs1', 'ei3', 'eu0', 'gy1'], 'Turkish': ['ah4', 'bg5', 'bo5', 'bs8', 'ch1', 'co1', 'dp2', 'dx4', 'em0', 'er9', 'fr1', 'fu1', 'fx2', 'gg1', 'gq1', 'ha9'], 'French': ['av4', 'da9', 'dh6', 'fv6'], 'Russian': ['ax9', 'cm8', 'dj3'], 'English': ['ay4'], 'Vietnamese': ['bh9'], 'Spanish': ['bj2', 'ch0', 'cm9', 'cy6', 'en3', 'fa2', 'fe7', 'fg7', 'fy1', 'fy6'], 'Montenegrin': ['ce1'], 'Suundi': ['cl9'], 'Italian': ['cp7', 'cx8'], 'Farsi': ['db5', 'fz1'], 'Portuguese': ['di0', 'em8', 'fe3', 'ff3', 'go9'], 'Hebrew': ['ex6', 'fb1'], 'Mongol': ['fa9', 'gg5'], 'Other': ['gb1']}\n"
     ]
    }
   ],
   "source": [
    "lang_dict_34={}\n",
    "for i in lvls34:\n",
    "    df_ind=binarySearchArr(all_anon,i)\n",
    "    key=sorted_sac.at[df_ind,'native_language']\n",
    "    val=sorted_sac.at[df_ind,'anon_id']\n",
    "    \n",
    "    if key in lang_dict_34:\n",
    "        lang_dict_34[key].append(val)\n",
    "    else:\n",
    "        lang_dict_34[key]=[val]\n",
    "    \n",
    "print(lang_dict_34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chinese 49\n",
      "Arabic 180\n",
      "Korean 62\n",
      "Japanese 13\n",
      "Taiwanese 4\n",
      "Thai 7\n",
      "Turkish 16\n",
      "French 4\n",
      "Russian 3\n",
      "English 1\n",
      "Vietnamese 1\n",
      "Spanish 10\n",
      "Montenegrin 1\n",
      "Suundi 1\n",
      "Italian 2\n",
      "Farsi 2\n",
      "Portuguese 5\n",
      "Hebrew 2\n",
      "Mongol 2\n",
      "Other 1\n"
     ]
    }
   ],
   "source": [
    "for key, value in lang_dict_34.items():\n",
    "    print(key,len(value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding Participants in Levels 4 and 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "415"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# will create a list of only the ids that have levels 3 and 4 in their lvl_nums column\n",
    "lvls45=[]\n",
    "ind=0\n",
    "for i in lvl_list.anon_id:\n",
    "    if ((4 in lvl_list.iat[ind,2]) and (5 in lvl_list.iat[ind,2])):\n",
    "        append=lvl_list.at[ind, 'anon_id']\n",
    "        lvls45.append(append)\n",
    "    ind+=1\n",
    "\n",
    "lvls45.sort()\n",
    "len(lvls45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Korean': ['aa8', 'ac5', 'ad1', 'ag9', 'al5', 'an5', 'ap4', 'aq5', 'as0', 'as7', 'au5', 'au6', 'aw6', 'ay1', 'be7', 'bq0', 'bu4', 'bv9', 'bw3', 'bz5', 'cc4', 'ce3', 'ch2', 'ci0', 'cj8', 'co5', 'cp0', 'cv3', 'cw0', 'cw1', 'dd9', 'df3', 'dh0', 'dm3', 'dp5', 'dy7', 'ea4', 'eb3', 'eb9', 'ec1', 'eg5', 'eq8', 'es0', 'es9', 'et3', 'ex3', 'fa0', 'fa5', 'fb4', 'fd6', 'ff1', 'fi5', 'fj7', 'fl0', 'fp5', 'fs0', 'ft2', 'fu6', 'fx4', 'fz8', 'ga1', 'gc2', 'ge6', 'gg2', 'gg6', 'gj0', 'gk5', 'gl1', 'gn0', 'gq8', 'gs3', 'gu0', 'gz2', 'ha2', 'hb4'], 'Arabic': ['ac6', 'ad4', 'ad5', 'af3', 'ag5', 'ai1', 'aj5', 'ak0', 'al0', 'am1', 'am7', 'ao2', 'ao4', 'ap7', 'aq4', 'aq7', 'ar2', 'au7', 'aw4', 'aw9', 'ax3', 'ay2', 'ba0', 'ba1', 'ba5', 'ba9', 'bd4', 'bf0', 'bh2', 'bh3', 'bi3', 'bi5', 'bi6', 'bi7', 'bj8', 'bk5', 'bl5', 'bm8', 'bn5', 'bn6', 'bn7', 'bq3', 'br4', 'br8', 'bs5', 'bt2', 'bv1', 'bv2', 'bw2', 'bw4', 'bw6', 'by1', 'bz9', 'cb8', 'cc6', 'ce2', 'cg9', 'ci5', 'cj2', 'cj3', 'ck1', 'ck2', 'ck4', 'cl1', 'cl5', 'cn0', 'co0', 'co4', 'cp4', 'cp5', 'cp6', 'cr1', 'cs0', 'cs7', 'ct4', 'cu1', 'cv2', 'cv8', 'cy2', 'cz9', 'db4', 'db8', 'dd3', 'de1', 'dg9', 'dh8', 'di2', 'di3', 'dj9', 'dk3', 'dl1', 'dn4', 'do0', 'do1', 'do5', 'dp7', 'dq0', 'dr3', 'dr5', 'ds6', 'dt8', 'du6', 'dv1', 'dw0', 'dx2', 'dx5', 'dx9', 'dz1', 'ea9', 'ed3', 'ee5', 'ef0', 'ef6', 'ef9', 'eg2', 'eh0', 'eh4', 'ei0', 'ej9', 'ek1', 'ek6', 'el2', 'en4', 'eo5', 'eq0', 'eq1', 'er4', 'et0', 'et5', 'et8', 'ew2', 'ex9', 'ez5', 'ez6', 'fb3', 'fc0', 'fd3', 'fe2', 'fe9', 'fg0', 'fg9', 'fh1', 'fh5', 'fj2', 'fm5', 'fm9', 'fn5', 'fo0', 'fp1', 'fs3', 'fs6', 'ft9', 'fv4', 'fx8', 'fy0', 'fz0', 'ga9', 'gc0', 'gd7', 'gd8', 'gg0', 'gg7', 'gh8', 'gi1', 'gj2', 'gj4', 'gj8', 'gk4', 'gl6', 'go4', 'gp2', 'gw1', 'gw7', 'gx8', 'gz4', 'hb0', 'hb9'], 'Japanese': ['ac7', 'ad8', 'ah0', 'al2', 'am9', 'as2', 'at4', 'ay0', 'ay3', 'bc2', 'bh4', 'bs1', 'bu1', 'co2', 'cx4', 'db2', 'df7', 'dt3', 'dw7', 'dz5', 'dz9', 'el5', 'ey2', 'fh9', 'fu0', 'fw1', 'gs2', 'hb2', 'hb7'], 'Chinese': ['ad7', 'ae9', 'af4', 'am5', 'an7', 'aq1', 'ar8', 'ar9', 'az8', 'bd7', 'bf2', 'bf7', 'bf9', 'bl4', 'bl7', 'bp2', 'bp4', 'br9', 'bv8', 'bw9', 'by5', 'by6', 'bz1', 'bz2', 'ca4', 'cb3', 'cd6', 'cf9', 'ci2', 'cj5', 'cl3', 'cs4', 'cz2', 'cz4', 'dc0', 'di7', 'dk6', 'dk9', 'dm8', 'dq9', 'du9', 'dw2', 'ei2', 'ei8', 'eo1', 'eq4', 'es4', 'et4', 'ev6', 'ev9', 'ff2', 'fg8', 'fi1', 'fj4', 'fk8', 'fo4', 'fq5', 'fw7', 'ga3', 'gb4', 'gf5', 'gl2', 'gm1', 'gn5', 'go8', 'gt0', 'gv3', 'gw0', 'gx5'], 'Thai': ['af0', 'ah1', 'am8', 'ax2', 'be1', 'bl2', 'bl9', 'by3', 'cf2', 'cn4', 'dn8', 'ep4', 'eu0', 'gy1'], 'Turkish': ['ah4', 'an1', 'bs8', 'ch1', 'de5', 'dp2', 'dx4', 'ed2', 'em0', 'em7', 'fu1', 'gc5'], 'Taiwanese': ['aj1', 'az3', 'gb6', 'hc0'], 'Portuguese': ['am6', 'bm7', 'ff3'], 'Russian': ['ax9', 'bk2', 'cm8', 'eu8'], 'English': ['ay4'], 'Spanish': ['bi4', 'bj2', 'br2', 'cm9', 'cv7', 'dc6', 'df4', 'dk0', 'eo8', 'fa2', 'fx7', 'fy1', 'gq4', 'gs6', 'gu1', 'gu9'], 'Other': ['bm5', 'dp9', 'el7', 'fw9'], 'Suundi': ['cl9'], 'Italian': ['cx8', 'df6'], 'Farsi': ['db5'], 'French': ['ep2', 'ff4'], 'German': ['fh4']}\n"
     ]
    }
   ],
   "source": [
    "lang_dict_45={}\n",
    "for i in lvls45:\n",
    "    df_ind=binarySearchArr(all_anon,i)\n",
    "    key=sorted_sac.at[df_ind,'native_language']\n",
    "    val=sorted_sac.at[df_ind,'anon_id']\n",
    "    \n",
    "    if key in lang_dict_45:\n",
    "        lang_dict_45[key].append(val)\n",
    "    else:\n",
    "        lang_dict_45[key]=[val]\n",
    "    \n",
    "print(lang_dict_45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Korean 75\n",
      "Arabic 177\n",
      "Japanese 29\n",
      "Chinese 69\n",
      "Thai 14\n",
      "Turkish 12\n",
      "Taiwanese 4\n",
      "Portuguese 3\n",
      "Russian 4\n",
      "English 1\n",
      "Spanish 16\n",
      "Other 4\n",
      "Suundi 1\n",
      "Italian 2\n",
      "Farsi 1\n",
      "French 2\n",
      "German 1\n"
     ]
    }
   ],
   "source": [
    "for key, value in lang_dict_45.items():\n",
    "    print(key,len(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
