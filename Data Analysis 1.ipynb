{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import os\n",
    "import nltk\n",
    "import re\n",
    "import numpy as np\n",
    "import regex\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import pandas as pd\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function removes all of the rows that contain a string in the passed column\n",
    "def rmStr (df, col):\n",
    "    row_index=0\n",
    "    row_ind=[]\n",
    "    for i in df[col]:\n",
    "        try:\n",
    "            int(i)\n",
    "        except:\n",
    "            row_ind.append(row_index)\n",
    "        row_index+=1\n",
    "    return df.drop(labels=row_ind,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that finds the unique values in a list\n",
    "def get_uniques(x):\n",
    "    return list(x.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "loose=pd.read_csv('original-sheets\\Responses-Loose.csv')\n",
    "student_info=pd.read_csv('corpus-files\\student_information.csv')\n",
    "course=pd.read_csv('corpus-files\\course.csv')\n",
    "answer_df=pd.read_csv('answer.csv',index_col = 'answer_id', low_memory=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#dropping to only relevant columns\n",
    "loose=loose.drop(columns=['3Langs','Item','gender','course_id','class_id','version','text1_len','text2_len','text1',\n",
    "                         'text2 (line breaks/extra spaces removed, spaces added to reach 60)','Judgement','Notes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "course_=course.drop(columns=['class_id','semester','section'])\n",
    "\n",
    "student=student_info.drop(columns=['birth_year','language_used_at_home','non_native_language_1','yrs_of_study_lang1',\n",
    "                                  'study_in_classroom_lang1','ways_of_study_lang1','non_native_language_2','study_in_classroom_lang2',\n",
    "                                  'ways_of_study_lang2','non_native_language_3','yrs_of_study_lang3','study_in_classroom_lang3',\n",
    "                                  'ways_of_study_lang3','yrs_of_english_learning','yrs_in_english_environment','yrs_of_study_lang2'])\n",
    "answer_=answer_df[['question_id','anon_id','course_id','version','text_len','text','tokens']].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleaning the answer df\n",
    "col='course_id'\n",
    "answer=rmStr(answer_, col) #removes strings from answer_.course_id "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging the datasets\n",
    "\n",
    "merge_ans=answer[['anon_id','course_id']] #sets answer df up for merging \n",
    "student_merge=student.drop(columns=['course_history']) #set student df up for merging\n",
    "\n",
    "student_ans=student_merge.merge(answer,on='anon_id').astype({'course_id':'int64'}) #merges student and answers\n",
    "\n",
    "stu_ans_crs_=student_ans.merge(course_, on='course_id').drop(columns=['age','course_id','version','tokens']) #merges the student-answers df with course df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning Ans in Whole Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding spaces after punctuation if needed\n",
    "\n",
    "index=0\n",
    "stu_ans_crs=stu_ans_crs_.copy()\n",
    "stu_ans_crs['processed_text']=pd.NaT\n",
    "stu_ans_crs['wordtype_len']=pd.NaT\n",
    "words=[]\n",
    "for text in stu_ans_crs.text:\n",
    "    uwords=[]\n",
    "    text=text.replace('\\n',' ')\n",
    "    nopunc=text.translate(str.maketrans('','',string.punctuation))\n",
    "    nopunc=nopunc.lower()\n",
    "    stu_ans_crs.at[index,'processed_text']=nopunc\n",
    "    words=nopunc.strip().split(\" \")\n",
    "    for word in words:\n",
    "        if word=='':\n",
    "            words.remove(word)\n",
    "        elif word not in uwords:\n",
    "            uwords.append(word)\n",
    "    stu_ans_crs.at[index,'text_len']=len(words)\n",
    "    stu_ans_crs.at[index,'wordtype_len']=len(uwords)\n",
    "    index+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping all rows where the answer is less than 60 words\n",
    "index=0\n",
    "ind_list=[]\n",
    "for i in stu_ans_crs.text_len:\n",
    "    txtlen=int(i)\n",
    "    if txtlen < 60:\n",
    "        ind_list.append(index)\n",
    "    index+=1\n",
    "\n",
    "stu_ans_crs=stu_ans_crs.drop(labels=ind_list,axis=0).reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>anon_id</th>\n",
       "      <th>gender</th>\n",
       "      <th>native_language</th>\n",
       "      <th>answer_id</th>\n",
       "      <th>question_id</th>\n",
       "      <th>text_len</th>\n",
       "      <th>text</th>\n",
       "      <th>level_id</th>\n",
       "      <th>processed_text</th>\n",
       "      <th>wordtype_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>do6</td>\n",
       "      <td>Female</td>\n",
       "      <td>Russian</td>\n",
       "      <td>150</td>\n",
       "      <td>4</td>\n",
       "      <td>299</td>\n",
       "      <td>Some people prefer eat out and some like doing...</td>\n",
       "      <td>5</td>\n",
       "      <td>some people prefer eat out and some like doing...</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>do6</td>\n",
       "      <td>Female</td>\n",
       "      <td>Russian</td>\n",
       "      <td>1221</td>\n",
       "      <td>97</td>\n",
       "      <td>288</td>\n",
       "      <td>My opinion is that a person does need educatio...</td>\n",
       "      <td>5</td>\n",
       "      <td>my opinion is that a person does need educatio...</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>do6</td>\n",
       "      <td>Female</td>\n",
       "      <td>Russian</td>\n",
       "      <td>1957</td>\n",
       "      <td>189</td>\n",
       "      <td>317</td>\n",
       "      <td>There are two national rooms in the Cathedral ...</td>\n",
       "      <td>5</td>\n",
       "      <td>there are two national rooms in the cathedral ...</td>\n",
       "      <td>149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>do6</td>\n",
       "      <td>Female</td>\n",
       "      <td>Russian</td>\n",
       "      <td>2164</td>\n",
       "      <td>190</td>\n",
       "      <td>459</td>\n",
       "      <td>There are two nation rooms in the Cathedral of...</td>\n",
       "      <td>5</td>\n",
       "      <td>there are two nation rooms in the cathedral of...</td>\n",
       "      <td>187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>bv5</td>\n",
       "      <td>Male</td>\n",
       "      <td>Arabic</td>\n",
       "      <td>151</td>\n",
       "      <td>4</td>\n",
       "      <td>311</td>\n",
       "      <td>\"Not all learning takes place in the classroom...</td>\n",
       "      <td>5</td>\n",
       "      <td>not all learning takes place in the classroom ...</td>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17144</th>\n",
       "      <td>46214</td>\n",
       "      <td>bh8</td>\n",
       "      <td>Male</td>\n",
       "      <td>Japanese</td>\n",
       "      <td>48034</td>\n",
       "      <td>6087</td>\n",
       "      <td>107</td>\n",
       "      <td>I received my Medical Doctor license in Japan ...</td>\n",
       "      <td>3</td>\n",
       "      <td>i received my medical doctor license in japan ...</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17145</th>\n",
       "      <td>46215</td>\n",
       "      <td>bh8</td>\n",
       "      <td>Male</td>\n",
       "      <td>Japanese</td>\n",
       "      <td>48293</td>\n",
       "      <td>6119</td>\n",
       "      <td>138</td>\n",
       "      <td>I introduce my ideal home to you quickly. This...</td>\n",
       "      <td>3</td>\n",
       "      <td>i introduce my ideal home to you quickly this ...</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17146</th>\n",
       "      <td>46217</td>\n",
       "      <td>cz3</td>\n",
       "      <td>Female</td>\n",
       "      <td>Korean</td>\n",
       "      <td>47451</td>\n",
       "      <td>6027</td>\n",
       "      <td>102</td>\n",
       "      <td>I will put 5 items in time capsule such as som...</td>\n",
       "      <td>3</td>\n",
       "      <td>i will put 5 items in time capsule such as som...</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17147</th>\n",
       "      <td>46218</td>\n",
       "      <td>cz3</td>\n",
       "      <td>Female</td>\n",
       "      <td>Korean</td>\n",
       "      <td>48001</td>\n",
       "      <td>6087</td>\n",
       "      <td>104</td>\n",
       "      <td>I have studied Visual Design since 2002. I gra...</td>\n",
       "      <td>3</td>\n",
       "      <td>i have studied visual design since 2002 i grad...</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17148</th>\n",
       "      <td>46219</td>\n",
       "      <td>cz3</td>\n",
       "      <td>Female</td>\n",
       "      <td>Korean</td>\n",
       "      <td>48316</td>\n",
       "      <td>6119</td>\n",
       "      <td>70</td>\n",
       "      <td>I will describe about my ideal home. I want qu...</td>\n",
       "      <td>3</td>\n",
       "      <td>i will describe about my ideal home i want qui...</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17149 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index anon_id  gender native_language answer_id question_id text_len  \\\n",
       "0          0     do6  Female         Russian       150           4      299   \n",
       "1          1     do6  Female         Russian      1221          97      288   \n",
       "2          2     do6  Female         Russian      1957         189      317   \n",
       "3          3     do6  Female         Russian      2164         190      459   \n",
       "4          4     bv5    Male          Arabic       151           4      311   \n",
       "...      ...     ...     ...             ...       ...         ...      ...   \n",
       "17144  46214     bh8    Male        Japanese     48034        6087      107   \n",
       "17145  46215     bh8    Male        Japanese     48293        6119      138   \n",
       "17146  46217     cz3  Female          Korean     47451        6027      102   \n",
       "17147  46218     cz3  Female          Korean     48001        6087      104   \n",
       "17148  46219     cz3  Female          Korean     48316        6119       70   \n",
       "\n",
       "                                                    text  level_id  \\\n",
       "0      Some people prefer eat out and some like doing...         5   \n",
       "1      My opinion is that a person does need educatio...         5   \n",
       "2      There are two national rooms in the Cathedral ...         5   \n",
       "3      There are two nation rooms in the Cathedral of...         5   \n",
       "4      \"Not all learning takes place in the classroom...         5   \n",
       "...                                                  ...       ...   \n",
       "17144  I received my Medical Doctor license in Japan ...         3   \n",
       "17145  I introduce my ideal home to you quickly. This...         3   \n",
       "17146  I will put 5 items in time capsule such as som...         3   \n",
       "17147  I have studied Visual Design since 2002. I gra...         3   \n",
       "17148  I will describe about my ideal home. I want qu...         3   \n",
       "\n",
       "                                          processed_text wordtype_len  \n",
       "0      some people prefer eat out and some like doing...          125  \n",
       "1      my opinion is that a person does need educatio...          112  \n",
       "2      there are two national rooms in the cathedral ...          149  \n",
       "3      there are two nation rooms in the cathedral of...          187  \n",
       "4      not all learning takes place in the classroom ...          136  \n",
       "...                                                  ...          ...  \n",
       "17144  i received my medical doctor license in japan ...           54  \n",
       "17145  i introduce my ideal home to you quickly this ...           88  \n",
       "17146  i will put 5 items in time capsule such as som...           67  \n",
       "17147  i have studied visual design since 2002 i grad...           57  \n",
       "17148  i will describe about my ideal home i want qui...           51  \n",
       "\n",
       "[17149 rows x 11 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stu_ans_crs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning Loose Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answer_id</th>\n",
       "      <th>anon_id</th>\n",
       "      <th>L1</th>\n",
       "      <th>level_id</th>\n",
       "      <th>question_id</th>\n",
       "      <th>text3_len</th>\n",
       "      <th>text3 (edits made to fix word counts)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34686.0</td>\n",
       "      <td>aa0</td>\n",
       "      <td>Spanish</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4497.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>Barber, chef by profession, but an expert on a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32129.0</td>\n",
       "      <td>aa0</td>\n",
       "      <td>Spanish</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4199.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>The article \"English as Co star\" support the f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33302.0</td>\n",
       "      <td>aa0</td>\n",
       "      <td>Spanish</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4346.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>In this article the authors Goleman, Kaufman a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33308.0</td>\n",
       "      <td>aa0</td>\n",
       "      <td>Spanish</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4347.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>Flow in the sense expressed in the text \"The C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32572.0</td>\n",
       "      <td>aa0</td>\n",
       "      <td>Spanish</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4260.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>Bill Gates, in this conference, explained two ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1805</th>\n",
       "      <td>32406.0</td>\n",
       "      <td>ha2</td>\n",
       "      <td>Korean</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4273.0</td>\n",
       "      <td>217.0</td>\n",
       "      <td>Pittsburgh had a big snowstorm recently. A lot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1806</th>\n",
       "      <td>32326.0</td>\n",
       "      <td>ha2</td>\n",
       "      <td>Korean</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4256.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>Korea, which is connected to China, belongs to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1807</th>\n",
       "      <td>32077.0</td>\n",
       "      <td>ha2</td>\n",
       "      <td>Korean</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4197.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>Koko is a big female gorilla who was born in S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1808</th>\n",
       "      <td>29631.0</td>\n",
       "      <td>ha2</td>\n",
       "      <td>Korean</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3943.0</td>\n",
       "      <td>283.0</td>\n",
       "      <td>A natural disaster is the effect of the natura...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1809</th>\n",
       "      <td>32324.0</td>\n",
       "      <td>ha2</td>\n",
       "      <td>Korean</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4257.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>I think human language and nonhuman primate la...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1810 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      answer_id anon_id       L1  level_id  question_id  text3_len  \\\n",
       "0       34686.0     aa0  Spanish       5.0       4497.0      109.0   \n",
       "1       32129.0     aa0  Spanish       5.0       4199.0      190.0   \n",
       "2       33302.0     aa0  Spanish       5.0       4346.0      193.0   \n",
       "3       33308.0     aa0  Spanish       5.0       4347.0      170.0   \n",
       "4       32572.0     aa0  Spanish       5.0       4260.0       85.0   \n",
       "...         ...     ...      ...       ...          ...        ...   \n",
       "1805    32406.0     ha2   Korean       5.0       4273.0      217.0   \n",
       "1806    32326.0     ha2   Korean       5.0       4256.0      170.0   \n",
       "1807    32077.0     ha2   Korean       5.0       4197.0      195.0   \n",
       "1808    29631.0     ha2   Korean       4.0       3943.0      283.0   \n",
       "1809    32324.0     ha2   Korean       5.0       4257.0      168.0   \n",
       "\n",
       "                  text3 (edits made to fix word counts)  \n",
       "0     Barber, chef by profession, but an expert on a...  \n",
       "1     The article \"English as Co star\" support the f...  \n",
       "2     In this article the authors Goleman, Kaufman a...  \n",
       "3     Flow in the sense expressed in the text \"The C...  \n",
       "4     Bill Gates, in this conference, explained two ...  \n",
       "...                                                 ...  \n",
       "1805  Pittsburgh had a big snowstorm recently. A lot...  \n",
       "1806  Korea, which is connected to China, belongs to...  \n",
       "1807  Koko is a big female gorilla who was born in S...  \n",
       "1808  A natural disaster is the effect of the natura...  \n",
       "1809  I think human language and nonhuman primate la...  \n",
       "\n",
       "[1810 rows x 7 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop_loose=loose.dropna()\n",
    "\n",
    "sorted_loose=drop_loose.sort_values(by=['anon_id']).reset_index(drop=True)\n",
    "sorted_loose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "index=0\n",
    "textcount_loose=sorted_loose.copy()\n",
    "\n",
    "textcount_loose['processed_text']=pd.NaT\n",
    "textcount_loose['wordtype_len']=pd.NaT\n",
    "words=[]\n",
    "for text in textcount_loose['text3 (edits made to fix word counts)']:\n",
    "    uwords=[]\n",
    "    text=text.replace('\\n',' ')\n",
    "    nopunc=text.translate(str.maketrans('','',string.punctuation))\n",
    "    nopunc=nopunc.lower()\n",
    "    textcount_loose.at[index,'processed_text']=nopunc\n",
    "    words=nopunc.strip().split(\" \")\n",
    "    for word in words:\n",
    "        if word=='':\n",
    "            words.remove(word)\n",
    "        elif word not in uwords:\n",
    "            uwords.append(word)\n",
    "    textcount_loose.at[index,'text3_len']=len(words)\n",
    "    textcount_loose.at[index,'wordtype_len']=len(uwords)\n",
    "    index+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answer_id</th>\n",
       "      <th>anon_id</th>\n",
       "      <th>L1</th>\n",
       "      <th>level_id</th>\n",
       "      <th>question_id</th>\n",
       "      <th>text3_len</th>\n",
       "      <th>text3 (edits made to fix word counts)</th>\n",
       "      <th>processed_text</th>\n",
       "      <th>wordtype_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34686.0</td>\n",
       "      <td>aa0</td>\n",
       "      <td>Spanish</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4497.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>Barber, chef by profession, but an expert on a...</td>\n",
       "      <td>barber chef by profession but an expert on agr...</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32129.0</td>\n",
       "      <td>aa0</td>\n",
       "      <td>Spanish</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4199.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>The article \"English as Co star\" support the f...</td>\n",
       "      <td>the article english as co star support the fac...</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33302.0</td>\n",
       "      <td>aa0</td>\n",
       "      <td>Spanish</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4346.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>In this article the authors Goleman, Kaufman a...</td>\n",
       "      <td>in this article the authors goleman kaufman an...</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33308.0</td>\n",
       "      <td>aa0</td>\n",
       "      <td>Spanish</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4347.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>Flow in the sense expressed in the text \"The C...</td>\n",
       "      <td>flow in the sense expressed in the text the cr...</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32572.0</td>\n",
       "      <td>aa0</td>\n",
       "      <td>Spanish</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4260.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>Bill Gates, in this conference, explained two ...</td>\n",
       "      <td>bill gates in this conference explained two bi...</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1805</th>\n",
       "      <td>32406.0</td>\n",
       "      <td>ha2</td>\n",
       "      <td>Korean</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4273.0</td>\n",
       "      <td>217.0</td>\n",
       "      <td>Pittsburgh had a big snowstorm recently. A lot...</td>\n",
       "      <td>pittsburgh had a big snowstorm recently a lot ...</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1806</th>\n",
       "      <td>32326.0</td>\n",
       "      <td>ha2</td>\n",
       "      <td>Korean</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4256.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>Korea, which is connected to China, belongs to...</td>\n",
       "      <td>korea which is connected to china belongs to t...</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1807</th>\n",
       "      <td>32077.0</td>\n",
       "      <td>ha2</td>\n",
       "      <td>Korean</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4197.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>Koko is a big female gorilla who was born in S...</td>\n",
       "      <td>koko is a big female gorilla who was born in s...</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1808</th>\n",
       "      <td>29631.0</td>\n",
       "      <td>ha2</td>\n",
       "      <td>Korean</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3943.0</td>\n",
       "      <td>283.0</td>\n",
       "      <td>A natural disaster is the effect of the natura...</td>\n",
       "      <td>a natural disaster is the effect of the natura...</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1809</th>\n",
       "      <td>32324.0</td>\n",
       "      <td>ha2</td>\n",
       "      <td>Korean</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4257.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>I think human language and nonhuman primate la...</td>\n",
       "      <td>i think human language and nonhuman primate la...</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1810 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      answer_id anon_id       L1  level_id  question_id  text3_len  \\\n",
       "0       34686.0     aa0  Spanish       5.0       4497.0      109.0   \n",
       "1       32129.0     aa0  Spanish       5.0       4199.0      190.0   \n",
       "2       33302.0     aa0  Spanish       5.0       4346.0      193.0   \n",
       "3       33308.0     aa0  Spanish       5.0       4347.0      170.0   \n",
       "4       32572.0     aa0  Spanish       5.0       4260.0       85.0   \n",
       "...         ...     ...      ...       ...          ...        ...   \n",
       "1805    32406.0     ha2   Korean       5.0       4273.0      217.0   \n",
       "1806    32326.0     ha2   Korean       5.0       4256.0      170.0   \n",
       "1807    32077.0     ha2   Korean       5.0       4197.0      195.0   \n",
       "1808    29631.0     ha2   Korean       4.0       3943.0      283.0   \n",
       "1809    32324.0     ha2   Korean       5.0       4257.0      168.0   \n",
       "\n",
       "                  text3 (edits made to fix word counts)  \\\n",
       "0     Barber, chef by profession, but an expert on a...   \n",
       "1     The article \"English as Co star\" support the f...   \n",
       "2     In this article the authors Goleman, Kaufman a...   \n",
       "3     Flow in the sense expressed in the text \"The C...   \n",
       "4     Bill Gates, in this conference, explained two ...   \n",
       "...                                                 ...   \n",
       "1805  Pittsburgh had a big snowstorm recently. A lot...   \n",
       "1806  Korea, which is connected to China, belongs to...   \n",
       "1807  Koko is a big female gorilla who was born in S...   \n",
       "1808  A natural disaster is the effect of the natura...   \n",
       "1809  I think human language and nonhuman primate la...   \n",
       "\n",
       "                                         processed_text wordtype_len  \n",
       "0     barber chef by profession but an expert on agr...           79  \n",
       "1     the article english as co star support the fac...          117  \n",
       "2     in this article the authors goleman kaufman an...          122  \n",
       "3     flow in the sense expressed in the text the cr...          103  \n",
       "4     bill gates in this conference explained two bi...           66  \n",
       "...                                                 ...          ...  \n",
       "1805  pittsburgh had a big snowstorm recently a lot ...          129  \n",
       "1806  korea which is connected to china belongs to t...          101  \n",
       "1807  koko is a big female gorilla who was born in s...          115  \n",
       "1808  a natural disaster is the effect of the natura...          135  \n",
       "1809  i think human language and nonhuman primate la...          100  \n",
       "\n",
       "[1810 rows x 9 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textcount_loose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Level Grouping Whole Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "sac_lvls=stu_ans_crs[['anon_id','native_language','level_id']]\n",
    "sac_lvls_rkc=sac_lvls\n",
    "\n",
    "index=0\n",
    "for i in sac_lvls_rkc.native_language:\n",
    "    if (i != 'Korean' and i != 'Spanish' and i != 'Chinese'):\n",
    "        sac_lvls_rkc=sac_lvls_rkc.drop(index)\n",
    "    index+=1\n",
    "    \n",
    "# allows us to see what levels each anon_id participated in \n",
    "lvl_list=sac_lvls_rkc.groupby('anon_id').agg(n_uniq=('level_id','nunique'), lvl_nums=('level_id',get_uniques))\n",
    "lvl_list=lvl_list.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# will create a list of only the ids that have levels 3, 4, and 5 in their lvl_nums column\n",
    "all_three=[]\n",
    "ind=0\n",
    "for i in lvl_list.anon_id:\n",
    "    if ((3 in lvl_list.iat[ind,2]) and (4 in lvl_list.iat[ind,2]) and (5 in lvl_list.iat[ind,2])):\n",
    "        append=lvl_list.at[ind, 'anon_id']\n",
    "        all_three.append(append)\n",
    "    ind+=1\n",
    "\n",
    "all_three.sort()\n",
    "len(all_three)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "111"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# will create a list of only the ids that have levels 3 and 4 in their lvl_nums column\n",
    "lvls34=[]\n",
    "ind=0\n",
    "for i in lvl_list.anon_id:\n",
    "    if ((3 in lvl_list.iat[ind,2]) and (4 in lvl_list.iat[ind,2])):\n",
    "        append=lvl_list.at[ind, 'anon_id']\n",
    "        lvls34.append(append)\n",
    "    ind+=1\n",
    "\n",
    "lvls34.sort()\n",
    "len(lvls34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "154"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# will create a list of only the ids that have levels 3 and 4 in their lvl_nums column\n",
    "lvls45=[]\n",
    "ind=0\n",
    "for i in lvl_list.anon_id:\n",
    "    if ((4 in lvl_list.iat[ind,2]) and (5 in lvl_list.iat[ind,2])):\n",
    "        append=lvl_list.at[ind, 'anon_id']\n",
    "        lvls45.append(append)\n",
    "    ind+=1\n",
    "\n",
    "lvls45.sort()\n",
    "len(lvls45)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Level Grouping Loose Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anon_id</th>\n",
       "      <th>n_anon_ids_loose</th>\n",
       "      <th>lvl_nums_loose</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aa0</td>\n",
       "      <td>1</td>\n",
       "      <td>[5.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aa3</td>\n",
       "      <td>1</td>\n",
       "      <td>[4.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aa8</td>\n",
       "      <td>2</td>\n",
       "      <td>[4.0, 5.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aa9</td>\n",
       "      <td>2</td>\n",
       "      <td>[3.0, 4.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ab6</td>\n",
       "      <td>1</td>\n",
       "      <td>[4.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>gz2</td>\n",
       "      <td>2</td>\n",
       "      <td>[4.0, 5.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>gz5</td>\n",
       "      <td>1</td>\n",
       "      <td>[4.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>gz7</td>\n",
       "      <td>1</td>\n",
       "      <td>[4.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>ha0</td>\n",
       "      <td>1</td>\n",
       "      <td>[5.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>ha2</td>\n",
       "      <td>2</td>\n",
       "      <td>[4.0, 5.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>283 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    anon_id  n_anon_ids_loose lvl_nums_loose\n",
       "0       aa0                 1          [5.0]\n",
       "1       aa3                 1          [4.0]\n",
       "2       aa8                 2     [4.0, 5.0]\n",
       "3       aa9                 2     [3.0, 4.0]\n",
       "4       ab6                 1          [4.0]\n",
       "..      ...               ...            ...\n",
       "278     gz2                 2     [4.0, 5.0]\n",
       "279     gz5                 1          [4.0]\n",
       "280     gz7                 1          [4.0]\n",
       "281     ha0                 1          [5.0]\n",
       "282     ha2                 2     [4.0, 5.0]\n",
       "\n",
       "[283 rows x 3 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this code gets how many times an id appeared (n_anon_ids) as well as an array of what levels they participated in (lvl_nums)\n",
    "clean_ids_lvl_loose=drop_loose.groupby('anon_id').agg(\n",
    "    n_anon_ids_loose=('level_id', 'nunique'),\n",
    "    lvl_nums_loose=('level_id', get_uniques)\n",
    ")\n",
    "\n",
    "#changes the clean_ids_lvl's index so we can access the anon_id easier\n",
    "ind_loose= clean_ids_lvl_loose.reset_index()\n",
    "ind_loose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for loop that checks if lvl_nums has all three levels in it (3,4, and 5)\n",
    "# if there are three values in lvl_nums, the anon_id is appended to the all_three list\n",
    "ind=0\n",
    "all_three_loose=[]\n",
    "append=''\n",
    "for i in ind_loose.anon_id:\n",
    "    if ind_loose.iat[ind, 1]==3:\n",
    "        append=ind_loose.at[ind,'anon_id']\n",
    "        all_three_loose.append(append)\n",
    "    ind=ind+1\n",
    "\n",
    "all_three_loose.sort()\n",
    "len(all_three_loose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n"
     ]
    }
   ],
   "source": [
    "# creates list of participants in loose sheet that are in level 3 and 4\n",
    "ind=0\n",
    "in34_loose=[]\n",
    "append=''\n",
    "for i in ind_loose.anon_id:\n",
    "    if ind_loose.iat[ind, 1]==2:\n",
    "        if (3 in ind_loose.iat[ind,2] and 4 in ind_loose.iat[ind,2]):\n",
    "            append=ind_loose.at[ind,'anon_id']\n",
    "            in34_loose.append(append)\n",
    "    elif ind_loose.iat[ind,1]==3:\n",
    "        append=ind_loose.at[ind,'anon_id']\n",
    "        in34_loose.append(append)\n",
    "    ind=ind+1\n",
    "in34_loose.sort()\n",
    "print(len(in34_loose))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61\n"
     ]
    }
   ],
   "source": [
    "# creates list of participants in loose sheet that are in level 4 and 5\n",
    "ind=0\n",
    "in45_loose=[]\n",
    "append=''\n",
    "for i in ind_loose.anon_id:\n",
    "    if ind_loose.iat[ind, 1]==2:\n",
    "        if (4 in ind_loose.iat[ind,2] and 5 in ind_loose.iat[ind,2]):\n",
    "            append=ind_loose.at[ind,'anon_id']\n",
    "            in45_loose.append(append)\n",
    "    elif ind_loose.iat[ind,1]==3:\n",
    "        append=ind_loose.at[ind,'anon_id']\n",
    "        in45_loose.append(append)\n",
    "    ind=ind+1\n",
    "in45_loose.sort()\n",
    "print(len(in45_loose))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vocabulary Sophistication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ranked word list containing most commonly used words in the English language\n",
    "word_list=pd.read_csv(\"unigram_freq.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the</td>\n",
       "      <td>23135851162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>of</td>\n",
       "      <td>13151942776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>and</td>\n",
       "      <td>12997637966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>to</td>\n",
       "      <td>12136980858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a</td>\n",
       "      <td>9081174698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333328</th>\n",
       "      <td>gooek</td>\n",
       "      <td>12711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333329</th>\n",
       "      <td>gooddg</td>\n",
       "      <td>12711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333330</th>\n",
       "      <td>gooblle</td>\n",
       "      <td>12711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333331</th>\n",
       "      <td>gollgo</td>\n",
       "      <td>12711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333332</th>\n",
       "      <td>golgw</td>\n",
       "      <td>12711</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>333333 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           word        count\n",
       "0           the  23135851162\n",
       "1            of  13151942776\n",
       "2           and  12997637966\n",
       "3            to  12136980858\n",
       "4             a   9081174698\n",
       "...         ...          ...\n",
       "333328    gooek        12711\n",
       "333329   gooddg        12711\n",
       "333330  gooblle        12711\n",
       "333331   gollgo        12711\n",
       "333332    golgw        12711\n",
       "\n",
       "[333333 rows x 2 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creates a list of words from the word_list df\n",
    "def thousandcount(df, word_list, count,limit):\n",
    "    while(count<limit):\n",
    "        word=str(df.iat[count,0])\n",
    "        word_list.append(word)\n",
    "        count+=1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#will create a list of words out of the answer text then check those words with whatever thousand list is passed\n",
    "#if a word from the answer is also in the thousand list, then it's added to a list. the length of this list is\n",
    "#the number of words from the thousands list that occurs in the answer text and that's appended to a new column for the thousand list\n",
    "def vocSophCols(df, col_name, col2_name, text_col, thouslist):\n",
    "    index=0\n",
    "    df[col_name]=pd.NaT\n",
    "    df[col2_name]=pd.NaT\n",
    "    df[\"Words \"+col2_name]=pd.NaT\n",
    "    for text in df[text_col]:\n",
    "        twords=[]\n",
    "        uwords=[]\n",
    "        words=[]\n",
    "        words=text.strip().split(\" \")\n",
    "        for word in words:\n",
    "            if word in thouslist:\n",
    "                twords.append(word)\n",
    "                if word not in uwords:\n",
    "                    uwords.append(word)\n",
    "        df.at[index,col_name]=len(twords)\n",
    "        df.at[index,col2_name]=len(uwords)\n",
    "        df.at[index,\"Words \"+col2_name]=str(uwords)\n",
    "        index+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating list of the first,second,third, etc thousand words in the most common words list\n",
    "firstk,secondk,thirdk,fourthk,fifthk,sixthk,seventhk,eighthk,ninthk,tenthk,rest=[],[],[],[],[],[],[],[],[],[],[]\n",
    "count=0\n",
    "\n",
    "count=thousandcount(word_list,firstk,count,1000)\n",
    "count=thousandcount(word_list,secondk,count,2000)\n",
    "count=thousandcount(word_list, thirdk, count,3000)\n",
    "count=thousandcount(word_list, fourthk, count,4000)\n",
    "count=thousandcount(word_list, fifthk, count,5000)\n",
    "count=thousandcount(word_list, sixthk, count,6000)\n",
    "count=thousandcount(word_list, seventhk, count,7000)\n",
    "count=thousandcount(word_list,eighthk,count, 8000)\n",
    "count=thousandcount(word_list,ninthk,count,9000)\n",
    "count=thousandcount(word_list,tenthk,count, 10000)\n",
    "#count=thousandcount(word_list,rest,count,333333)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'of', 'a', 'stuff', 'online', 'stuff']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#testing\n",
    "text=\"the of a stuff online stuff glapagos\"\n",
    "twords=[]\n",
    "words=text.strip().split(\" \")\n",
    "for word in words:\n",
    "    if word in firstk:\n",
    "        twords.append(word)\n",
    "print(twords)\n",
    "len(twords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Whole Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a list of all the ids in all the groups\n",
    "all_groups=[]\n",
    "for i in all_three: # and lvls34 and lvls45:\n",
    "    if i not in all_groups:\n",
    "        all_groups.append(i)\n",
    "for i in lvls34:\n",
    "    if i not in all_groups:\n",
    "        all_groups.append(i)\n",
    "for i in lvls45:\n",
    "    if i not in all_groups:\n",
    "        all_groups.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>anon_id</th>\n",
       "      <th>gender</th>\n",
       "      <th>native_language</th>\n",
       "      <th>answer_id</th>\n",
       "      <th>question_id</th>\n",
       "      <th>text_len</th>\n",
       "      <th>text</th>\n",
       "      <th>level_id</th>\n",
       "      <th>processed_text</th>\n",
       "      <th>wordtype_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>do6</td>\n",
       "      <td>Female</td>\n",
       "      <td>Russian</td>\n",
       "      <td>150</td>\n",
       "      <td>4</td>\n",
       "      <td>299</td>\n",
       "      <td>Some people prefer eat out and some like doing...</td>\n",
       "      <td>5</td>\n",
       "      <td>some people prefer eat out and some like doing...</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>do6</td>\n",
       "      <td>Female</td>\n",
       "      <td>Russian</td>\n",
       "      <td>1221</td>\n",
       "      <td>97</td>\n",
       "      <td>288</td>\n",
       "      <td>My opinion is that a person does need educatio...</td>\n",
       "      <td>5</td>\n",
       "      <td>my opinion is that a person does need educatio...</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>do6</td>\n",
       "      <td>Female</td>\n",
       "      <td>Russian</td>\n",
       "      <td>1957</td>\n",
       "      <td>189</td>\n",
       "      <td>317</td>\n",
       "      <td>There are two national rooms in the Cathedral ...</td>\n",
       "      <td>5</td>\n",
       "      <td>there are two national rooms in the cathedral ...</td>\n",
       "      <td>149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>do6</td>\n",
       "      <td>Female</td>\n",
       "      <td>Russian</td>\n",
       "      <td>2164</td>\n",
       "      <td>190</td>\n",
       "      <td>459</td>\n",
       "      <td>There are two nation rooms in the Cathedral of...</td>\n",
       "      <td>5</td>\n",
       "      <td>there are two nation rooms in the cathedral of...</td>\n",
       "      <td>187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>bv5</td>\n",
       "      <td>Male</td>\n",
       "      <td>Arabic</td>\n",
       "      <td>151</td>\n",
       "      <td>4</td>\n",
       "      <td>311</td>\n",
       "      <td>\"Not all learning takes place in the classroom...</td>\n",
       "      <td>5</td>\n",
       "      <td>not all learning takes place in the classroom ...</td>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17144</th>\n",
       "      <td>46214</td>\n",
       "      <td>bh8</td>\n",
       "      <td>Male</td>\n",
       "      <td>Japanese</td>\n",
       "      <td>48034</td>\n",
       "      <td>6087</td>\n",
       "      <td>107</td>\n",
       "      <td>I received my Medical Doctor license in Japan ...</td>\n",
       "      <td>3</td>\n",
       "      <td>i received my medical doctor license in japan ...</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17145</th>\n",
       "      <td>46215</td>\n",
       "      <td>bh8</td>\n",
       "      <td>Male</td>\n",
       "      <td>Japanese</td>\n",
       "      <td>48293</td>\n",
       "      <td>6119</td>\n",
       "      <td>138</td>\n",
       "      <td>I introduce my ideal home to you quickly. This...</td>\n",
       "      <td>3</td>\n",
       "      <td>i introduce my ideal home to you quickly this ...</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17146</th>\n",
       "      <td>46217</td>\n",
       "      <td>cz3</td>\n",
       "      <td>Female</td>\n",
       "      <td>Korean</td>\n",
       "      <td>47451</td>\n",
       "      <td>6027</td>\n",
       "      <td>102</td>\n",
       "      <td>I will put 5 items in time capsule such as som...</td>\n",
       "      <td>3</td>\n",
       "      <td>i will put 5 items in time capsule such as som...</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17147</th>\n",
       "      <td>46218</td>\n",
       "      <td>cz3</td>\n",
       "      <td>Female</td>\n",
       "      <td>Korean</td>\n",
       "      <td>48001</td>\n",
       "      <td>6087</td>\n",
       "      <td>104</td>\n",
       "      <td>I have studied Visual Design since 2002. I gra...</td>\n",
       "      <td>3</td>\n",
       "      <td>i have studied visual design since 2002 i grad...</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17148</th>\n",
       "      <td>46219</td>\n",
       "      <td>cz3</td>\n",
       "      <td>Female</td>\n",
       "      <td>Korean</td>\n",
       "      <td>48316</td>\n",
       "      <td>6119</td>\n",
       "      <td>70</td>\n",
       "      <td>I will describe about my ideal home. I want qu...</td>\n",
       "      <td>3</td>\n",
       "      <td>i will describe about my ideal home i want qui...</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17149 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index anon_id  gender native_language answer_id question_id text_len  \\\n",
       "0          0     do6  Female         Russian       150           4      299   \n",
       "1          1     do6  Female         Russian      1221          97      288   \n",
       "2          2     do6  Female         Russian      1957         189      317   \n",
       "3          3     do6  Female         Russian      2164         190      459   \n",
       "4          4     bv5    Male          Arabic       151           4      311   \n",
       "...      ...     ...     ...             ...       ...         ...      ...   \n",
       "17144  46214     bh8    Male        Japanese     48034        6087      107   \n",
       "17145  46215     bh8    Male        Japanese     48293        6119      138   \n",
       "17146  46217     cz3  Female          Korean     47451        6027      102   \n",
       "17147  46218     cz3  Female          Korean     48001        6087      104   \n",
       "17148  46219     cz3  Female          Korean     48316        6119       70   \n",
       "\n",
       "                                                    text  level_id  \\\n",
       "0      Some people prefer eat out and some like doing...         5   \n",
       "1      My opinion is that a person does need educatio...         5   \n",
       "2      There are two national rooms in the Cathedral ...         5   \n",
       "3      There are two nation rooms in the Cathedral of...         5   \n",
       "4      \"Not all learning takes place in the classroom...         5   \n",
       "...                                                  ...       ...   \n",
       "17144  I received my Medical Doctor license in Japan ...         3   \n",
       "17145  I introduce my ideal home to you quickly. This...         3   \n",
       "17146  I will put 5 items in time capsule such as som...         3   \n",
       "17147  I have studied Visual Design since 2002. I gra...         3   \n",
       "17148  I will describe about my ideal home. I want qu...         3   \n",
       "\n",
       "                                          processed_text wordtype_len  \n",
       "0      some people prefer eat out and some like doing...          125  \n",
       "1      my opinion is that a person does need educatio...          112  \n",
       "2      there are two national rooms in the cathedral ...          149  \n",
       "3      there are two nation rooms in the cathedral of...          187  \n",
       "4      not all learning takes place in the classroom ...          136  \n",
       "...                                                  ...          ...  \n",
       "17144  i received my medical doctor license in japan ...           54  \n",
       "17145  i introduce my ideal home to you quickly this ...           88  \n",
       "17146  i will put 5 items in time capsule such as som...           67  \n",
       "17147  i have studied visual design since 2002 i grad...           57  \n",
       "17148  i will describe about my ideal home i want qui...           51  \n",
       "\n",
       "[17149 rows x 11 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stu_ans_crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>anon_id</th>\n",
       "      <th>native_language</th>\n",
       "      <th>question_id</th>\n",
       "      <th>text_len</th>\n",
       "      <th>text</th>\n",
       "      <th>level_id</th>\n",
       "      <th>processed_text</th>\n",
       "      <th>wordtype_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>aa8</td>\n",
       "      <td>Korean</td>\n",
       "      <td>1258</td>\n",
       "      <td>770</td>\n",
       "      <td>College students are usually very busy during ...</td>\n",
       "      <td>5</td>\n",
       "      <td>college students are usually very busy during ...</td>\n",
       "      <td>232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>61</td>\n",
       "      <td>aa8</td>\n",
       "      <td>Korean</td>\n",
       "      <td>1511</td>\n",
       "      <td>64</td>\n",
       "      <td>I think it is strange to throw away something ...</td>\n",
       "      <td>4</td>\n",
       "      <td>i think it is strange to throw away something ...</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>62</td>\n",
       "      <td>aa8</td>\n",
       "      <td>Korean</td>\n",
       "      <td>1184</td>\n",
       "      <td>809</td>\n",
       "      <td>College students are usually very busy during ...</td>\n",
       "      <td>5</td>\n",
       "      <td>college students are usually very busy during ...</td>\n",
       "      <td>237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>63</td>\n",
       "      <td>aa8</td>\n",
       "      <td>Korean</td>\n",
       "      <td>1219</td>\n",
       "      <td>343</td>\n",
       "      <td>I thought this was homework. \\nT.T I could not...</td>\n",
       "      <td>5</td>\n",
       "      <td>i thought this was homework  tt i could not th...</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>64</td>\n",
       "      <td>aa8</td>\n",
       "      <td>Korean</td>\n",
       "      <td>1138</td>\n",
       "      <td>137</td>\n",
       "      <td>I. I think using a schedule book is a good way...</td>\n",
       "      <td>5</td>\n",
       "      <td>i i think using a schedule book is a good way ...</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5221</th>\n",
       "      <td>17074</td>\n",
       "      <td>hb4</td>\n",
       "      <td>Korean</td>\n",
       "      <td>160</td>\n",
       "      <td>397</td>\n",
       "      <td>Cats and dogs are the most popular pets in the...</td>\n",
       "      <td>4</td>\n",
       "      <td>cats and dogs are the most popular pets in the...</td>\n",
       "      <td>172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5222</th>\n",
       "      <td>17075</td>\n",
       "      <td>hb4</td>\n",
       "      <td>Korean</td>\n",
       "      <td>203</td>\n",
       "      <td>440</td>\n",
       "      <td>Cats and dogs are the most popular pets in the...</td>\n",
       "      <td>4</td>\n",
       "      <td>cats and dogs are the most popular pets in the...</td>\n",
       "      <td>183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5223</th>\n",
       "      <td>17076</td>\n",
       "      <td>hb4</td>\n",
       "      <td>Korean</td>\n",
       "      <td>117</td>\n",
       "      <td>405</td>\n",
       "      <td>Global Warming\\n\\nIn the greenhouse, plants ca...</td>\n",
       "      <td>4</td>\n",
       "      <td>global warming  in the greenhouse plants can l...</td>\n",
       "      <td>199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5224</th>\n",
       "      <td>17077</td>\n",
       "      <td>hb4</td>\n",
       "      <td>Korean</td>\n",
       "      <td>472</td>\n",
       "      <td>110</td>\n",
       "      <td>My hometown is Seoul, which is capital city of...</td>\n",
       "      <td>4</td>\n",
       "      <td>my hometown is seoul which is capital city of ...</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5225</th>\n",
       "      <td>17078</td>\n",
       "      <td>hb4</td>\n",
       "      <td>Korean</td>\n",
       "      <td>386</td>\n",
       "      <td>84</td>\n",
       "      <td>By the time I went to high school, I hadn't ex...</td>\n",
       "      <td>4</td>\n",
       "      <td>by the time i went to high school i hadnt exer...</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5226 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index anon_id native_language question_id text_len  \\\n",
       "0        60     aa8          Korean        1258      770   \n",
       "1        61     aa8          Korean        1511       64   \n",
       "2        62     aa8          Korean        1184      809   \n",
       "3        63     aa8          Korean        1219      343   \n",
       "4        64     aa8          Korean        1138      137   \n",
       "...     ...     ...             ...         ...      ...   \n",
       "5221  17074     hb4          Korean         160      397   \n",
       "5222  17075     hb4          Korean         203      440   \n",
       "5223  17076     hb4          Korean         117      405   \n",
       "5224  17077     hb4          Korean         472      110   \n",
       "5225  17078     hb4          Korean         386       84   \n",
       "\n",
       "                                                   text  level_id  \\\n",
       "0     College students are usually very busy during ...         5   \n",
       "1     I think it is strange to throw away something ...         4   \n",
       "2     College students are usually very busy during ...         5   \n",
       "3     I thought this was homework. \\nT.T I could not...         5   \n",
       "4     I. I think using a schedule book is a good way...         5   \n",
       "...                                                 ...       ...   \n",
       "5221  Cats and dogs are the most popular pets in the...         4   \n",
       "5222  Cats and dogs are the most popular pets in the...         4   \n",
       "5223  Global Warming\\n\\nIn the greenhouse, plants ca...         4   \n",
       "5224  My hometown is Seoul, which is capital city of...         4   \n",
       "5225  By the time I went to high school, I hadn't ex...         4   \n",
       "\n",
       "                                         processed_text wordtype_len  \n",
       "0     college students are usually very busy during ...          232  \n",
       "1     i think it is strange to throw away something ...           51  \n",
       "2     college students are usually very busy during ...          237  \n",
       "3     i thought this was homework  tt i could not th...          150  \n",
       "4     i i think using a schedule book is a good way ...           63  \n",
       "...                                                 ...          ...  \n",
       "5221  cats and dogs are the most popular pets in the...          172  \n",
       "5222  cats and dogs are the most popular pets in the...          183  \n",
       "5223  global warming  in the greenhouse plants can l...          199  \n",
       "5224  my hometown is seoul which is capital city of ...           70  \n",
       "5225  by the time i went to high school i hadnt exer...           50  \n",
       "\n",
       "[5226 rows x 9 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#removing the ids that aren't in any of the level groups\n",
    "sort_sac=stu_ans_crs.sort_values(by=['anon_id']).reset_index(drop=True)\n",
    "sort_sac=sort_sac.drop(columns=['index','answer_id','gender'])\n",
    "just_groups=sort_sac.copy()\n",
    "drops=[]\n",
    "ind=0\n",
    "for i in sort_sac['anon_id']:\n",
    "    if i not in all_groups:\n",
    "        drops.append(ind)\n",
    "    ind+=1\n",
    "\n",
    "just_groups=just_groups.drop(labels=drops,axis=0).reset_index()\n",
    "just_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocSophCols(just_groups, '1k','WT 1k','processed_text',firstk)\n",
    "vocSophCols(just_groups,'2k','WT 2k','processed_text',secondk)\n",
    "vocSophCols(just_groups,'3k','WT 3k','processed_text',thirdk)\n",
    "vocSophCols(just_groups,'4k','WT 4k','processed_text',fourthk)\n",
    "vocSophCols(just_groups,'5k','WT 5k','processed_text',fifthk)\n",
    "vocSophCols(just_groups,'6k','WT 6k','processed_text',sixthk)\n",
    "vocSophCols(just_groups,'7k','WT 7k','processed_text',seventhk)\n",
    "vocSophCols(just_groups,'8k','WT 8k','processed_text',eighthk)\n",
    "vocSophCols(just_groups,'9k','WT 9k','processed_text',ninthk)\n",
    "vocSophCols(just_groups,'10k','WT 10k','processed_text',tenthk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "index=0\n",
    "just_groups['10k+']=pd.NaT\n",
    "for length in just_groups.text_len:\n",
    "    k1=just_groups.at[index,'1k']\n",
    "    k2=just_groups.at[index,'2k']\n",
    "    k3=just_groups.at[index,'3k']\n",
    "    k4=just_groups.at[index,'4k']\n",
    "    k5=just_groups.at[index,'5k']\n",
    "    k6=just_groups.at[index,'6k']\n",
    "    k7=just_groups.at[index,'7k']\n",
    "    k8=just_groups.at[index,'8k']\n",
    "    k9=just_groups.at[index,'9k']\n",
    "    k10=just_groups.at[index,'10k']\n",
    "    total=k1+k2+k3+k4+k5+k6+k7+k8+k9+k10\n",
    "    remaining=length-total\n",
    "    just_groups.at[index, '10k+']=remaining\n",
    "    \n",
    "    lengthwt=just_groups.at[index,'wordtype_len']\n",
    "    k1wt=just_groups.at[index,'WT 1k']\n",
    "    k2wt=just_groups.at[index,'WT 2k']\n",
    "    k3wt=just_groups.at[index,'WT 3k']\n",
    "    k4wt=just_groups.at[index,'WT 4k']\n",
    "    k5wt=just_groups.at[index,'WT 5k']\n",
    "    k6wt=just_groups.at[index,'WT 6k']\n",
    "    k7wt=just_groups.at[index,'WT 7k']\n",
    "    k8wt=just_groups.at[index,'WT 8k']\n",
    "    k9wt=just_groups.at[index,'WT 9k']\n",
    "    k10wt=just_groups.at[index,'WT 10k']\n",
    "    totalwt=k1wt+k2wt+k3wt+k4wt+k5wt+k6wt+k7wt+k8wt+k9wt+k10wt\n",
    "    remainingwt=lengthwt-totalwt\n",
    "    just_groups.at[index,'WT 10k+']=remainingwt\n",
    "    index+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>anon_id</th>\n",
       "      <th>native_language</th>\n",
       "      <th>question_id</th>\n",
       "      <th>text_len</th>\n",
       "      <th>text</th>\n",
       "      <th>level_id</th>\n",
       "      <th>processed_text</th>\n",
       "      <th>wordtype_len</th>\n",
       "      <th>1k</th>\n",
       "      <th>...</th>\n",
       "      <th>WT 8k</th>\n",
       "      <th>Words WT 8k</th>\n",
       "      <th>9k</th>\n",
       "      <th>WT 9k</th>\n",
       "      <th>Words WT 9k</th>\n",
       "      <th>10k</th>\n",
       "      <th>WT 10k</th>\n",
       "      <th>Words WT 10k</th>\n",
       "      <th>10k+</th>\n",
       "      <th>WT 10k+</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>aa8</td>\n",
       "      <td>Korean</td>\n",
       "      <td>1258</td>\n",
       "      <td>770</td>\n",
       "      <td>College students are usually very busy during ...</td>\n",
       "      <td>5</td>\n",
       "      <td>college students are usually very busy during ...</td>\n",
       "      <td>232</td>\n",
       "      <td>606</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>['cant', 'scanning']</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>['quizzes', 'efficiently', 'divide']</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>['concentrate', 'bother', 'qt']</td>\n",
       "      <td>28</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>61</td>\n",
       "      <td>aa8</td>\n",
       "      <td>Korean</td>\n",
       "      <td>1511</td>\n",
       "      <td>64</td>\n",
       "      <td>I think it is strange to throw away something ...</td>\n",
       "      <td>4</td>\n",
       "      <td>i think it is strange to throw away something ...</td>\n",
       "      <td>51</td>\n",
       "      <td>43</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>['predict']</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>62</td>\n",
       "      <td>aa8</td>\n",
       "      <td>Korean</td>\n",
       "      <td>1184</td>\n",
       "      <td>809</td>\n",
       "      <td>College students are usually very busy during ...</td>\n",
       "      <td>5</td>\n",
       "      <td>college students are usually very busy during ...</td>\n",
       "      <td>237</td>\n",
       "      <td>665</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>['cant', 'nervous', 'organize']</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>['efficiently']</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>['concentrate', 'bother']</td>\n",
       "      <td>18</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>63</td>\n",
       "      <td>aa8</td>\n",
       "      <td>Korean</td>\n",
       "      <td>1219</td>\n",
       "      <td>343</td>\n",
       "      <td>I thought this was homework. \\nT.T I could not...</td>\n",
       "      <td>5</td>\n",
       "      <td>i thought this was homework  tt i could not th...</td>\n",
       "      <td>150</td>\n",
       "      <td>271</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>['grammar', 'expressions']</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>['concentrate']</td>\n",
       "      <td>19</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>64</td>\n",
       "      <td>aa8</td>\n",
       "      <td>Korean</td>\n",
       "      <td>1138</td>\n",
       "      <td>137</td>\n",
       "      <td>I. I think using a schedule book is a good way...</td>\n",
       "      <td>5</td>\n",
       "      <td>i i think using a schedule book is a good way ...</td>\n",
       "      <td>63</td>\n",
       "      <td>108</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>['organize']</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>11</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5221</th>\n",
       "      <td>17074</td>\n",
       "      <td>hb4</td>\n",
       "      <td>Korean</td>\n",
       "      <td>160</td>\n",
       "      <td>397</td>\n",
       "      <td>Cats and dogs are the most popular pets in the...</td>\n",
       "      <td>4</td>\n",
       "      <td>cats and dogs are the most popular pets in the...</td>\n",
       "      <td>172</td>\n",
       "      <td>280</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>['cant', 'lonely']</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>['differently']</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>12</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5222</th>\n",
       "      <td>17075</td>\n",
       "      <td>hb4</td>\n",
       "      <td>Korean</td>\n",
       "      <td>203</td>\n",
       "      <td>440</td>\n",
       "      <td>Cats and dogs are the most popular pets in the...</td>\n",
       "      <td>4</td>\n",
       "      <td>cats and dogs are the most popular pets in the...</td>\n",
       "      <td>183</td>\n",
       "      <td>313</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>['lonely', 'aggressive', 'cant']</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>['differently']</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>14</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5223</th>\n",
       "      <td>17076</td>\n",
       "      <td>hb4</td>\n",
       "      <td>Korean</td>\n",
       "      <td>117</td>\n",
       "      <td>405</td>\n",
       "      <td>Global Warming\\n\\nIn the greenhouse, plants ca...</td>\n",
       "      <td>4</td>\n",
       "      <td>global warming  in the greenhouse plants can l...</td>\n",
       "      <td>199</td>\n",
       "      <td>241</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>['cant']</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>['warming', 'phenomenon', 'rays', 'centuries']</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>['greenhouse', 'refrigerator', 'ozone']</td>\n",
       "      <td>37</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5224</th>\n",
       "      <td>17077</td>\n",
       "      <td>hb4</td>\n",
       "      <td>Korean</td>\n",
       "      <td>472</td>\n",
       "      <td>110</td>\n",
       "      <td>My hometown is Seoul, which is capital city of...</td>\n",
       "      <td>4</td>\n",
       "      <td>my hometown is seoul which is capital city of ...</td>\n",
       "      <td>70</td>\n",
       "      <td>82</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>['neighbors']</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>['lobby']</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>['hometown']</td>\n",
       "      <td>6</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5225</th>\n",
       "      <td>17078</td>\n",
       "      <td>hb4</td>\n",
       "      <td>Korean</td>\n",
       "      <td>386</td>\n",
       "      <td>84</td>\n",
       "      <td>By the time I went to high school, I hadn't ex...</td>\n",
       "      <td>4</td>\n",
       "      <td>by the time i went to high school i hadnt exer...</td>\n",
       "      <td>50</td>\n",
       "      <td>57</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>['hobby']</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>['boring']</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>6</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5226 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index anon_id native_language question_id text_len  \\\n",
       "0        60     aa8          Korean        1258      770   \n",
       "1        61     aa8          Korean        1511       64   \n",
       "2        62     aa8          Korean        1184      809   \n",
       "3        63     aa8          Korean        1219      343   \n",
       "4        64     aa8          Korean        1138      137   \n",
       "...     ...     ...             ...         ...      ...   \n",
       "5221  17074     hb4          Korean         160      397   \n",
       "5222  17075     hb4          Korean         203      440   \n",
       "5223  17076     hb4          Korean         117      405   \n",
       "5224  17077     hb4          Korean         472      110   \n",
       "5225  17078     hb4          Korean         386       84   \n",
       "\n",
       "                                                   text  level_id  \\\n",
       "0     College students are usually very busy during ...         5   \n",
       "1     I think it is strange to throw away something ...         4   \n",
       "2     College students are usually very busy during ...         5   \n",
       "3     I thought this was homework. \\nT.T I could not...         5   \n",
       "4     I. I think using a schedule book is a good way...         5   \n",
       "...                                                 ...       ...   \n",
       "5221  Cats and dogs are the most popular pets in the...         4   \n",
       "5222  Cats and dogs are the most popular pets in the...         4   \n",
       "5223  Global Warming\\n\\nIn the greenhouse, plants ca...         4   \n",
       "5224  My hometown is Seoul, which is capital city of...         4   \n",
       "5225  By the time I went to high school, I hadn't ex...         4   \n",
       "\n",
       "                                         processed_text wordtype_len   1k  \\\n",
       "0     college students are usually very busy during ...          232  606   \n",
       "1     i think it is strange to throw away something ...           51   43   \n",
       "2     college students are usually very busy during ...          237  665   \n",
       "3     i thought this was homework  tt i could not th...          150  271   \n",
       "4     i i think using a schedule book is a good way ...           63  108   \n",
       "...                                                 ...          ...  ...   \n",
       "5221  cats and dogs are the most popular pets in the...          172  280   \n",
       "5222  cats and dogs are the most popular pets in the...          183  313   \n",
       "5223  global warming  in the greenhouse plants can l...          199  241   \n",
       "5224  my hometown is seoul which is capital city of ...           70   82   \n",
       "5225  by the time i went to high school i hadnt exer...           50   57   \n",
       "\n",
       "      ... WT 8k                       Words WT 8k  9k WT 9k  \\\n",
       "0     ...     2              ['cant', 'scanning']   7     3   \n",
       "1     ...     0                                []   1     1   \n",
       "2     ...     3   ['cant', 'nervous', 'organize']   1     1   \n",
       "3     ...     2        ['grammar', 'expressions']   0     0   \n",
       "4     ...     1                      ['organize']   0     0   \n",
       "...   ...   ...                               ...  ..   ...   \n",
       "5221  ...     2                ['cant', 'lonely']   1     1   \n",
       "5222  ...     3  ['lonely', 'aggressive', 'cant']   2     1   \n",
       "5223  ...     1                          ['cant']  12     4   \n",
       "5224  ...     1                     ['neighbors']   1     1   \n",
       "5225  ...     1                         ['hobby']   1     1   \n",
       "\n",
       "                                         Words WT 9k 10k WT 10k  \\\n",
       "0               ['quizzes', 'efficiently', 'divide']   4      3   \n",
       "1                                        ['predict']   0      0   \n",
       "2                                    ['efficiently']   2      2   \n",
       "3                                                 []   1      1   \n",
       "4                                                 []   0      0   \n",
       "...                                              ...  ..    ...   \n",
       "5221                                 ['differently']   0      0   \n",
       "5222                                 ['differently']   0      0   \n",
       "5223  ['warming', 'phenomenon', 'rays', 'centuries']  12      3   \n",
       "5224                                       ['lobby']   1      1   \n",
       "5225                                      ['boring']   0      0   \n",
       "\n",
       "                                 Words WT 10k 10k+ WT 10k+  \n",
       "0             ['concentrate', 'bother', 'qt']   28    14.0  \n",
       "1                                          []    5     5.0  \n",
       "2                   ['concentrate', 'bother']   18    10.0  \n",
       "3                             ['concentrate']   19     8.0  \n",
       "4                                          []   11     0.0  \n",
       "...                                       ...  ...     ...  \n",
       "5221                                       []   12    12.0  \n",
       "5222                                       []   14    13.0  \n",
       "5223  ['greenhouse', 'refrigerator', 'ozone']   37    29.0  \n",
       "5224                             ['hometown']    6     3.0  \n",
       "5225                                       []    6     6.0  \n",
       "\n",
       "[5226 rows x 41 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "just_groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loose Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answer_id</th>\n",
       "      <th>anon_id</th>\n",
       "      <th>L1</th>\n",
       "      <th>level_id</th>\n",
       "      <th>question_id</th>\n",
       "      <th>text3_len</th>\n",
       "      <th>text3 (edits made to fix word counts)</th>\n",
       "      <th>processed_text</th>\n",
       "      <th>wordtype_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34686.0</td>\n",
       "      <td>aa0</td>\n",
       "      <td>Spanish</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4497.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>Barber, chef by profession, but an expert on a...</td>\n",
       "      <td>barber chef by profession but an expert on agr...</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32129.0</td>\n",
       "      <td>aa0</td>\n",
       "      <td>Spanish</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4199.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>The article \"English as Co star\" support the f...</td>\n",
       "      <td>the article english as co star support the fac...</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33302.0</td>\n",
       "      <td>aa0</td>\n",
       "      <td>Spanish</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4346.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>In this article the authors Goleman, Kaufman a...</td>\n",
       "      <td>in this article the authors goleman kaufman an...</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33308.0</td>\n",
       "      <td>aa0</td>\n",
       "      <td>Spanish</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4347.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>Flow in the sense expressed in the text \"The C...</td>\n",
       "      <td>flow in the sense expressed in the text the cr...</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32572.0</td>\n",
       "      <td>aa0</td>\n",
       "      <td>Spanish</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4260.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>Bill Gates, in this conference, explained two ...</td>\n",
       "      <td>bill gates in this conference explained two bi...</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1792</th>\n",
       "      <td>32816.0</td>\n",
       "      <td>ha2</td>\n",
       "      <td>Korean</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4305.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>In Korea, a lot of parents who want their chil...</td>\n",
       "      <td>in korea a lot of parents who want their child...</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1791</th>\n",
       "      <td>29184.0</td>\n",
       "      <td>ha2</td>\n",
       "      <td>Korean</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3852.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>The importance of women is getting greater in ...</td>\n",
       "      <td>the importance of women is getting greater in ...</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1808</th>\n",
       "      <td>29631.0</td>\n",
       "      <td>ha2</td>\n",
       "      <td>Korean</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3943.0</td>\n",
       "      <td>283.0</td>\n",
       "      <td>A natural disaster is the effect of the natura...</td>\n",
       "      <td>a natural disaster is the effect of the natura...</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1799</th>\n",
       "      <td>35728.0</td>\n",
       "      <td>ha2</td>\n",
       "      <td>Korean</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4604.0</td>\n",
       "      <td>315.0</td>\n",
       "      <td>Fresh air, the npr's program, invited Ben Stil...</td>\n",
       "      <td>fresh air the nprs program invited ben stiller...</td>\n",
       "      <td>159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1809</th>\n",
       "      <td>32324.0</td>\n",
       "      <td>ha2</td>\n",
       "      <td>Korean</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4257.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>I think human language and nonhuman primate la...</td>\n",
       "      <td>i think human language and nonhuman primate la...</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1810 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      answer_id anon_id       L1  level_id  question_id  text3_len  \\\n",
       "0       34686.0     aa0  Spanish       5.0       4497.0      109.0   \n",
       "1       32129.0     aa0  Spanish       5.0       4199.0      190.0   \n",
       "2       33302.0     aa0  Spanish       5.0       4346.0      193.0   \n",
       "3       33308.0     aa0  Spanish       5.0       4347.0      170.0   \n",
       "4       32572.0     aa0  Spanish       5.0       4260.0       85.0   \n",
       "...         ...     ...      ...       ...          ...        ...   \n",
       "1792    32816.0     ha2   Korean       5.0       4305.0      177.0   \n",
       "1791    29184.0     ha2   Korean       4.0       3852.0       69.0   \n",
       "1808    29631.0     ha2   Korean       4.0       3943.0      283.0   \n",
       "1799    35728.0     ha2   Korean       5.0       4604.0      315.0   \n",
       "1809    32324.0     ha2   Korean       5.0       4257.0      168.0   \n",
       "\n",
       "                  text3 (edits made to fix word counts)  \\\n",
       "0     Barber, chef by profession, but an expert on a...   \n",
       "1     The article \"English as Co star\" support the f...   \n",
       "2     In this article the authors Goleman, Kaufman a...   \n",
       "3     Flow in the sense expressed in the text \"The C...   \n",
       "4     Bill Gates, in this conference, explained two ...   \n",
       "...                                                 ...   \n",
       "1792  In Korea, a lot of parents who want their chil...   \n",
       "1791  The importance of women is getting greater in ...   \n",
       "1808  A natural disaster is the effect of the natura...   \n",
       "1799  Fresh air, the npr's program, invited Ben Stil...   \n",
       "1809  I think human language and nonhuman primate la...   \n",
       "\n",
       "                                         processed_text wordtype_len  \n",
       "0     barber chef by profession but an expert on agr...           79  \n",
       "1     the article english as co star support the fac...          117  \n",
       "2     in this article the authors goleman kaufman an...          122  \n",
       "3     flow in the sense expressed in the text the cr...          103  \n",
       "4     bill gates in this conference explained two bi...           66  \n",
       "...                                                 ...          ...  \n",
       "1792  in korea a lot of parents who want their child...          100  \n",
       "1791  the importance of women is getting greater in ...           53  \n",
       "1808  a natural disaster is the effect of the natura...          135  \n",
       "1799  fresh air the nprs program invited ben stiller...          159  \n",
       "1809  i think human language and nonhuman primate la...          100  \n",
       "\n",
       "[1810 rows x 9 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loose_soph=textcount_loose.sort_values(by=['anon_id'])\n",
    "loose_soph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocSophCols(loose_soph, '1k','WT 1k','processed_text',firstk)\n",
    "vocSophCols(loose_soph,'2k','WT 2k','processed_text',secondk)\n",
    "vocSophCols(loose_soph,'3k','WT 3k','processed_text',thirdk)\n",
    "vocSophCols(loose_soph,'4k','WT 4k','processed_text',fourthk)\n",
    "vocSophCols(loose_soph,'5k','WT 5k','processed_text',fifthk)\n",
    "vocSophCols(loose_soph,'6k','WT 6k','processed_text',sixthk)\n",
    "vocSophCols(loose_soph,'7k','WT 7k','processed_text',seventhk)\n",
    "vocSophCols(loose_soph,'8k','WT 8k','processed_text',eighthk)\n",
    "vocSophCols(loose_soph,'9k','WT 9k','processed_text',ninthk)\n",
    "vocSophCols(loose_soph,'10k','WT 10k','processed_text',tenthk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index=0\n",
    "loose_soph['10k+']=pd.NaT\n",
    "for length in loose_soph.text3_len:\n",
    "    k1=loose_soph.at[index,'1k']\n",
    "    k2=loose_soph.at[index,'2k']\n",
    "    k3=loose_soph.at[index,'3k']\n",
    "    k4=loose_soph.at[index,'4k']\n",
    "    k5=loose_soph.at[index,'5k']\n",
    "    k6=loose_soph.at[index,'6k']\n",
    "    k7=loose_soph.at[index,'7k']\n",
    "    k8=loose_soph.at[index,'8k']\n",
    "    k9=loose_soph.at[index,'9k']\n",
    "    k10=loose_soph.at[index,'10k']\n",
    "    total=k1+k2+k3+k4+k5+k6+k7+k8+k9+k10\n",
    "    remaining=length-total\n",
    "    loose_soph.at[index, '10k+']=remaining\n",
    "    \n",
    "    lengthwt=loose_soph.at[index,'wordtype_len']\n",
    "    k1wt=loose_soph.at[index,'WT 1k']\n",
    "    k2wt=loose_soph.at[index,'WT 2k']\n",
    "    k3wt=loose_soph.at[index,'WT 3k']\n",
    "    k4wt=loose_soph.at[index,'WT 4k']\n",
    "    k5wt=loose_soph.at[index,'WT 5k']\n",
    "    k6wt=loose_soph.at[index,'WT 6k']\n",
    "    k7wt=loose_soph.at[index,'WT 7k']\n",
    "    k8wt=loose_soph.at[index,'WT 8k']\n",
    "    k9wt=loose_soph.at[index,'WT 9k']\n",
    "    k10wt=loose_soph.at[index,'WT 10k']\n",
    "    totalwt=k1wt+k2wt+k3wt+k4wt+k5wt+k6wt+k7wt+k8wt+k9wt+k10wt\n",
    "    remainingwt=lengthwt-totalwt\n",
    "    loose_soph.at[index,'WT 10k+']=remainingwt\n",
    "    index+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loose_soph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finds the average of all the columns \n",
    "def vocDist(df, lang_col, lvl, lang, thoulist):\n",
    "    index=0\n",
    "    count=0\n",
    "    thoucount=0\n",
    "    for i in df.anon_id:\n",
    "        if df.at[index,'level_id']==lvl and df.at[index,lang_col]==lang:\n",
    "            thoucount+=df.at[index,thoulist]\n",
    "            count+=1\n",
    "        index+=1\n",
    "    return thoucount/count"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
