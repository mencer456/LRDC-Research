{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import nltk\n",
    "import re\n",
    "import numpy as np\n",
    "import regex\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import pandas as pd\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "loose=pd.read_csv('original-sheets\\Responses-Loose.csv')\n",
    "student_info=pd.read_csv('corpus-files\\student_information.csv')\n",
    "course=pd.read_csv('corpus-files\\course.csv')\n",
    "answer_df=pd.read_csv('answer.csv',index_col = 'answer_id', low_memory=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping to only relevant columns\n",
    "loose=loose.drop(columns=['3Langs','Item','gender','course_id','class_id','version','text1_len','text2_len','text1',\n",
    "                         'text2 (line breaks/extra spaces removed, spaces added to reach 60)','Judgement','Notes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "course_=course.drop(columns=['class_id','semester','section'])\n",
    "\n",
    "student=student_info.drop(columns=['birth_year','language_used_at_home','non_native_language_1','yrs_of_study_lang1',\n",
    "                                  'study_in_classroom_lang1','ways_of_study_lang1','non_native_language_2','study_in_classroom_lang2',\n",
    "                                  'ways_of_study_lang2','non_native_language_3','yrs_of_study_lang3','study_in_classroom_lang3',\n",
    "                                  'ways_of_study_lang3','yrs_of_english_learning','yrs_in_english_environment','yrs_of_study_lang2'])\n",
    "answer_=answer_df[['question_id','anon_id','course_id','version','text_len','text','tokens']].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rmStr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-4f1ce8ac66c3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Cleaning the answer df\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mcol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'course_id'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0manswer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrmStr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0manswer_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#removes strings from answer_.course_id\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'rmStr' is not defined"
     ]
    }
   ],
   "source": [
    "#Cleaning the answer df\n",
    "col='course_id'\n",
    "answer=rmStr(answer_, col) #removes strings from answer_.course_id "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging the datasets\n",
    "\n",
    "#merge_ans=answer_[['anon_id','course_id']] #sets answer df up for merging \n",
    "#student_merge=student.drop(columns=['course_history']) #set student df up for merging\n",
    "\n",
    "student_ans=student.merge(answer_,on='anon_id').astype({'course_id':'int64'}) #merges student and answers\n",
    "\n",
    "stu_ans_crs=student_ans.merge(course_, on='course_id')\n",
    "#.drop(columns=['age','course_id','version','tokens']) #merges the student-answers df with course df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that finds the unique values in a list\n",
    "def get_uniques(x):\n",
    "    return list(x.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Whole Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stu_ans_crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sac_lvls=stu_ans_crs[['anon_id','native_language','level_id','question_id','text']]\n",
    "sac_lvls_rkc=sac_lvls\n",
    "\n",
    "index=0\n",
    "for i in sac_lvls_rkc.native_language:\n",
    "    if (i != 'Korean' and i != 'Spanish' and i != 'Chinese'):\n",
    "        sac_lvls_rkc=sac_lvls_rkc.drop(index)\n",
    "    index+=1\n",
    "\n",
    "sac_lvls_rkc=sac_lvls_rkc.reset_index()\n",
    "\n",
    "sac_lvls_rkc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# allows us to see what levels each anon_id participated in \n",
    "lvl_list=sac_lvls_rkc.groupby('anon_id').agg(n_uniq=('question_id','nunique'), lvl_nums=('question_id',get_uniques))\n",
    "lvl_list=lvl_list.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_q=sac_lvls_rkc.groupby('native_language').agg(n_uniq=('question_id','nunique'))\n",
    "unique_q=unique_q.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_t=sac_lvls_rkc.groupby('native_language').agg(n_uniq=('text','nunique'))\n",
    "unique_t=unique_t.reset_index()\n",
    "unique_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_a=sac_lvls_rkc.groupby('native_language').agg(n_uniq=('anon_id','nunique'))\n",
    "unique_a=unique_a.reset_index()\n",
    "unique_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sac_lvls_rkc=sac_lvls_rkc.reset_index()\n",
    "sac_lvls_rkc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dividing my level 3 and language\n",
    "sac_lvls_rkc3=sac_lvls_rkc\n",
    "\n",
    "index=0\n",
    "for i in sac_lvls_rkc3.level_id:\n",
    "    if i!=3:\n",
    "        sac_lvls_rkc3=sac_lvls_rkc3.drop(index)\n",
    "    index+=1\n",
    "    \n",
    "sac_lvls_rkc3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_q=sac_lvls_rkc3.groupby('native_language').agg(n_uniq=('question_id','nunique'))\n",
    "unique_q=unique_q.reset_index()\n",
    "\n",
    "unique_t=sac_lvls_rkc3.groupby('native_language').agg(n_uniq=('text','nunique'))\n",
    "unique_t=unique_t.reset_index()\n",
    "\n",
    "unique_a=sac_lvls_rkc3.groupby('native_language').agg(n_uniq=('anon_id','nunique'))\n",
    "unique_a=unique_a.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dividing my level 4 and language\n",
    "sac_lvls_rkc4=sac_lvls_rkc\n",
    "\n",
    "index=0\n",
    "for i in sac_lvls_rkc4.level_id:\n",
    "    if i!=4:\n",
    "        sac_lvls_rkc4=sac_lvls_rkc4.drop(index)\n",
    "    index+=1\n",
    "    \n",
    "sac_lvls_rkc4=sac_lvls_rkc4.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_q=sac_lvls_rkc4.groupby('native_language').agg(n_uniq=('question_id','nunique'))\n",
    "unique_q=unique_q.reset_index()\n",
    "\n",
    "unique_t=sac_lvls_rkc4.groupby('native_language').agg(n_uniq=('text','nunique'))\n",
    "unique_t=unique_t.reset_index()\n",
    "\n",
    "unique_a=sac_lvls_rkc4.groupby('native_language').agg(n_uniq=('anon_id','nunique'))\n",
    "unique_a=unique_a.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dividing my level 5 and language\n",
    "sac_lvls_rkc5=sac_lvls_rkc\n",
    "\n",
    "index=0\n",
    "for i in sac_lvls_rkc5.level_id:\n",
    "    if i!=5:\n",
    "        sac_lvls_rkc5=sac_lvls_rkc5.drop(index)\n",
    "    index+=1\n",
    "    \n",
    "sac_lvls_rkc5=sac_lvls_rkc5.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_q=sac_lvls_rkc5.groupby('native_language').agg(n_uniq=('question_id','nunique'))\n",
    "unique_q=unique_q.reset_index()\n",
    "\n",
    "unique_t=sac_lvls_rkc5.groupby('native_language').agg(n_uniq=('text','nunique'))\n",
    "unique_t=unique_t.reset_index()\n",
    "\n",
    "unique_a=sac_lvls_rkc5.groupby('native_language').agg(n_uniq=('anon_id','nunique'))\n",
    "unique_a=unique_a.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loose Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loose=loose.dropna()\n",
    "loose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # this code gets how many times an id appeared (n_anon_ids) as well as an array of what levels they participated in (lvl_nums)\n",
    "clean_ids_lvl_loose=loose.groupby('anon_id').agg(\n",
    "    n_anon_ids_loose=('level_id', 'nunique'),\n",
    "    lvl_nums_loose=('level_id', get_uniques)\n",
    ")\n",
    "\n",
    "#changes the clean_ids_lvl's index so we can access the anon_id easier\n",
    "ind_loose= clean_ids_lvl_loose.reset_index()\n",
    "ind_loose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for loop that checks if lvl_nums has all three levels in it (3,4, and 5)\n",
    "# if there are three values in lvl_nums, the anon_id is appended to the all_three list\n",
    "ind=0\n",
    "all_three_loose=[]\n",
    "append=''\n",
    "for i in ind_loose.anon_id:\n",
    "    if ind_loose.iat[ind, 1]==3:\n",
    "        append=ind_loose.at[ind,'anon_id']\n",
    "        all_three_loose.append(append)\n",
    "    ind=ind+1\n",
    "\n",
    "all_three_loose.sort()\n",
    "len(all_three_loose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates list of participants in loose sheet that are in level 3 and 4\n",
    "ind=0\n",
    "in34_loose=[]\n",
    "append=''\n",
    "for i in ind_loose.anon_id:\n",
    "    if ind_loose.iat[ind, 1]==2:\n",
    "        if (3 in ind_loose.iat[ind,2] and 4 in ind_loose.iat[ind,2]):\n",
    "            append=ind_loose.at[ind,'anon_id']\n",
    "            in34_loose.append(append)\n",
    "    elif ind_loose.iat[ind,1]==3:\n",
    "        append=ind_loose.at[ind,'anon_id']\n",
    "        in34_loose.append(append)\n",
    "    ind=ind+1\n",
    "in34_loose.sort()\n",
    "print(len(in34_loose))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates list of participants in loose sheet that are in level 4 and 5\n",
    "ind=0\n",
    "in45_loose=[]\n",
    "append=''\n",
    "for i in ind_loose.anon_id:\n",
    "    if ind_loose.iat[ind, 1]==2:\n",
    "        if (4 in ind_loose.iat[ind,2] and 5 in ind_loose.iat[ind,2]):\n",
    "            append=ind_loose.at[ind,'anon_id']\n",
    "            in45_loose.append(append)\n",
    "    elif ind_loose.iat[ind,1]==3:\n",
    "        append=ind_loose.at[ind,'anon_id']\n",
    "        in45_loose.append(append)\n",
    "    ind=ind+1\n",
    "in45_loose.sort()\n",
    "print(len(in45_loose))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding number of texts breakdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_three_loose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_three=loose\n",
    "index=0\n",
    "for i in all_three.anon_id:\n",
    "    if i not in all_three_loose:\n",
    "        all_three=all_three.drop(index)\n",
    "    index+=1\n",
    "    \n",
    "all_three=all_three.reset_index()\n",
    "all_three"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loose34=loose\n",
    "index=0\n",
    "for i in loose34.anon_id:\n",
    "    if i not in in34_loose:\n",
    "        loose34=loose34.drop(index)\n",
    "    index+=1\n",
    "    \n",
    "loose34=loose34.reset_index()\n",
    "loose34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loose45=loose\n",
    "index=0\n",
    "for i in loose45.anon_id:\n",
    "    if i not in in45_loose:\n",
    "        loose45=loose45.drop(index)\n",
    "    index+=1\n",
    "    \n",
    "loose45=loose45.reset_index()\n",
    "loose45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_t=all_three.groupby(['L1','level_id']).agg(n_uniq=('text3 (edits made to fix word counts)','nunique'))\n",
    "unique_t=unique_t.reset_index()\n",
    "unique_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_t=loose34.groupby(['L1','level_id']).agg(n_uniq=('text3 (edits made to fix word counts)','nunique'))\n",
    "unique_t=unique_t.reset_index()\n",
    "unique_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_t=loose45.groupby(['L1','level_id']).agg(n_uniq=('text3 (edits made to fix word counts)','nunique'))\n",
    "unique_t=unique_t.reset_index()\n",
    "unique_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finds the number of texts per language in the given list of anon_ids\n",
    "def find_counts(df,lang_col):\n",
    "    spanish=0\n",
    "    chinese=0\n",
    "    korean=0\n",
    "    index=0\n",
    "    for i in df[\"answer_id\"]:\n",
    "        if df.at[index,lang_col]=='Spanish':\n",
    "            spanish+=1\n",
    "        elif df.at[index,lang_col]=='Chinese':\n",
    "            chinese+=1\n",
    "        elif df.at[index,lang_col]=='Korean':\n",
    "            korean+=1\n",
    "        index+=1\n",
    "       # anon_id=str(df.at[index,'anon_id'])\n",
    "    return(spanish,chinese,korean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finds the token average of the given level in the given level group (id_list) for each language\n",
    "def tokenAvg(df,textlencol,lang, id_list,lvl):\n",
    "    index=0\n",
    "    #total token count\n",
    "    spanish=0\n",
    "    chinese=0\n",
    "    korean=0\n",
    "    #number of questions\n",
    "    qcounts=0\n",
    "    qcountc=0\n",
    "    qcountk=0\n",
    "\n",
    "    for anon in df['anon_id']:\n",
    "        if df.at[index,'level_id']==lvl and df.at[index,'anon_id'] in id_list:\n",
    "            textlen=df.at[index,textlencol]\n",
    "            textlen=int(textlen)\n",
    "            if df.at[index,lang]=='Spanish':\n",
    "                spanish+=textlen\n",
    "                qcounts+=1\n",
    "            elif df.at[index,lang]=='Korean':\n",
    "                korean+=textlen\n",
    "                qcountk+=1\n",
    "            elif df.at[index,lang]=='Chinese':\n",
    "                chinese+=textlen\n",
    "                qcountc+=1\n",
    "        index+=1\n",
    "        \n",
    "    print(\"Spanish Average: \",spanish/qcounts)\n",
    "    print(\"Korean Average: \",korean/qcountk)\n",
    "    print(\"Chinese Average: \",chinese/qcountc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding the token/word count ratio for each language\n",
    "def ratio(df,textlencol,typelencol,lang, id_list,lvl):\n",
    "    index=0\n",
    "    #total token count\n",
    "    spanish=0\n",
    "    chinese=0\n",
    "    korean=0\n",
    "    #unique token count\n",
    "    tspanish=0\n",
    "    tkorean=0\n",
    "    tchinese=0\n",
    "    #total question count\n",
    "    qcounts=0\n",
    "    qcountc=0\n",
    "    qcountk=0\n",
    "\n",
    "    for anon in df['anon_id']:\n",
    "        if df.at[index,'level_id']==lvl and df.at[index,'anon_id'] in id_list:\n",
    "            textlen=df.at[index,textlencol]\n",
    "            textlen=int(textlen)\n",
    "            typelen=df.at[index,typelencol]\n",
    "            typelen=int(typelen)\n",
    "            if df.at[index,lang]=='Spanish':\n",
    "                spanish+=textlen\n",
    "                tspanish+=typelen\n",
    "                qcounts+=1\n",
    "            elif df.at[index,lang]=='Korean':\n",
    "                korean+=textlen\n",
    "                tkorean+=typelen\n",
    "                qcountk+=1\n",
    "            elif df.at[index,lang]=='Chinese':\n",
    "                chinese+=textlen\n",
    "                tchinese+=typelen\n",
    "                qcountc+=1\n",
    "        index+=1\n",
    "\n",
    "    #finding ratios    \n",
    "    spanishavg=spanish/qcounts\n",
    "    tspanishavg=tspanish/qcounts\n",
    "    koreanavg=korean/qcountk\n",
    "    tkoreanavg=tkorean/qcountk\n",
    "    chineseavg=chinese/qcountc\n",
    "    tchineseavg=tchinese/qcountc\n",
    "    \n",
    "    print(\"Spanish Ratio: \",tspanishavg/spanishavg)\n",
    "    print(\"Korean Ratio: \",tkoreanavg/koreanavg)\n",
    "    print(\"Chinese Ratio: \",tchineseavg/chineseavg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that counts the amount of tokens per language FINDS AVERAGE OF ALL LVLS IN SPECIFIED LIST\n",
    "def finding_tokens(df,id_list,lang_col,text_len_col,qcounts):\n",
    "    spanish=0\n",
    "    korean=0\n",
    "    chinese=0\n",
    "    index=0\n",
    "    lspanish=0\n",
    "    lchinese=0\n",
    "    lkorean=0\n",
    "    \n",
    "    for i in df['anon_id']:\n",
    "        if i in id_list:\n",
    "            lang=df.at[index,lang_col]\n",
    "            length=int(df.at[index,text_len_col])\n",
    "            if lang=='Spanish':\n",
    "                lspanish+=1\n",
    "                spanish+=length\n",
    "            elif lang=='Korean':\n",
    "                lkorean+=1\n",
    "                korean+=length\n",
    "            elif lang=='Chinese':\n",
    "                lchinese+=1\n",
    "                chinese+=length\n",
    "        index+=1\n",
    "   # print('Spanish Token Average: ',spanish,'\\nKorean Token Average: ',korean,\n",
    "    #      '\\nChinese Token Average:',chinese)\n",
    "    print('Spanish Token Average: ',spanish/lspanish,'\\nKorean Token Average: ',korean/lkorean,\n",
    "          '\\nChinese Token Average:',chinese/lchinese)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "index=0\n",
    "textcount_loose=loose.copy()\n",
    "\n",
    "textcount_loose['processed_text']=pd.NaT\n",
    "textcount_loose['wordtype_len']=pd.NaT\n",
    "words=[]\n",
    "for text in textcount_loose['text3 (edits made to fix word counts)']:\n",
    "    uwords=[]\n",
    "    text=str(text).replace('\\n',' ')\n",
    "    nopunc=text.translate(str.maketrans('','',string.punctuation))\n",
    "    nopunc=nopunc.lower()\n",
    "    textcount_loose.at[index,'processed_text']=nopunc\n",
    "    words=nopunc.strip().split(\" \")\n",
    "    for word in words:\n",
    "        if word=='':\n",
    "            words.remove(word)\n",
    "        elif word not in uwords:\n",
    "            uwords.append(word)\n",
    "    textcount_loose.at[index,'text3_len']=len(words)\n",
    "    textcount_loose.at[index,'wordtype_len']=len(uwords)\n",
    "    index+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "textcount_loose.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answer_id</th>\n",
       "      <th>anon_id</th>\n",
       "      <th>L1</th>\n",
       "      <th>level_id</th>\n",
       "      <th>question_id</th>\n",
       "      <th>text3_len</th>\n",
       "      <th>text3 (edits made to fix word counts)</th>\n",
       "      <th>processed_text</th>\n",
       "      <th>wordtype_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>141.0</td>\n",
       "      <td>aj8</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>5.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>Today, I am going to describe one of my classm...</td>\n",
       "      <td>today i am going to describe one of my classma...</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>143.0</td>\n",
       "      <td>az8</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>5.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>My niece is 3 years old who is my younger brot...</td>\n",
       "      <td>my niece is 3 years old who is my younger brot...</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>133.0</td>\n",
       "      <td>az2</td>\n",
       "      <td>Korean</td>\n",
       "      <td>5.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>When I was in Germany, I met a friend who was ...</td>\n",
       "      <td>when i was in germany i met a friend who was f...</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>135.0</td>\n",
       "      <td>at8</td>\n",
       "      <td>Korean</td>\n",
       "      <td>5.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>my friend is ANON_NAME_0. she is a my ELI frie...</td>\n",
       "      <td>my friend is anonname0 she is a my eli friend ...</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>188.0</td>\n",
       "      <td>eh9</td>\n",
       "      <td>Korean</td>\n",
       "      <td>5.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>Younghun is my best friend. His facial appeara...</td>\n",
       "      <td>younghun is my best friend his facial appearan...</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1805</th>\n",
       "      <td>47845.0</td>\n",
       "      <td>ec1</td>\n",
       "      <td>Korean</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6070.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>My best friend is Sohyun who graduated from th...</td>\n",
       "      <td>my best friend is sohyun who graduated from th...</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1806</th>\n",
       "      <td>47882.0</td>\n",
       "      <td>cq1</td>\n",
       "      <td>Spanish</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6070.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>My soul mate is Melissa, who has been my frien...</td>\n",
       "      <td>my soul mate is melissa who has been my friend...</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1807</th>\n",
       "      <td>48246.0</td>\n",
       "      <td>bv8</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6105.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>The quote that talks about a true friend is so...</td>\n",
       "      <td>the quote that talks about a true friend is so...</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1808</th>\n",
       "      <td>48254.0</td>\n",
       "      <td>dr8</td>\n",
       "      <td>Korean</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6105.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>I think this means that home is not just a pla...</td>\n",
       "      <td>i think this means that home is not just a pla...</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1809</th>\n",
       "      <td>48252.0</td>\n",
       "      <td>bl3</td>\n",
       "      <td>Spanish</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6105.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>This quotation means that the majority of peop...</td>\n",
       "      <td>this quotation means that the majority of peop...</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1810 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      answer_id anon_id       L1  level_id  question_id  text3_len  \\\n",
       "0         141.0     aj8  Chinese       5.0         17.0      114.0   \n",
       "1         143.0     az8  Chinese       5.0         17.0       95.0   \n",
       "2         133.0     az2   Korean       5.0         17.0      128.0   \n",
       "3         135.0     at8   Korean       5.0         17.0      105.0   \n",
       "4         188.0     eh9   Korean       5.0         17.0       97.0   \n",
       "...         ...     ...      ...       ...          ...        ...   \n",
       "1805    47845.0     ec1   Korean       4.0       6070.0      138.0   \n",
       "1806    47882.0     cq1  Spanish       4.0       6070.0       80.0   \n",
       "1807    48246.0     bv8  Chinese       4.0       6105.0      131.0   \n",
       "1808    48254.0     dr8   Korean       4.0       6105.0      162.0   \n",
       "1809    48252.0     bl3  Spanish       4.0       6105.0      146.0   \n",
       "\n",
       "                  text3 (edits made to fix word counts)  \\\n",
       "0     Today, I am going to describe one of my classm...   \n",
       "1     My niece is 3 years old who is my younger brot...   \n",
       "2     When I was in Germany, I met a friend who was ...   \n",
       "3     my friend is ANON_NAME_0. she is a my ELI frie...   \n",
       "4     Younghun is my best friend. His facial appeara...   \n",
       "...                                                 ...   \n",
       "1805  My best friend is Sohyun who graduated from th...   \n",
       "1806  My soul mate is Melissa, who has been my frien...   \n",
       "1807  The quote that talks about a true friend is so...   \n",
       "1808  I think this means that home is not just a pla...   \n",
       "1809  This quotation means that the majority of peop...   \n",
       "\n",
       "                                         processed_text wordtype_len  \n",
       "0     today i am going to describe one of my classma...           74  \n",
       "1     my niece is 3 years old who is my younger brot...           67  \n",
       "2     when i was in germany i met a friend who was f...           72  \n",
       "3     my friend is anonname0 she is a my eli friend ...           60  \n",
       "4     younghun is my best friend his facial appearan...           70  \n",
       "...                                                 ...          ...  \n",
       "1805  my best friend is sohyun who graduated from th...           80  \n",
       "1806  my soul mate is melissa who has been my friend...           57  \n",
       "1807  the quote that talks about a true friend is so...           73  \n",
       "1808  i think this means that home is not just a pla...           79  \n",
       "1809  this quotation means that the majority of peop...           93  \n",
       "\n",
       "[1810 rows x 9 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textcount_loose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60, 52, 98)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loose3=textcount_loose.query('level_id==3').reset_index()\n",
    "find_counts(loose3,'L1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>answer_id</th>\n",
       "      <th>anon_id</th>\n",
       "      <th>L1</th>\n",
       "      <th>level_id</th>\n",
       "      <th>question_id</th>\n",
       "      <th>text3_len</th>\n",
       "      <th>text3 (edits made to fix word counts)</th>\n",
       "      <th>processed_text</th>\n",
       "      <th>wordtype_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>62</td>\n",
       "      <td>2579.0</td>\n",
       "      <td>da6</td>\n",
       "      <td>Spanish</td>\n",
       "      <td>3.0</td>\n",
       "      <td>302.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>When I was leaving to the English class in my ...</td>\n",
       "      <td>when i was leaving to the english class in my ...</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>63</td>\n",
       "      <td>2570.0</td>\n",
       "      <td>fo8</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>3.0</td>\n",
       "      <td>302.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>I went to declare to pick up my child yesterda...</td>\n",
       "      <td>i went to declare to pick up my child yesterda...</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>64</td>\n",
       "      <td>2593.0</td>\n",
       "      <td>gv1</td>\n",
       "      <td>Korean</td>\n",
       "      <td>3.0</td>\n",
       "      <td>302.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>While I am going to home, I listened music. Wh...</td>\n",
       "      <td>while i am going to home i listened music when...</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>65</td>\n",
       "      <td>2600.0</td>\n",
       "      <td>aa9</td>\n",
       "      <td>Korean</td>\n",
       "      <td>3.0</td>\n",
       "      <td>302.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>While I was taking the trolley yesterday, I sa...</td>\n",
       "      <td>while i was taking the trolley yesterday i saw...</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>66</td>\n",
       "      <td>2697.0</td>\n",
       "      <td>fv7</td>\n",
       "      <td>Korean</td>\n",
       "      <td>3.0</td>\n",
       "      <td>302.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>I had a reunion with my friens. They were taki...</td>\n",
       "      <td>i had a reunion with my friens they were takin...</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>1750</td>\n",
       "      <td>43550.0</td>\n",
       "      <td>cf6</td>\n",
       "      <td>Korean</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5533.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>There are many reasons to travel. First a fami...</td>\n",
       "      <td>there are many reasons to travel first a famil...</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>1751</td>\n",
       "      <td>43568.0</td>\n",
       "      <td>fb9</td>\n",
       "      <td>Korean</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5533.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>Vacation has many beautiful places. They have ...</td>\n",
       "      <td>vacation has many beautiful places they have m...</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>1752</td>\n",
       "      <td>43629.0</td>\n",
       "      <td>cf1</td>\n",
       "      <td>Korean</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5533.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>Here are some suggestions about becoming healt...</td>\n",
       "      <td>here are some suggestions about becoming healt...</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>1753</td>\n",
       "      <td>43659.0</td>\n",
       "      <td>bm0</td>\n",
       "      <td>Korean</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5533.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>A life in a small town has some disadvantages....</td>\n",
       "      <td>a life in a small town has some disadvantages ...</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>1754</td>\n",
       "      <td>43563.0</td>\n",
       "      <td>aw5</td>\n",
       "      <td>Spanish</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5533.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>All people have ways in common to waste time. ...</td>\n",
       "      <td>all people have ways in common to waste time t...</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>210 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     index  answer_id anon_id       L1  level_id  question_id  text3_len  \\\n",
       "0       62     2579.0     da6  Spanish       3.0        302.0      204.0   \n",
       "1       63     2570.0     fo8  Chinese       3.0        302.0       60.0   \n",
       "2       64     2593.0     gv1   Korean       3.0        302.0       72.0   \n",
       "3       65     2600.0     aa9   Korean       3.0        302.0       60.0   \n",
       "4       66     2697.0     fv7   Korean       3.0        302.0      108.0   \n",
       "..     ...        ...     ...      ...       ...          ...        ...   \n",
       "205   1750    43550.0     cf6   Korean       3.0       5533.0       82.0   \n",
       "206   1751    43568.0     fb9   Korean       3.0       5533.0       60.0   \n",
       "207   1752    43629.0     cf1   Korean       3.0       5533.0      105.0   \n",
       "208   1753    43659.0     bm0   Korean       3.0       5533.0       97.0   \n",
       "209   1754    43563.0     aw5  Spanish       3.0       5533.0      127.0   \n",
       "\n",
       "                 text3 (edits made to fix word counts)  \\\n",
       "0    When I was leaving to the English class in my ...   \n",
       "1    I went to declare to pick up my child yesterda...   \n",
       "2    While I am going to home, I listened music. Wh...   \n",
       "3    While I was taking the trolley yesterday, I sa...   \n",
       "4    I had a reunion with my friens. They were taki...   \n",
       "..                                                 ...   \n",
       "205  There are many reasons to travel. First a fami...   \n",
       "206  Vacation has many beautiful places. They have ...   \n",
       "207  Here are some suggestions about becoming healt...   \n",
       "208  A life in a small town has some disadvantages....   \n",
       "209  All people have ways in common to waste time. ...   \n",
       "\n",
       "                                        processed_text wordtype_len  \n",
       "0    when i was leaving to the english class in my ...           62  \n",
       "1    i went to declare to pick up my child yesterda...           37  \n",
       "2    while i am going to home i listened music when...           47  \n",
       "3    while i was taking the trolley yesterday i saw...           37  \n",
       "4    i had a reunion with my friens they were takin...           70  \n",
       "..                                                 ...          ...  \n",
       "205  there are many reasons to travel first a famil...           55  \n",
       "206  vacation has many beautiful places they have m...           40  \n",
       "207  here are some suggestions about becoming healt...           76  \n",
       "208  a life in a small town has some disadvantages ...           58  \n",
       "209  all people have ways in common to waste time t...           82  \n",
       "\n",
       "[210 rows x 10 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loose3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
