{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Data analysis for Lexical Richness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import os\n",
    "import nltk\n",
    "import re\n",
    "import numpy as np\n",
    "import regex\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "#binary search for strings\n",
    "def binarySearchArr(arr, x):\n",
    "    l = 0\n",
    "    r = len(arr)\n",
    "    while (l <= r):\n",
    "        m = l + ((r - l) // 2)\n",
    " \n",
    "        res = (x == arr[m])\n",
    "        # Check if x is present at mid\n",
    "        if (res == True):\n",
    "            return m\n",
    " \n",
    "        # If x greater, ignore left half\n",
    "    #problem is here\n",
    "        elif (res == False):\n",
    "            if (x>arr[m]):\n",
    "                l = m+1\n",
    "            elif (x<arr[m]):\n",
    "                r=m-1\n",
    "        # If x is smaller, ignore right half\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function removes all of the rows that contain a string in the passed column\n",
    "def rmStr (df, col):\n",
    "    row_index=0\n",
    "    row_ind=[]\n",
    "    for i in df[col]:\n",
    "        try:\n",
    "            int(i)\n",
    "        except:\n",
    "            row_ind.append(row_index)\n",
    "        row_index+=1\n",
    "    return df.drop(labels=row_ind,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that finds the unique values in a list\n",
    "def get_uniques(x):\n",
    "    return list(x.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finds the number of texts per language in the given list of anon_ids\n",
    "def find_counts(df,anon_list,lang_col):\n",
    "    spanish=0\n",
    "    chinese=0\n",
    "    korean=0\n",
    "    index=0\n",
    "    for i in df[\"Number of Questions\"]:\n",
    "        anon_id=str(df.at[index,'anon_id'])\n",
    "        if anon_id in anon_list:\n",
    "            if df.at[index,lang_col]=='Spanish':            \n",
    "                spanish+=i\n",
    "            elif df.at[index,lang_col]=='Chinese':\n",
    "                chinese+=i\n",
    "            elif df.at[index,lang_col]=='Korean':\n",
    "                korean+=i\n",
    "        index+=1\n",
    "    return(spanish,chinese,korean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 637,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anon_id</th>\n",
       "      <th>native_language</th>\n",
       "      <th>Number of Questions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aa0</td>\n",
       "      <td>Spanish</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aa1</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aa3</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aa8</td>\n",
       "      <td>Korean</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aa9</td>\n",
       "      <td>Korean</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>ha0</td>\n",
       "      <td>Korean</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>ha2</td>\n",
       "      <td>Korean</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>ha6</td>\n",
       "      <td>Korean</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>hb4</td>\n",
       "      <td>Korean</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>hc1</td>\n",
       "      <td>Korean</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>476 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    anon_id native_language  Number of Questions\n",
       "0       aa0         Spanish                   17\n",
       "1       aa1         Chinese                   22\n",
       "2       aa3         Chinese                    8\n",
       "3       aa8          Korean                   34\n",
       "4       aa9          Korean                   28\n",
       "..      ...             ...                  ...\n",
       "471     ha0          Korean                    3\n",
       "472     ha2          Korean                   44\n",
       "473     ha6          Korean                   32\n",
       "474     hb4          Korean                   39\n",
       "475     hc1          Korean                    5\n",
       "\n",
       "[476 rows x 3 columns]"
      ]
     },
     "execution_count": 637,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qcount_entire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 642,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finds the number of texts per language in the given list of anon_ids IN SPECIFIED LVL\n",
    "def find_countslvl(df,anon_list,lang_col,lvl,qcounts):\n",
    "    spanish=0\n",
    "    chinese=0\n",
    "    korean=0\n",
    "    index=0\n",
    "    #for i in qcounts[\"Number of Questions\"]:\n",
    "    anon_id=str(df.at[index,'anon_id'])\n",
    "    if (anon_id in anon_list and df.at[index,'level_id']==lvl):\n",
    "        if qcounts.at[index,lang_col]=='Spanish':            \n",
    "            spanish=i\n",
    "        elif qcounts.at[index,lang_col]=='Chinese':\n",
    "            chinese=i\n",
    "        elif qcounts.at[index,lang_col]=='Korean':\n",
    "            korean=i\n",
    "    index+=1\n",
    "    return(spanish,chinese,korean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reference code from previous research, tokinizes essays\n",
    "# NEEDS UPDATING TO FIT CSV FILES\n",
    "\n",
    "#function that does this\n",
    "def calculate_tokens(text):\n",
    "    essay = text\n",
    "\n",
    "        \n",
    "    tokenizer = RegexpTokenizer(r'[0-9a-zA-Z_\\-]+')\n",
    "    tokenized = tokenizer.tokenize(essay)\n",
    "    unique = np.unique(tokenized)\n",
    "    \n",
    "    return {\n",
    "        'total': len(tokenized),\n",
    "        'unique': len(unique)\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that counts the amount of tokens per language FINDS AVERAGE OF ALL LVLS IN SPECIFIED LIST\n",
    "def finding_tokens(df,id_list,lang_col,text_len_col,qcounts):\n",
    "    spanish=0\n",
    "    korean=0\n",
    "    chinese=0\n",
    "    index=0\n",
    "    lspanish,lchinese,lkorean=find_counts(qcounts, id_list,lang_col)\n",
    "\n",
    "    for i in df['anon_id']:\n",
    "        if i in id_list:\n",
    "            lang=df.at[index,lang_col]\n",
    "            length=int(df.at[index,text_len_col])\n",
    "            if lang=='Spanish':\n",
    "                spanish+=length\n",
    "            elif lang=='Korean':\n",
    "                korean+=length\n",
    "            elif lang=='Chinese':\n",
    "                chinese+=length\n",
    "        index+=1\n",
    "   # print('Spanish Token Average: ',spanish,'\\nKorean Token Average: ',korean,\n",
    "    #      '\\nChinese Token Average:',chinese)\n",
    "    print('Spanish Token Average: ',spanish/lspanish,'\\nKorean Token Average: ',korean/lkorean,\n",
    "          '\\nChinese Token Average:',chinese/lchinese)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 618,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lspanish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "illegal expression for augmented assignment (<ipython-input-643-5996aa01f3ad>, line 11)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-643-5996aa01f3ad>\"\u001b[1;36m, line \u001b[1;32m11\u001b[0m\n\u001b[1;33m    lspanish,lchinese,lkorean+=find_countslvl(df, id_list,lang_col,lvl,qcounts,index)\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m illegal expression for augmented assignment\n"
     ]
    }
   ],
   "source": [
    "# function that counts the amount of tokens per language FINDS AVERAGE OF SPECIFIED LEVEL IN LIST\n",
    "def finding_tokens_lvl(df,id_list,lang_col,text_len_col,lvl,qcounts):\n",
    "    spanish=0\n",
    "    korean=0\n",
    "    chinese=0\n",
    "    index=0\n",
    "    lspanish,lchinese,lkorean=0\n",
    "\n",
    "    for i in df['anon_id']:\n",
    "        if i in id_list:\n",
    "            lspanish,lchinese,lkorean+=find_countslvl(df, id_list,lang_col,lvl,qcounts,index)\n",
    "\n",
    "            lang=df.at[index,lang_col]\n",
    "            length=int(df.at[index,text_len_col])\n",
    "            if (df.at[index,'level_id']==lvl):\n",
    "                if lang=='Spanish':\n",
    "                    spanish+=length\n",
    "                elif lang=='Korean':\n",
    "                    korean+=length\n",
    "                elif lang=='Chinese':\n",
    "                    chinese+=length\n",
    "        index+=1\n",
    "    print('Spanish Token Average: ',spanish/lspanish,'\\nKorean Token Average: ',korean/lkorean,\n",
    "          '\\nChinese Token Average:',chinese/lchinese)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding DFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "loose=pd.read_csv('original-sheets\\Responses-Loose.csv')\n",
    "student_info=pd.read_csv('corpus-files\\student_information.csv')\n",
    "course=pd.read_csv('corpus-files\\course.csv')\n",
    "answer_df=pd.read_csv('answer.csv',index_col = 'answer_id', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "course_=course.drop(columns=['class_id','semester','section'])\n",
    "\n",
    "student=student_info.drop(columns=['birth_year','language_used_at_home','non_native_language_1','yrs_of_study_lang1',\n",
    "                                  'study_in_classroom_lang1','ways_of_study_lang1','non_native_language_2','study_in_classroom_lang2',\n",
    "                                  'ways_of_study_lang2','non_native_language_3','yrs_of_study_lang3','study_in_classroom_lang3',\n",
    "                                  'ways_of_study_lang3','yrs_of_english_learning','yrs_in_english_environment','yrs_of_study_lang2'])\n",
    "answer_=answer_df[['question_id','anon_id','course_id','version','text_len','text','tokens']].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>3Langs</th>\n",
       "      <th>Item</th>\n",
       "      <th>answer_id</th>\n",
       "      <th>anon_id</th>\n",
       "      <th>L1</th>\n",
       "      <th>gender</th>\n",
       "      <th>course_id</th>\n",
       "      <th>level_id</th>\n",
       "      <th>class_id</th>\n",
       "      <th>question_id</th>\n",
       "      <th>version</th>\n",
       "      <th>text1_len</th>\n",
       "      <th>text2_len</th>\n",
       "      <th>text3_len</th>\n",
       "      <th>text1</th>\n",
       "      <th>text2 (line breaks/extra spaces removed, spaces added to reach 60)</th>\n",
       "      <th>text3 (edits made to fix word counts)</th>\n",
       "      <th>Judgement</th>\n",
       "      <th>Notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Y</td>\n",
       "      <td>C12</td>\n",
       "      <td>141.0</td>\n",
       "      <td>aj8</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>Male</td>\n",
       "      <td>118.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>w</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>\\n\\n\\n Today, I am going to describe one of my...</td>\n",
       "      <td>Today, I am going to describe one of my classm...</td>\n",
       "      <td>Today, I am going to describe one of my classm...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Y</td>\n",
       "      <td>C13</td>\n",
       "      <td>143.0</td>\n",
       "      <td>az8</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>Female</td>\n",
       "      <td>118.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>w</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>My niece is 3 years old who is my younger brot...</td>\n",
       "      <td>My niece is 3 years old who is my younger brot...</td>\n",
       "      <td>My niece is 3 years old who is my younger brot...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Y</td>\n",
       "      <td>K9</td>\n",
       "      <td>133.0</td>\n",
       "      <td>az2</td>\n",
       "      <td>Korean</td>\n",
       "      <td>Male</td>\n",
       "      <td>118.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>w</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>When I was in Germany, I met a friend who was ...</td>\n",
       "      <td>When I was in Germany, I met a friend who was ...</td>\n",
       "      <td>When I was in Germany, I met a friend who was ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Y</td>\n",
       "      <td>K11</td>\n",
       "      <td>135.0</td>\n",
       "      <td>at8</td>\n",
       "      <td>Korean</td>\n",
       "      <td>Female</td>\n",
       "      <td>118.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>w</td>\n",
       "      <td>17.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>my friend is ANON_NAME_0. she is a my ELI frie...</td>\n",
       "      <td>my friend is ANON_NAME_0. she is a my ELI frie...</td>\n",
       "      <td>my friend is ANON_NAME_0. she is a my ELI frie...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Y</td>\n",
       "      <td>K20</td>\n",
       "      <td>188.0</td>\n",
       "      <td>eh9</td>\n",
       "      <td>Korean</td>\n",
       "      <td>Male</td>\n",
       "      <td>118.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>w</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>Younghun is my best friend. His facial appeara...</td>\n",
       "      <td>Younghun is my best friend. His facial appeara...</td>\n",
       "      <td>Younghun is my best friend. His facial appeara...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  3Langs Item  answer_id anon_id       L1  gender  course_id  level_id  \\\n",
       "0      Y  C12      141.0     aj8  Chinese    Male      118.0       5.0   \n",
       "1      Y  C13      143.0     az8  Chinese  Female      118.0       5.0   \n",
       "2      Y   K9      133.0     az2   Korean    Male      118.0       5.0   \n",
       "3      Y  K11      135.0     at8   Korean  Female      118.0       5.0   \n",
       "4      Y  K20      188.0     eh9   Korean    Male      118.0       5.0   \n",
       "\n",
       "  class_id  question_id  version  text1_len  text2_len  text3_len  \\\n",
       "0        w         17.0      1.0      121.0      114.0      114.0   \n",
       "1        w         17.0      1.0       96.0       95.0       95.0   \n",
       "2        w         17.0      1.0      130.0      128.0      128.0   \n",
       "3        w         17.0      3.0      104.0      105.0      105.0   \n",
       "4        w         17.0      1.0       98.0       97.0       97.0   \n",
       "\n",
       "                                               text1  \\\n",
       "0  \\n\\n\\n Today, I am going to describe one of my...   \n",
       "1  My niece is 3 years old who is my younger brot...   \n",
       "2  When I was in Germany, I met a friend who was ...   \n",
       "3  my friend is ANON_NAME_0. she is a my ELI frie...   \n",
       "4  Younghun is my best friend. His facial appeara...   \n",
       "\n",
       "  text2 (line breaks/extra spaces removed, spaces added to reach 60)  \\\n",
       "0  Today, I am going to describe one of my classm...                   \n",
       "1  My niece is 3 years old who is my younger brot...                   \n",
       "2  When I was in Germany, I met a friend who was ...                   \n",
       "3  my friend is ANON_NAME_0. she is a my ELI frie...                   \n",
       "4  Younghun is my best friend. His facial appeara...                   \n",
       "\n",
       "               text3 (edits made to fix word counts)  Judgement Notes  \n",
       "0  Today, I am going to describe one of my classm...        1.0   NaN  \n",
       "1  My niece is 3 years old who is my younger brot...        1.0   NaN  \n",
       "2  When I was in Germany, I met a friend who was ...        1.0   NaN  \n",
       "3  my friend is ANON_NAME_0. she is a my ELI frie...        1.0   NaN  \n",
       "4  Younghun is my best friend. His facial appeara...        1.0   NaN  "
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loose.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleaning the answer df\n",
    "col='course_id'\n",
    "answer=rmStr(answer_, col) #removes strings from answer_.course_id "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging the datasets\n",
    "\n",
    "merge_ans=answer[['anon_id','course_id']] #sets answer df up for merging \n",
    "student_merge=student.drop(columns=['course_history']) #set student df up for merging\n",
    "\n",
    "student_ans=student_merge.merge(answer,on='anon_id').astype({'course_id':'int64'}) #merges student and answers\n",
    "\n",
    "stu_ans_crs_=student_ans.merge(course_, on='course_id') #merges the student-answers df with course df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anon_id</th>\n",
       "      <th>gender</th>\n",
       "      <th>native_language</th>\n",
       "      <th>age</th>\n",
       "      <th>answer_id</th>\n",
       "      <th>question_id</th>\n",
       "      <th>course_id</th>\n",
       "      <th>version</th>\n",
       "      <th>text_len</th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>level_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>do6</td>\n",
       "      <td>Female</td>\n",
       "      <td>Russian</td>\n",
       "      <td>31.0</td>\n",
       "      <td>150</td>\n",
       "      <td>4</td>\n",
       "      <td>117</td>\n",
       "      <td>1</td>\n",
       "      <td>299</td>\n",
       "      <td>Some people prefer eat out and some like doing...</td>\n",
       "      <td>['Some', 'people', 'prefer', 'eat', 'out', 'an...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>do6</td>\n",
       "      <td>Female</td>\n",
       "      <td>Russian</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1221</td>\n",
       "      <td>97</td>\n",
       "      <td>117</td>\n",
       "      <td>1</td>\n",
       "      <td>288</td>\n",
       "      <td>My opinion is that a person does need educatio...</td>\n",
       "      <td>['My', 'opinion', 'is', 'that', 'a', 'person',...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>do6</td>\n",
       "      <td>Female</td>\n",
       "      <td>Russian</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1957</td>\n",
       "      <td>189</td>\n",
       "      <td>117</td>\n",
       "      <td>1</td>\n",
       "      <td>321</td>\n",
       "      <td>There are two national rooms in the Cathedral ...</td>\n",
       "      <td>['There', 'are', 'two', 'national', 'rooms', '...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>do6</td>\n",
       "      <td>Female</td>\n",
       "      <td>Russian</td>\n",
       "      <td>31.0</td>\n",
       "      <td>2164</td>\n",
       "      <td>190</td>\n",
       "      <td>117</td>\n",
       "      <td>1</td>\n",
       "      <td>464</td>\n",
       "      <td>There are two nation rooms in the Cathedral of...</td>\n",
       "      <td>['There', 'are', 'two', 'nation', 'rooms', 'in...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bv5</td>\n",
       "      <td>Male</td>\n",
       "      <td>Arabic</td>\n",
       "      <td>21.0</td>\n",
       "      <td>151</td>\n",
       "      <td>4</td>\n",
       "      <td>117</td>\n",
       "      <td>1</td>\n",
       "      <td>315</td>\n",
       "      <td>\"Not all learning takes place in the classroom...</td>\n",
       "      <td>['``', 'Not', 'all', 'learning', 'takes', 'pla...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46225</th>\n",
       "      <td>cy7</td>\n",
       "      <td>Female</td>\n",
       "      <td>Korean</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47682</td>\n",
       "      <td>6066</td>\n",
       "      <td>1034</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1. emphasis\\n2. appropriate\\n3. requires\\n4. a...</td>\n",
       "      <td>['1', '.', 'emphasis', '2', '.', 'appropriate'...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46226</th>\n",
       "      <td>fp7</td>\n",
       "      <td>Female</td>\n",
       "      <td>Turkish</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47823</td>\n",
       "      <td>6066</td>\n",
       "      <td>1034</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1.emphasis \\n2.appropriate\\n3.requires\\n4.anal...</td>\n",
       "      <td>['1', '.', 'emphasis', '2', '.', 'appropriate'...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46227</th>\n",
       "      <td>fq6</td>\n",
       "      <td>Male</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47824</td>\n",
       "      <td>6066</td>\n",
       "      <td>1034</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1.emphasis\\n2.appropriate\\n3.requires\\n4.analy...</td>\n",
       "      <td>['1', '.', 'emphasis', '2', '.', 'appropriate'...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46228</th>\n",
       "      <td>di6</td>\n",
       "      <td>Male</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47787</td>\n",
       "      <td>6066</td>\n",
       "      <td>1034</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1 emphasis\\n2 normal\\n3 requires\\n4 analyze\\n5...</td>\n",
       "      <td>['1', 'emphasis', '2', 'normal', '3', 'require...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46229</th>\n",
       "      <td>fm3</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Arabic</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47725</td>\n",
       "      <td>6066</td>\n",
       "      <td>1034</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1- emphasis\\n2- appropriate\\n3- requires\\n4- a...</td>\n",
       "      <td>['1', '-', 'emphasis', '2', '-', 'appropriate'...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>46230 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      anon_id   gender native_language   age answer_id question_id  course_id  \\\n",
       "0         do6   Female         Russian  31.0       150           4        117   \n",
       "1         do6   Female         Russian  31.0      1221          97        117   \n",
       "2         do6   Female         Russian  31.0      1957         189        117   \n",
       "3         do6   Female         Russian  31.0      2164         190        117   \n",
       "4         bv5     Male          Arabic  21.0       151           4        117   \n",
       "...       ...      ...             ...   ...       ...         ...        ...   \n",
       "46225     cy7   Female          Korean   NaN     47682        6066       1034   \n",
       "46226     fp7   Female         Turkish   NaN     47823        6066       1034   \n",
       "46227     fq6     Male         Chinese   NaN     47824        6066       1034   \n",
       "46228     di6     Male         Chinese   NaN     47787        6066       1034   \n",
       "46229     fm3  Unknown          Arabic   NaN     47725        6066       1034   \n",
       "\n",
       "      version text_len                                               text  \\\n",
       "0           1      299  Some people prefer eat out and some like doing...   \n",
       "1           1      288  My opinion is that a person does need educatio...   \n",
       "2           1      321  There are two national rooms in the Cathedral ...   \n",
       "3           1      464  There are two nation rooms in the Cathedral of...   \n",
       "4           1      315  \"Not all learning takes place in the classroom...   \n",
       "...       ...      ...                                                ...   \n",
       "46225       1       10  1. emphasis\\n2. appropriate\\n3. requires\\n4. a...   \n",
       "46226       1       10  1.emphasis \\n2.appropriate\\n3.requires\\n4.anal...   \n",
       "46227       1       10  1.emphasis\\n2.appropriate\\n3.requires\\n4.analy...   \n",
       "46228       1       10  1 emphasis\\n2 normal\\n3 requires\\n4 analyze\\n5...   \n",
       "46229       1       10  1- emphasis\\n2- appropriate\\n3- requires\\n4- a...   \n",
       "\n",
       "                                                  tokens  level_id  \n",
       "0      ['Some', 'people', 'prefer', 'eat', 'out', 'an...         5  \n",
       "1      ['My', 'opinion', 'is', 'that', 'a', 'person',...         5  \n",
       "2      ['There', 'are', 'two', 'national', 'rooms', '...         5  \n",
       "3      ['There', 'are', 'two', 'nation', 'rooms', 'in...         5  \n",
       "4      ['``', 'Not', 'all', 'learning', 'takes', 'pla...         5  \n",
       "...                                                  ...       ...  \n",
       "46225  ['1', '.', 'emphasis', '2', '.', 'appropriate'...         3  \n",
       "46226  ['1', '.', 'emphasis', '2', '.', 'appropriate'...         3  \n",
       "46227  ['1', '.', 'emphasis', '2', '.', 'appropriate'...         3  \n",
       "46228  ['1', 'emphasis', '2', 'normal', '3', 'require...         3  \n",
       "46229  ['1', '-', 'emphasis', '2', '-', 'appropriate'...         3  \n",
       "\n",
       "[46230 rows x 12 columns]"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stu_ans_crs_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning Answers in Whole Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#dropping all rows where the answer is less than 60 words\n",
    "index=0\n",
    "ind_list=[]\n",
    "for i in stu_ans_crs_.text_len:\n",
    "    txtlen=int(i)\n",
    "    if txtlen < 60:\n",
    "        ind_list.append(index)\n",
    "    index+=1\n",
    "\n",
    "stu_ans_crs_=stu_ans_crs_.drop(labels=ind_list,axis=0).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding spaces after punctuation if needed\n",
    "index=0\n",
    "stu_ans_crs=stu_ans_crs_.copy()\n",
    "for text in testing.text:    \n",
    "    stu_ans_crs.at[index,'text']=re.sub(r'(?<=[.,!?)\\n])(?=[^\\s])', r' ', text)\n",
    "    index+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before adding spaces:\n",
      " In my country we usually don't use tea bags. First we boil the water,then we put some of the hot water at the top.We add the tea at the top. We wait like 20 minutes with low heat for it to be ready.At last, we first poor the water with tea,then we add some pure hot water in it. \n",
      "\n",
      "After adding spaces:\n",
      " In my country we usually don't use tea bags. First we boil the water, then we put some of the hot water at the top. We add the tea at the top. We wait like 20 minutes with low heat for it to be ready. At last, we first poor the water with tea, then we add some pure hot water in it.\n"
     ]
    }
   ],
   "source": [
    "print('Before adding spaces:\\n',stu_ans_crs_.at[690,'text'],'\\n')\n",
    "print('After adding spaces:\\n',stu_ans_crs.at[690,'text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['In',\n",
       " 'my',\n",
       " 'country',\n",
       " 'we',\n",
       " 'usually',\n",
       " 'do',\n",
       " \"n't\",\n",
       " 'use',\n",
       " 'tea',\n",
       " 'bags',\n",
       " '.',\n",
       " 'First',\n",
       " 'we',\n",
       " 'boil',\n",
       " 'the',\n",
       " 'water',\n",
       " ',',\n",
       " 'then',\n",
       " 'we',\n",
       " 'put',\n",
       " 'some',\n",
       " 'of',\n",
       " 'the',\n",
       " 'hot',\n",
       " 'water',\n",
       " 'at',\n",
       " 'the',\n",
       " 'top',\n",
       " '.',\n",
       " 'We',\n",
       " 'add',\n",
       " 'the',\n",
       " 'tea',\n",
       " 'at',\n",
       " 'the',\n",
       " 'top',\n",
       " '.',\n",
       " 'We',\n",
       " 'wait',\n",
       " 'like',\n",
       " '20',\n",
       " 'minutes',\n",
       " 'with',\n",
       " 'low',\n",
       " 'heat',\n",
       " 'for',\n",
       " 'it',\n",
       " 'to',\n",
       " 'be',\n",
       " 'ready',\n",
       " '.',\n",
       " 'At',\n",
       " 'last',\n",
       " ',',\n",
       " 'we',\n",
       " 'first',\n",
       " 'poor',\n",
       " 'the',\n",
       " 'water',\n",
       " 'with',\n",
       " 'tea',\n",
       " ',',\n",
       " 'then',\n",
       " 'we',\n",
       " 'add',\n",
       " 'some',\n",
       " 'pure',\n",
       " 'hot',\n",
       " 'water',\n",
       " 'in',\n",
       " 'it',\n",
       " '.']"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(stu_ans_crs.at[690,'text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>anon_id</th>\n",
       "      <th>gender</th>\n",
       "      <th>native_language</th>\n",
       "      <th>age</th>\n",
       "      <th>answer_id</th>\n",
       "      <th>question_id</th>\n",
       "      <th>course_id</th>\n",
       "      <th>version</th>\n",
       "      <th>text_len</th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>level_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>do6</td>\n",
       "      <td>Female</td>\n",
       "      <td>Russian</td>\n",
       "      <td>31.0</td>\n",
       "      <td>150</td>\n",
       "      <td>4</td>\n",
       "      <td>117</td>\n",
       "      <td>1</td>\n",
       "      <td>299</td>\n",
       "      <td>Some people prefer eat out and some like doing...</td>\n",
       "      <td>['Some', 'people', 'prefer', 'eat', 'out', 'an...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>do6</td>\n",
       "      <td>Female</td>\n",
       "      <td>Russian</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1221</td>\n",
       "      <td>97</td>\n",
       "      <td>117</td>\n",
       "      <td>1</td>\n",
       "      <td>288</td>\n",
       "      <td>My opinion is that a person does need educatio...</td>\n",
       "      <td>['My', 'opinion', 'is', 'that', 'a', 'person',...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>do6</td>\n",
       "      <td>Female</td>\n",
       "      <td>Russian</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1957</td>\n",
       "      <td>189</td>\n",
       "      <td>117</td>\n",
       "      <td>1</td>\n",
       "      <td>317</td>\n",
       "      <td>There are two national rooms in the Cathedral ...</td>\n",
       "      <td>['There', 'are', 'two', 'national', 'rooms', '...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>do6</td>\n",
       "      <td>Female</td>\n",
       "      <td>Russian</td>\n",
       "      <td>31.0</td>\n",
       "      <td>2164</td>\n",
       "      <td>190</td>\n",
       "      <td>117</td>\n",
       "      <td>1</td>\n",
       "      <td>459</td>\n",
       "      <td>There are two nation rooms in the Cathedral of...</td>\n",
       "      <td>['There', 'are', 'two', 'nation', 'rooms', 'in...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>bv5</td>\n",
       "      <td>Male</td>\n",
       "      <td>Arabic</td>\n",
       "      <td>21.0</td>\n",
       "      <td>151</td>\n",
       "      <td>4</td>\n",
       "      <td>117</td>\n",
       "      <td>1</td>\n",
       "      <td>308</td>\n",
       "      <td>\"Not all learning takes place in the classroom...</td>\n",
       "      <td>['``', 'Not', 'all', 'learning', 'takes', 'pla...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17252</th>\n",
       "      <td>46214</td>\n",
       "      <td>bh8</td>\n",
       "      <td>Male</td>\n",
       "      <td>Japanese</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48034</td>\n",
       "      <td>6087</td>\n",
       "      <td>1033</td>\n",
       "      <td>1</td>\n",
       "      <td>107</td>\n",
       "      <td>I received my Medical Doctor license in Japan ...</td>\n",
       "      <td>['I', 'received', 'my', 'Medical', 'Doctor', '...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17253</th>\n",
       "      <td>46215</td>\n",
       "      <td>bh8</td>\n",
       "      <td>Male</td>\n",
       "      <td>Japanese</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48293</td>\n",
       "      <td>6119</td>\n",
       "      <td>1033</td>\n",
       "      <td>1</td>\n",
       "      <td>138</td>\n",
       "      <td>I introduce my ideal home to you quickly. This...</td>\n",
       "      <td>['I', 'introduce', 'my', 'ideal', 'home', 'to'...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17254</th>\n",
       "      <td>46217</td>\n",
       "      <td>cz3</td>\n",
       "      <td>Female</td>\n",
       "      <td>Korean</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47451</td>\n",
       "      <td>6027</td>\n",
       "      <td>1033</td>\n",
       "      <td>1</td>\n",
       "      <td>102</td>\n",
       "      <td>I will put 5 items in time capsule such as som...</td>\n",
       "      <td>['I', 'will', 'put', '5', 'items', 'in', 'time...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17255</th>\n",
       "      <td>46218</td>\n",
       "      <td>cz3</td>\n",
       "      <td>Female</td>\n",
       "      <td>Korean</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48001</td>\n",
       "      <td>6087</td>\n",
       "      <td>1033</td>\n",
       "      <td>1</td>\n",
       "      <td>104</td>\n",
       "      <td>I have studied Visual Design since 2002. I gra...</td>\n",
       "      <td>['I', 'have', 'studied', 'Visual', 'Design', '...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17256</th>\n",
       "      <td>46219</td>\n",
       "      <td>cz3</td>\n",
       "      <td>Female</td>\n",
       "      <td>Korean</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48316</td>\n",
       "      <td>6119</td>\n",
       "      <td>1033</td>\n",
       "      <td>1</td>\n",
       "      <td>71</td>\n",
       "      <td>I will describe about my ideal home. I want qu...</td>\n",
       "      <td>['I', 'will', 'describe', 'about', 'my', 'idea...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17257 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index anon_id  gender native_language   age answer_id question_id  \\\n",
       "0          0     do6  Female         Russian  31.0       150           4   \n",
       "1          1     do6  Female         Russian  31.0      1221          97   \n",
       "2          2     do6  Female         Russian  31.0      1957         189   \n",
       "3          3     do6  Female         Russian  31.0      2164         190   \n",
       "4          4     bv5    Male          Arabic  21.0       151           4   \n",
       "...      ...     ...     ...             ...   ...       ...         ...   \n",
       "17252  46214     bh8    Male        Japanese   NaN     48034        6087   \n",
       "17253  46215     bh8    Male        Japanese   NaN     48293        6119   \n",
       "17254  46217     cz3  Female          Korean   NaN     47451        6027   \n",
       "17255  46218     cz3  Female          Korean   NaN     48001        6087   \n",
       "17256  46219     cz3  Female          Korean   NaN     48316        6119   \n",
       "\n",
       "       course_id version text_len  \\\n",
       "0            117       1      299   \n",
       "1            117       1      288   \n",
       "2            117       1      317   \n",
       "3            117       1      459   \n",
       "4            117       1      308   \n",
       "...          ...     ...      ...   \n",
       "17252       1033       1      107   \n",
       "17253       1033       1      138   \n",
       "17254       1033       1      102   \n",
       "17255       1033       1      104   \n",
       "17256       1033       1       71   \n",
       "\n",
       "                                                    text  \\\n",
       "0      Some people prefer eat out and some like doing...   \n",
       "1      My opinion is that a person does need educatio...   \n",
       "2      There are two national rooms in the Cathedral ...   \n",
       "3      There are two nation rooms in the Cathedral of...   \n",
       "4      \"Not all learning takes place in the classroom...   \n",
       "...                                                  ...   \n",
       "17252  I received my Medical Doctor license in Japan ...   \n",
       "17253  I introduce my ideal home to you quickly. This...   \n",
       "17254  I will put 5 items in time capsule such as som...   \n",
       "17255  I have studied Visual Design since 2002. I gra...   \n",
       "17256  I will describe about my ideal home. I want qu...   \n",
       "\n",
       "                                                  tokens  level_id  \n",
       "0      ['Some', 'people', 'prefer', 'eat', 'out', 'an...         5  \n",
       "1      ['My', 'opinion', 'is', 'that', 'a', 'person',...         5  \n",
       "2      ['There', 'are', 'two', 'national', 'rooms', '...         5  \n",
       "3      ['There', 'are', 'two', 'nation', 'rooms', 'in...         5  \n",
       "4      ['``', 'Not', 'all', 'learning', 'takes', 'pla...         5  \n",
       "...                                                  ...       ...  \n",
       "17252  ['I', 'received', 'my', 'Medical', 'Doctor', '...         3  \n",
       "17253  ['I', 'introduce', 'my', 'ideal', 'home', 'to'...         3  \n",
       "17254  ['I', 'will', 'put', '5', 'items', 'in', 'time...         3  \n",
       "17255  ['I', 'have', 'studied', 'Visual', 'Design', '...         3  \n",
       "17256  ['I', 'will', 'describe', 'about', 'my', 'idea...         3  \n",
       "\n",
       "[17257 rows x 13 columns]"
      ]
     },
     "execution_count": 430,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index=0\n",
    "for text in stu_ans_crs.text:   \n",
    "    words=text.strip().split(\" \")  #creates a list of each word in the text by seperating them whenever there is a space\n",
    "    for word in words:\n",
    "        if word=='\\n': #sometimes it counted \\n as a word, so this just gets rid of instances of that if it happens\n",
    "            words.remove(word)\n",
    "    stu_ans_crs.at[index,'text_len']=len(words) #changes the text_len column to include the fixed word counts\n",
    "    index+=1\n",
    "stu_ans_crs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Ids of participants in all three of Whole Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [],
   "source": [
    "sac_lvls=stu_ans_crs[['anon_id','native_language','level_id']]\n",
    "sac_lvls_rkc=sac_lvls\n",
    "\n",
    "index=0\n",
    "for i in sac_lvls_rkc.native_language:\n",
    "    if (i != 'Korean' and i != 'Spanish' and i != 'Chinese'):\n",
    "        sac_lvls_rkc=sac_lvls_rkc.drop(index)\n",
    "    index+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anon_id</th>\n",
       "      <th>native_language</th>\n",
       "      <th>level_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ax4</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ax4</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ax4</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ax4</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ax4</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17243</th>\n",
       "      <td>ew6</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17244</th>\n",
       "      <td>ew6</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17254</th>\n",
       "      <td>cz3</td>\n",
       "      <td>Korean</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17255</th>\n",
       "      <td>cz3</td>\n",
       "      <td>Korean</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17256</th>\n",
       "      <td>cz3</td>\n",
       "      <td>Korean</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7629 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      anon_id native_language  level_id\n",
       "13        ax4         Chinese         5\n",
       "14        ax4         Chinese         5\n",
       "15        ax4         Chinese         5\n",
       "16        ax4         Chinese         5\n",
       "17        ax4         Chinese         5\n",
       "...       ...             ...       ...\n",
       "17243     ew6         Chinese         3\n",
       "17244     ew6         Chinese         3\n",
       "17254     cz3          Korean         3\n",
       "17255     cz3          Korean         3\n",
       "17256     cz3          Korean         3\n",
       "\n",
       "[7629 rows x 3 columns]"
      ]
     },
     "execution_count": 432,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sac_lvls_rkc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [],
   "source": [
    "# allows us to see what levels each anon_id participated in \n",
    "lvl_list=sac_lvls_rkc.groupby('anon_id').agg(n_uniq=('level_id','nunique'), lvl_nums=('level_id',get_uniques))\n",
    "lvl_list=lvl_list.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anon_id</th>\n",
       "      <th>n_uniq</th>\n",
       "      <th>lvl_nums</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aa0</td>\n",
       "      <td>1</td>\n",
       "      <td>[5]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aa1</td>\n",
       "      <td>1</td>\n",
       "      <td>[4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aa3</td>\n",
       "      <td>1</td>\n",
       "      <td>[4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aa8</td>\n",
       "      <td>2</td>\n",
       "      <td>[5, 4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aa9</td>\n",
       "      <td>3</td>\n",
       "      <td>[3, 4, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>ha0</td>\n",
       "      <td>1</td>\n",
       "      <td>[5]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>ha2</td>\n",
       "      <td>2</td>\n",
       "      <td>[5, 4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>ha6</td>\n",
       "      <td>2</td>\n",
       "      <td>[3, 4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>hb4</td>\n",
       "      <td>3</td>\n",
       "      <td>[5, 4, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>hc1</td>\n",
       "      <td>1</td>\n",
       "      <td>[5]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>476 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    anon_id  n_uniq   lvl_nums\n",
       "0       aa0       1        [5]\n",
       "1       aa1       1        [4]\n",
       "2       aa3       1        [4]\n",
       "3       aa8       2     [5, 4]\n",
       "4       aa9       3  [3, 4, 2]\n",
       "..      ...     ...        ...\n",
       "471     ha0       1        [5]\n",
       "472     ha2       2     [5, 4]\n",
       "473     ha6       2     [3, 4]\n",
       "474     hb4       3  [5, 4, 3]\n",
       "475     hc1       1        [5]\n",
       "\n",
       "[476 rows x 3 columns]"
      ]
     },
     "execution_count": 434,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lvl_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 438,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# will create a list of only the ids that have levels 3, 4, and 5 in their lvl_nums column\n",
    "all_three=[]\n",
    "ind=0\n",
    "for i in lvl_list.anon_id:\n",
    "    if ((3 in lvl_list.iat[ind,2]) and (4 in lvl_list.iat[ind,2]) and (5 in lvl_list.iat[ind,2])):\n",
    "        append=lvl_list.at[ind, 'anon_id']\n",
    "        all_three.append(append)\n",
    "    ind+=1\n",
    "\n",
    "all_three.sort()\n",
    "len(all_three)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_anon=[]\n",
    "for i in sac_lvls_rkc.anon_id:\n",
    "    all_anon.append(i)\n",
    "len(all_anon)\n",
    "all_anon.sort()\n",
    "\n",
    "sorted_sac=sac_lvls_rkc.sort_values(by=['anon_id']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Korean': ['ag9', 'an5', 'as0', 'ay1', 'be7', 'bv9', 'bz5', 'cc4', 'cj8', 'co5', 'cv3', 'cw0', 'ea4', 'eq8', 'es9', 'fj7', 'fp5', 'fu6', 'gc2', 'gq8', 'gz2', 'hb4'], 'Chinese': ['aq1', 'ar8', 'bf7', 'bl4', 'bl7', 'bp4', 'bz2', 'cb3', 'cf9', 'cz4', 'dk6', 'ev9', 'fi1', 'fj4', 'gb4', 'gx5'], 'Spanish': ['bj2', 'cm9', 'fa2', 'fy1']}\n"
     ]
    }
   ],
   "source": [
    "lang_dict_all={}\n",
    "for i in all_three:\n",
    "    df_ind=binarySearchArr(all_anon,i)\n",
    "    key=sorted_sac.at[df_ind,'native_language']\n",
    "    val=sorted_sac.at[df_ind,'anon_id']\n",
    "    \n",
    "    if key in lang_dict_all:\n",
    "        lang_dict_all[key].append(val)\n",
    "    else:\n",
    "        lang_dict_all[key]=[val]\n",
    "    \n",
    "print(lang_dict_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "111"
      ]
     },
     "execution_count": 441,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# will create a list of only the ids that have levels 3 and 4 in their lvl_nums column\n",
    "lvls34=[]\n",
    "ind=0\n",
    "for i in lvl_list.anon_id:\n",
    "    if ((3 in lvl_list.iat[ind,2]) and (4 in lvl_list.iat[ind,2])):\n",
    "        append=lvl_list.at[ind, 'anon_id']\n",
    "        lvls34.append(append)\n",
    "    ind+=1\n",
    "\n",
    "lvls34.sort()\n",
    "len(lvls34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Korean': ['aa9', 'af1', 'ag9', 'ah9', 'an4', 'an5', 'as0', 'as4', 'ay1', 'bc0', 'be2', 'be7', 'bf1', 'bm0', 'br5', 'bv9', 'bz5', 'ca6', 'cc4', 'cf6', 'ch9', 'cj8', 'cn3', 'co5', 'cv3', 'cw0', 'cw6', 'cy5', 'dd1', 'dj6', 'dp5', 'ea4', 'ef4', 'eo2', 'eq8', 'es9', 'et1', 'ex0', 'fc9', 'fh7', 'fi4', 'fj7', 'fk1', 'fl4', 'fl5', 'fo3', 'fp5', 'fp9', 'fu6', 'fv7', 'fv9', 'gb7', 'gc2', 'gd1', 'gl4', 'gq8', 'gv1', 'gz2', 'ha6', 'hb4'], 'Chinese': ['ag6', 'ai4', 'ap5', 'ap8', 'aq1', 'ar8', 'ax7', 'ba3', 'bf7', 'bl4', 'bl7', 'bp4', 'bu9', 'bz2', 'cb3', 'cf9', 'cl2', 'cl6', 'cq2', 'cs5', 'cz4', 'dk6', 'dl8', 'dm4', 'do7', 'dp1', 'dt4', 'dx1', 'eb6', 'ev5', 'ev9', 'ey8', 'ff6', 'fi1', 'fj4', 'fm2', 'fn8', 'fy3', 'gb4', 'gw5', 'gw8', 'gx5'], 'Spanish': ['bj2', 'ch0', 'cm9', 'en3', 'fa2', 'fe7', 'fg7', 'fy1', 'fy6']}\n"
     ]
    }
   ],
   "source": [
    "lang_dict_34={}\n",
    "for i in lvls34:\n",
    "    df_ind=binarySearchArr(all_anon,i)\n",
    "    key=sorted_sac.at[df_ind,'native_language']\n",
    "    val=sorted_sac.at[df_ind,'anon_id']\n",
    "    \n",
    "    if key in lang_dict_34:\n",
    "        lang_dict_34[key].append(val)\n",
    "    else:\n",
    "        lang_dict_34[key]=[val]\n",
    "    \n",
    "print(lang_dict_34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "154"
      ]
     },
     "execution_count": 444,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# will create a list of only the ids that have levels 3 and 4 in their lvl_nums column\n",
    "lvls45=[]\n",
    "ind=0\n",
    "for i in lvl_list.anon_id:\n",
    "    if ((4 in lvl_list.iat[ind,2]) and (5 in lvl_list.iat[ind,2])):\n",
    "        append=lvl_list.at[ind, 'anon_id']\n",
    "        lvls45.append(append)\n",
    "    ind+=1\n",
    "\n",
    "lvls45.sort()\n",
    "len(lvls45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Korean': ['aa8', 'ac5', 'ad1', 'ag9', 'al5', 'an5', 'ap4', 'aq5', 'as0', 'as7', 'au5', 'au6', 'aw6', 'ay1', 'be7', 'bq0', 'bu4', 'bv9', 'bw3', 'bz5', 'cc4', 'ce3', 'ch2', 'ci0', 'cj8', 'co5', 'cp0', 'cv3', 'cw0', 'cw1', 'dd9', 'df3', 'dm3', 'dy7', 'ea4', 'eb3', 'eb9', 'ec1', 'eg5', 'eq8', 'es0', 'es9', 'et3', 'ex3', 'fa0', 'fb4', 'fd6', 'ff1', 'fi5', 'fj7', 'fl0', 'fp5', 'fs0', 'ft2', 'fu6', 'fx4', 'fz8', 'ga1', 'gc2', 'ge6', 'gg2', 'gg6', 'gj0', 'gk5', 'gl1', 'gn0', 'gq8', 'gs3', 'gu0', 'gz2', 'ha2', 'hb4'], 'Chinese': ['ad7', 'ae9', 'af4', 'am5', 'an7', 'aq1', 'ar8', 'ar9', 'az8', 'bd7', 'bf2', 'bf7', 'bf9', 'bl4', 'bl7', 'bp2', 'bp4', 'br9', 'bv8', 'bw9', 'by5', 'by6', 'bz1', 'bz2', 'ca4', 'cb3', 'cd6', 'cf9', 'ci2', 'cj5', 'cl3', 'cz2', 'cz4', 'dc0', 'di7', 'dk6', 'dm8', 'dq9', 'du9', 'dw2', 'ei2', 'ei8', 'eo1', 'eq4', 'es4', 'et4', 'ev6', 'ev9', 'ff2', 'fg8', 'fi1', 'fj4', 'fk8', 'fo4', 'fq5', 'fw7', 'ga3', 'gb4', 'gf5', 'gl2', 'gm1', 'go8', 'gt0', 'gv3', 'gw0', 'gx5'], 'Spanish': ['bi4', 'bj2', 'br2', 'cm9', 'cv7', 'dc6', 'df4', 'dk0', 'eo8', 'fa2', 'fx7', 'fy1', 'gq4', 'gs6', 'gu1', 'gu9']}\n"
     ]
    }
   ],
   "source": [
    "lang_dict_45={}\n",
    "for i in lvls45:\n",
    "    df_ind=binarySearchArr(all_anon,i)\n",
    "    key=sorted_sac.at[df_ind,'native_language']\n",
    "    val=sorted_sac.at[df_ind,'anon_id']\n",
    "    \n",
    "    if key in lang_dict_45:\n",
    "        lang_dict_45[key].append(val)\n",
    "    else:\n",
    "        lang_dict_45[key]=[val]\n",
    "    \n",
    "print(lang_dict_45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3-5:  42 \n",
      "3-4:  111 \n",
      "4-5:  154\n"
     ]
    }
   ],
   "source": [
    "print(\"3-5: \",len(all_three),'\\n3-4: ',len(lvls34),\"\\n4-5: \",len(lvls45))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Three:\n",
      "Korean 22\n",
      "Chinese 16\n",
      "Spanish 4\n"
     ]
    }
   ],
   "source": [
    "print(\"All Three:\")\n",
    "for key, value in lang_dict_all.items():\n",
    "    print(key,len(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3-4:\n",
      "Korean 60\n",
      "Chinese 42\n",
      "Spanish 9\n"
     ]
    }
   ],
   "source": [
    "print(\"3-4:\")\n",
    "\n",
    "for key, value in lang_dict_34.items():\n",
    "    print(key,len(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4-5:\n",
      "Korean 72\n",
      "Chinese 66\n",
      "Spanish 16\n"
     ]
    }
   ],
   "source": [
    "print(\"4-5:\")\n",
    "\n",
    "for key, value in lang_dict_45.items():\n",
    "    print(key,len(value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting distributions of Loose Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping the columns that aren't needed for what we're doing right now\n",
    "dropped_loose=loose.drop(columns=['3Langs','Item','answer_id','gender','course_id','class_id','question_id','version','text1_len',\n",
    "                                     'text2_len','text3_len','text1','text2 (line breaks/extra spaces removed, spaces added to reach 60)',\n",
    "                                     'text3 (edits made to fix word counts)','Judgement','Notes'])\n",
    "final_loose=dropped_loose.dropna()\n",
    "\n",
    "sorted_loose=final_loose.sort_values(by=['anon_id']).reset_index(drop=True)\n",
    "all_anon_loose=[]\n",
    "for i in sorted_loose.anon_id:\n",
    "    all_anon_loose.append(i)\n",
    "len(all_anon_loose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anon_id</th>\n",
       "      <th>n_anon_ids_loose</th>\n",
       "      <th>lvl_nums_loose</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aa0</td>\n",
       "      <td>1</td>\n",
       "      <td>[5.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aa3</td>\n",
       "      <td>1</td>\n",
       "      <td>[4.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aa8</td>\n",
       "      <td>2</td>\n",
       "      <td>[4.0, 5.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aa9</td>\n",
       "      <td>2</td>\n",
       "      <td>[3.0, 4.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ab6</td>\n",
       "      <td>1</td>\n",
       "      <td>[4.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>gz2</td>\n",
       "      <td>2</td>\n",
       "      <td>[4.0, 5.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>gz5</td>\n",
       "      <td>1</td>\n",
       "      <td>[4.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>gz7</td>\n",
       "      <td>1</td>\n",
       "      <td>[4.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>ha0</td>\n",
       "      <td>1</td>\n",
       "      <td>[5.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>ha2</td>\n",
       "      <td>2</td>\n",
       "      <td>[4.0, 5.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>283 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    anon_id  n_anon_ids_loose lvl_nums_loose\n",
       "0       aa0                 1          [5.0]\n",
       "1       aa3                 1          [4.0]\n",
       "2       aa8                 2     [4.0, 5.0]\n",
       "3       aa9                 2     [3.0, 4.0]\n",
       "4       ab6                 1          [4.0]\n",
       "..      ...               ...            ...\n",
       "278     gz2                 2     [4.0, 5.0]\n",
       "279     gz5                 1          [4.0]\n",
       "280     gz7                 1          [4.0]\n",
       "281     ha0                 1          [5.0]\n",
       "282     ha2                 2     [4.0, 5.0]\n",
       "\n",
       "[283 rows x 3 columns]"
      ]
     },
     "execution_count": 489,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this code gets how many times an id appeared (n_anon_ids) as well as an array of what levels they participated in (lvl_nums)\n",
    "clean_ids_lvl_loose=final_loose.groupby('anon_id').agg(\n",
    "    n_anon_ids_loose=('level_id', 'nunique'),\n",
    "    lvl_nums_loose=('level_id', get_uniques)\n",
    ")\n",
    "\n",
    "#changes the clean_ids_lvl's index so we can access the anon_id easier\n",
    "ind_loose= clean_ids_lvl_loose.reset_index()\n",
    "ind_loose\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 469,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for loop that checks if lvl_nums has all three levels in it (3,4, and 5)\n",
    "# if there are three values in lvl_nums, the anon_id is appended to the all_three list\n",
    "ind=0\n",
    "all_three_loose=[]\n",
    "append=''\n",
    "for i in ind_loose.anon_id:\n",
    "    if ind_loose.iat[ind, 1]==3:\n",
    "        append=ind_loose.at[ind,'anon_id']\n",
    "        all_three_loose.append(append)\n",
    "    ind=ind+1\n",
    "\n",
    "all_three_loose.sort()\n",
    "len(all_three_loose)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Korean': ['an5', 'bv9'], 'Chinese': ['ar8', 'bl4', 'bp4', 'bz2'], 'Spanish': ['fa2', 'fy1']}\n"
     ]
    }
   ],
   "source": [
    "llang_dict_35={}\n",
    "for i in all_three_loose:\n",
    "    df_ind=binarySearchArr(all_anon_loose,i)\n",
    "    key=sorted_loose.at[df_ind,'L1']\n",
    "    val=sorted_loose.at[df_ind,'anon_id']\n",
    "    \n",
    "    if key in llang_dict_35:\n",
    "        llang_dict_35[key].append(val)\n",
    "    else:\n",
    "        llang_dict_35[key]=[val]\n",
    "    \n",
    "print(llang_dict_35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n"
     ]
    }
   ],
   "source": [
    "# creates list of participants in loose sheet that are in level 3 and 4\n",
    "ind=0\n",
    "in34_loose=[]\n",
    "append=''\n",
    "for i in ind_loose.anon_id:\n",
    "    if ind_loose.iat[ind, 1]==2:\n",
    "        if (3 in ind_loose.iat[ind,2] and 4 in ind_loose.iat[ind,2]):\n",
    "            append=ind_loose.at[ind,'anon_id']\n",
    "            in34_loose.append(append)\n",
    "    elif ind_loose.iat[ind,1]==3:\n",
    "        append=ind_loose.at[ind,'anon_id']\n",
    "        in34_loose.append(append)\n",
    "    ind=ind+1\n",
    "in34_loose.sort()\n",
    "print(len(in34_loose))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Korean': ['aa9', 'ah9', 'an5', 'be2', 'bf1', 'bv9', 'cf6', 'cw6', 'cy5', 'ex0', 'fc9', 'fv7', 'gd1', 'gv1'], 'Chinese': ['ap5', 'ar8', 'ax7', 'bl4', 'bp4', 'bz2', 'cs5', 'ey8', 'fn8'], 'Spanish': ['ch0', 'cm9', 'fa2', 'fe7', 'fy1']}\n"
     ]
    }
   ],
   "source": [
    "llang_dict_34={}\n",
    "for i in in34_loose:\n",
    "    df_ind=binarySearchArr(all_anon_loose,i)\n",
    "    key=sorted_loose.at[df_ind,'L1']\n",
    "    val=sorted_loose.at[df_ind,'anon_id']\n",
    "    \n",
    "    if key in llang_dict_34:\n",
    "        llang_dict_34[key].append(val)\n",
    "    else:\n",
    "        llang_dict_34[key]=[val]\n",
    "    \n",
    "print(llang_dict_34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61\n"
     ]
    }
   ],
   "source": [
    "# creates list of participants in loose sheet that are in level 4 and 5\n",
    "ind=0\n",
    "in45_loose=[]\n",
    "append=''\n",
    "for i in ind_loose.anon_id:\n",
    "    if ind_loose.iat[ind, 1]==2:\n",
    "        if (4 in ind_loose.iat[ind,2] and 5 in ind_loose.iat[ind,2]):\n",
    "            append=ind_loose.at[ind,'anon_id']\n",
    "            in45_loose.append(append)\n",
    "    elif ind_loose.iat[ind,1]==3:\n",
    "        append=ind_loose.at[ind,'anon_id']\n",
    "        in45_loose.append(append)\n",
    "    ind=ind+1\n",
    "in45_loose.sort()\n",
    "print(len(in45_loose))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Korean': ['aa8', 'ac5', 'al5', 'an5', 'au5', 'au6', 'bu4', 'bv9', 'cc4', 'ce3', 'cj8', 'co5', 'cw1', 'dd9', 'dy7', 'fa0', 'ff1', 'fj7', 'fp5', 'fu6', 'fx4', 'gq8', 'gz2', 'ha2'], 'Chinese': ['aq1', 'ar8', 'ar9', 'az8', 'bf2', 'bl4', 'bl7', 'bp4', 'bz2', 'cb3', 'cj5', 'cz4', 'dc0', 'dm8', 'dq9', 'ei8', 'et4', 'ev6', 'ev9', 'ff2', 'fg8', 'fk8', 'gb4', 'gf5', 'gm1'], 'Spanish': ['bi4', 'bj2', 'cv7', 'dc6', 'df4', 'dk0', 'eo8', 'fa2', 'fx7', 'fy1', 'gq4', 'gu1']}\n"
     ]
    }
   ],
   "source": [
    "llang_dict_45={}\n",
    "for i in in45_loose:\n",
    "    df_ind=binarySearchArr(all_anon_loose,i)\n",
    "    key=sorted_loose.at[df_ind,'L1']\n",
    "    val=sorted_loose.at[df_ind,'anon_id']\n",
    "    \n",
    "    if key in llang_dict_45:\n",
    "        llang_dict_45[key].append(val)\n",
    "    else:\n",
    "        llang_dict_45[key]=[val]\n",
    "    \n",
    "print(llang_dict_45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3-5:\n",
      "Korean 2\n",
      "Chinese 4\n",
      "Spanish 2\n"
     ]
    }
   ],
   "source": [
    "print(\"3-5:\")\n",
    "\n",
    "for key, value in llang_dict_35.items():\n",
    "    print(key,len(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3-4:\n",
      "Korean 14\n",
      "Chinese 9\n",
      "Spanish 5\n"
     ]
    }
   ],
   "source": [
    "print(\"3-4:\")\n",
    "\n",
    "for key, value in llang_dict_34.items():\n",
    "    print(key,len(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4-5:\n",
      "Korean 24\n",
      "Chinese 25\n",
      "Spanish 12\n"
     ]
    }
   ],
   "source": [
    "print(\"4-5:\")\n",
    "\n",
    "for key, value in llang_dict_45.items():\n",
    "    print(key,len(value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Answer counts for whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_counts=sorted_sac.copy()\n",
    "e_counts[\"Number of Questions\"]=e_counts.anon_id.count()\n",
    "entire_counts=e_counts.groupby(['anon_id','native_language'])['Number of Questions'].count()\n",
    "qcount_entire=entire_counts.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anon_id</th>\n",
       "      <th>native_language</th>\n",
       "      <th>Number of Questions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aa0</td>\n",
       "      <td>Spanish</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aa1</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aa3</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aa8</td>\n",
       "      <td>Korean</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aa9</td>\n",
       "      <td>Korean</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>ha0</td>\n",
       "      <td>Korean</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>ha2</td>\n",
       "      <td>Korean</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>ha6</td>\n",
       "      <td>Korean</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>hb4</td>\n",
       "      <td>Korean</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>hc1</td>\n",
       "      <td>Korean</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>476 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    anon_id native_language  Number of Questions\n",
       "0       aa0         Spanish                   17\n",
       "1       aa1         Chinese                   22\n",
       "2       aa3         Chinese                    8\n",
       "3       aa8          Korean                   34\n",
       "4       aa9          Korean                   28\n",
       "..      ...             ...                  ...\n",
       "471     ha0          Korean                    3\n",
       "472     ha2          Korean                   44\n",
       "473     ha6          Korean                   32\n",
       "474     hb4          Korean                   39\n",
       "475     hc1          Korean                    5\n",
       "\n",
       "[476 rows x 3 columns]"
      ]
     },
     "execution_count": 538,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qcount_entire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts in all 3\n",
      "Spanish counts:  107 \n",
      "Chinese counts:  468 \n",
      "Korean counts:  795\n"
     ]
    }
   ],
   "source": [
    "espanish,echinese,ekorean=find_counts(qcount_entire,all_three,'native_language')\n",
    "print('Counts in all 3\\nSpanish counts: ',espanish,'\\nChinese counts: ',echinese,'\\nKorean counts: ',ekorean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts in 3 and 4\n",
      "Spanish counts:  156 \n",
      "Chinese counts:  928 \n",
      "Korean counts:  1564\n"
     ]
    }
   ],
   "source": [
    "espanish34,echinese34,ekorean34=find_counts(qcount_entire,lvls34,'native_language')\n",
    "print('Counts in 3 and 4\\nSpanish counts: ',espanish34,'\\nChinese counts: ',echinese34,'\\nKorean counts: ',ekorean34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts in 4 and 5\n",
      "Spanish counts:  298 \n",
      "Chinese counts:  1712 \n",
      "Korean counts:  1975\n"
     ]
    }
   ],
   "source": [
    "espanish45,echinese45,ekorean45=find_counts(qcount_entire,lvls45,'native_language')\n",
    "print('Counts in 4 and 5\\nSpanish counts: ',espanish45,'\\nChinese counts: ',echinese45,'\\nKorean counts: ',ekorean45)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Answer Counts for Loose dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anon_id</th>\n",
       "      <th>L1</th>\n",
       "      <th>Number of Questions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aa0</td>\n",
       "      <td>Spanish</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aa3</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aa8</td>\n",
       "      <td>Korean</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aa9</td>\n",
       "      <td>Korean</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ab6</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>gz2</td>\n",
       "      <td>Korean</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>gz5</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>gz7</td>\n",
       "      <td>Korean</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>ha0</td>\n",
       "      <td>Korean</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>ha2</td>\n",
       "      <td>Korean</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>283 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    anon_id       L1  Number of Questions\n",
       "0       aa0  Spanish                    8\n",
       "1       aa3  Chinese                    2\n",
       "2       aa8   Korean                   13\n",
       "3       aa9   Korean                   18\n",
       "4       ab6  Chinese                    2\n",
       "..      ...      ...                  ...\n",
       "278     gz2   Korean                    8\n",
       "279     gz5  Chinese                    6\n",
       "280     gz7   Korean                    5\n",
       "281     ha0   Korean                    3\n",
       "282     ha2   Korean                   19\n",
       "\n",
       "[283 rows x 3 columns]"
      ]
     },
     "execution_count": 542,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l_counts=final_loose.copy()\n",
    "l_counts[\"Number of Questions\"]=l_counts.anon_id.count()\n",
    "loose_counts=l_counts.groupby(['anon_id','L1'])['Number of Questions'].count()\n",
    "qcount_loose=loose_counts.reset_index()\n",
    "qcount_loose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts in all three\n",
      "Spanish counts:  23 \n",
      "Chinese counts:  34 \n",
      "Korean counts:  26\n"
     ]
    }
   ],
   "source": [
    "lspanish,lchinese,lkorean=find_counts(qcount_loose, all_three_loose,'L1')\n",
    "print('Counts in all three\\nSpanish counts: ',lspanish,'\\nChinese counts: ',lchinese,'\\nKorean counts: ',lkorean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts in 3 and 4\n",
      "Spanish counts:  44 \n",
      "Chinese counts:  64 \n",
      "Korean counts:  146\n"
     ]
    }
   ],
   "source": [
    "lspanish34,lchinese34,lkorean34=find_counts(qcount_loose,in34_loose,'L1')\n",
    "print('Counts in 3 and 4\\nSpanish counts: ',lspanish34,'\\nChinese counts: ',lchinese34,'\\nKorean counts: ',lkorean34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts in 4 and 5\n",
      "Spanish counts:  128 \n",
      "Chinese counts:  305 \n",
      "Korean counts:  289\n"
     ]
    }
   ],
   "source": [
    "lspanish45,lchinese45,lkorean45=find_counts(qcount_loose, in45_loose,'L1')\n",
    "print('Counts in 4 and 5\\nSpanish counts: ',lspanish45,'\\nChinese counts: ',lchinese45,'\\nKorean counts: ',lkorean45)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokinizing Essays for Loose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reference code from previous research\n",
    "\n",
    "\n",
    "def calculate_tokens(text):\n",
    "    essay = text\n",
    "\n",
    "        \n",
    "    tokenizer = RegexpTokenizer(r'[0-9a-zA-Z_\\-]+')\n",
    "    tokenized = tokenizer.tokenize(essay)\n",
    "    unique = np.unique(tokenized)\n",
    "    \n",
    "    return {\n",
    "        'total': len(tokenized),\n",
    "        'unique': len(unique)\n",
    "    }\n",
    "\n",
    "\n",
    "directories = ['limited', 'loose', 'strictest']\n",
    "tokenize_results = { 'filename': [], 'total_tokens': [], 'unique_tokens': [] }\n",
    "\n",
    "for directory in directories:\n",
    "    for file in os.listdir(f'./data/in/{directory}'):\n",
    "        results = calculate_tokens(f'./data/in/{directory}/{file}')\n",
    "        tokenize_results['filename'].append(file)\n",
    "        tokenize_results['total_tokens'].append(results['total'])\n",
    "        tokenize_results['unique_tokens'].append(results['unique'])\n",
    "\n",
    "pd.DataFrame(data=tokenize_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loose All Three\n",
      "Spanish Token Average:  132.8695652173913 \n",
      "Korean Token Average:  181.3846153846154 \n",
      "Chinese Token Average: 188.64705882352942\n"
     ]
    }
   ],
   "source": [
    "print('Loose All Three')\n",
    "finding_tokens(loose,all_three_loose,'L1','text3_len',qcount_loose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loose 3-4\n",
      "Spanish Token Average:  140.8181818181818 \n",
      "Korean Token Average:  152.14383561643837 \n",
      "Chinese Token Average: 169.953125\n"
     ]
    }
   ],
   "source": [
    "print('Loose 3-4')\n",
    "finding_tokens(loose,in34_loose,'L1','text3_len',qcount_loose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loose 4-5\n",
      "Spanish Token Average:  203.5 \n",
      "Korean Token Average:  231.42560553633217 \n",
      "Chinese Token Average: 238.32131147540983\n"
     ]
    }
   ],
   "source": [
    "print('Loose 4-5')\n",
    "finding_tokens(loose,in45_loose,'L1','text3_len',qcount_loose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loose All Three, Level 3\n",
      "Spanish Token Average:  44.26086956521739 \n",
      "Korean Token Average:  31.03846153846154 \n",
      "Chinese Token Average: 42.64705882352941\n"
     ]
    }
   ],
   "source": [
    "print('Loose All Three, Level 3')\n",
    "finding_tokens_lvl(loose,all_three_loose,'L1','text3_len',3,qcount_loose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loose All Three, Level 4\n",
      "Spanish Token Average:  75.0 \n",
      "Korean Token Average:  117.84615384615384 \n",
      "Chinese Token Average: 54.38235294117647\n"
     ]
    }
   ],
   "source": [
    "print('Loose All Three, Level 4')\n",
    "finding_tokens_lvl(loose,all_three_loose,'L1','text3_len',4,qcount_loose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loose All Three, Level 5\n",
      "Spanish Token Average:  13.608695652173912 \n",
      "Korean Token Average:  32.5 \n",
      "Chinese Token Average: 91.61764705882354\n"
     ]
    }
   ],
   "source": [
    "print('Loose All Three, Level 5')\n",
    "finding_tokens_lvl(loose,all_three_loose,'L1','text3_len',5,qcount_loose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loose 3-4, Level 3\n",
      "Spanish Token Average:  49.45454545454545 \n",
      "Korean Token Average:  46.534246575342465 \n",
      "Chinese Token Average: 64.84375\n"
     ]
    }
   ],
   "source": [
    "print('Loose 3-4, Level 3')\n",
    "finding_tokens_lvl(loose,in34_loose,'L1','text3_len',3,qcount_loose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loose 3-4, Level 4\n",
      "Spanish Token Average:  84.25 \n",
      "Korean Token Average:  99.82191780821918 \n",
      "Chinese Token Average: 56.4375\n"
     ]
    }
   ],
   "source": [
    "print('Loose 3-4, Level 4')\n",
    "finding_tokens_lvl(loose,in34_loose,'L1','text3_len',4,qcount_loose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loose 4-5, Level 4\n",
      "Spanish Token Average:  110.7421875 \n",
      "Korean Token Average:  115.69204152249135 \n",
      "Chinese Token Average: 103.80327868852459\n"
     ]
    }
   ],
   "source": [
    "print('Loose 4-5, Level 4')\n",
    "finding_tokens_lvl(loose,in45_loose,'L1','text3_len',4,qcount_loose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loose 4-5, Level 5\n",
      "Spanish Token Average:  84.8046875 \n",
      "Korean Token Average:  112.94117647058823 \n",
      "Chinese Token Average: 129.7639344262295\n"
     ]
    }
   ],
   "source": [
    "print('Loose 4-5, Level 5')\n",
    "finding_tokens_lvl(loose,in45_loose,'L1','text3_len',5,qcount_loose)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenizing Essays for Whole Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "need to divide by number of answers, need to find number of answers per level for the level ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Whole All Three\n",
      "Spanish Token Average:  184.54205607476635 \n",
      "Korean Token Average:  211.46540880503144 \n",
      "Chinese Token Average: 211.1196581196581\n"
     ]
    }
   ],
   "source": [
    "print('Whole All Three')\n",
    "finding_tokens(stu_ans_crs,all_three,'native_language','text_len',qcount_entire)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Whole 3-4\n",
      "Spanish Token Average:  189.14743589743588 \n",
      "Korean Token Average:  187.4891304347826 \n",
      "Chinese Token Average: 194.24137931034483\n"
     ]
    }
   ],
   "source": [
    "print('Whole 3-4')\n",
    "finding_tokens(stu_ans_crs,lvls34,'native_language','text_len',qcount_entire)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Whole 4-5\n",
      "Spanish Token Average:  220.9228187919463 \n",
      "Korean Token Average:  238.02177215189874 \n",
      "Chinese Token Average: 247.8586448598131\n"
     ]
    }
   ],
   "source": [
    "print('Whole 4-5')\n",
    "finding_tokens(stu_ans_crs,lvls45,'native_language','text_len',qcount_entire)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 641,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Whole All Three, Level 3\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-641-4d4774a787c3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Whole All Three, Level 3'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mfinding_tokens_lvl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstu_ans_crs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mall_three\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'native_language'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'text_len'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mqcount_entire\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-634-5cccdadee98b>\u001b[0m in \u001b[0;36mfinding_tokens_lvl\u001b[1;34m(df, id_list, lang_col, text_len_col, lvl, qcounts)\u001b[0m\n\u001b[0;32m     19\u001b[0m                     \u001b[0mchinese\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[0mlength\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0mindex\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m     print('Spanish Token Average: ',spanish/lspanish,'\\nKorean Token Average: ',korean/lkorean,\n\u001b[0m\u001b[0;32m     22\u001b[0m           '\\nChinese Token Average:',chinese/lchinese)\n",
      "\u001b[1;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "print('Whole All Three, Level 3')\n",
    "finding_tokens_lvl(stu_ans_crs,all_three,'native_language','text_len',3,qcount_entire)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Whole All Three, Level 4\n",
      "Spanish Token Average:  120.82242990654206 \n",
      "Korean Token Average:  103.062893081761 \n",
      "Chinese Token Average: 84.73931623931624\n"
     ]
    }
   ],
   "source": [
    "print('Whole All Three, Level 4')\n",
    "finding_tokens_lvl(stu_ans_crs,all_three,'native_language','text_len',4,qcount_entire)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Whole All Three, Level 5\n",
      "Spanish Token Average:  27.570093457943926 \n",
      "Korean Token Average:  72.94591194968554 \n",
      "Chinese Token Average: 90.59615384615384\n"
     ]
    }
   ],
   "source": [
    "print('Whole All Three, Level 5')\n",
    "finding_tokens_lvl(stu_ans_crs,all_three,'native_language','text_len',5,qcount_entire)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Whole 3-4, Level 3\n",
      "Spanish Token Average:  49.833333333333336 \n",
      "Korean Token Average:  45.46739130434783 \n",
      "Chinese Token Average: 51.522629310344826\n"
     ]
    }
   ],
   "source": [
    "print('Whole 3-4, Level 3')\n",
    "finding_tokens_lvl(stu_ans_crs,lvls34,'native_language','text_len',3,qcount_entire)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Whole 3-4, Level 4\n",
      "Spanish Token Average:  120.40384615384616 \n",
      "Korean Token Average:  103.9616368286445 \n",
      "Chinese Token Average: 96.79094827586206\n"
     ]
    }
   ],
   "source": [
    "print('Whole 3-4, Level 4')\n",
    "finding_tokens_lvl(stu_ans_crs,lvls34,'native_language','text_len',4,qcount_entire)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Whole 4-5, Level 4\n",
      "Spanish Token Average:  117.78859060402685 \n",
      "Korean Token Average:  112.16303797468355 \n",
      "Chinese Token Average: 103.85221962616822\n"
     ]
    }
   ],
   "source": [
    "print('Whole 4-5, Level 4')\n",
    "finding_tokens_lvl(stu_ans_crs,lvls45,'native_language','text_len',4,qcount_entire)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Whole 4-5, Level 4\n",
      "Spanish Token Average:  90.15436241610739 \n",
      "Korean Token Average:  111.58632911392405 \n",
      "Chinese Token Average: 134.22429906542055\n"
     ]
    }
   ],
   "source": [
    "print('Whole 4-5, Level 4')\n",
    "finding_tokens_lvl(stu_ans_crs,lvls45,'native_language','text_len',5,qcount_entire)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>3Langs</th>\n",
       "      <th>Item</th>\n",
       "      <th>answer_id</th>\n",
       "      <th>anon_id</th>\n",
       "      <th>L1</th>\n",
       "      <th>gender</th>\n",
       "      <th>course_id</th>\n",
       "      <th>level_id</th>\n",
       "      <th>class_id</th>\n",
       "      <th>question_id</th>\n",
       "      <th>version</th>\n",
       "      <th>text1_len</th>\n",
       "      <th>text2_len</th>\n",
       "      <th>text3_len</th>\n",
       "      <th>text1</th>\n",
       "      <th>text2 (line breaks/extra spaces removed, spaces added to reach 60)</th>\n",
       "      <th>text3 (edits made to fix word counts)</th>\n",
       "      <th>Judgement</th>\n",
       "      <th>Notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Y</td>\n",
       "      <td>C12</td>\n",
       "      <td>141.0</td>\n",
       "      <td>aj8</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>Male</td>\n",
       "      <td>118.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>w</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>\\n\\n\\n Today, I am going to describe one of my...</td>\n",
       "      <td>Today, I am going to describe one of my classm...</td>\n",
       "      <td>Today, I am going to describe one of my classm...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Y</td>\n",
       "      <td>C13</td>\n",
       "      <td>143.0</td>\n",
       "      <td>az8</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>Female</td>\n",
       "      <td>118.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>w</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>My niece is 3 years old who is my younger brot...</td>\n",
       "      <td>My niece is 3 years old who is my younger brot...</td>\n",
       "      <td>My niece is 3 years old who is my younger brot...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Y</td>\n",
       "      <td>K9</td>\n",
       "      <td>133.0</td>\n",
       "      <td>az2</td>\n",
       "      <td>Korean</td>\n",
       "      <td>Male</td>\n",
       "      <td>118.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>w</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>When I was in Germany, I met a friend who was ...</td>\n",
       "      <td>When I was in Germany, I met a friend who was ...</td>\n",
       "      <td>When I was in Germany, I met a friend who was ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Y</td>\n",
       "      <td>K11</td>\n",
       "      <td>135.0</td>\n",
       "      <td>at8</td>\n",
       "      <td>Korean</td>\n",
       "      <td>Female</td>\n",
       "      <td>118.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>w</td>\n",
       "      <td>17.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>my friend is ANON_NAME_0. she is a my ELI frie...</td>\n",
       "      <td>my friend is ANON_NAME_0. she is a my ELI frie...</td>\n",
       "      <td>my friend is ANON_NAME_0. she is a my ELI frie...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Y</td>\n",
       "      <td>K20</td>\n",
       "      <td>188.0</td>\n",
       "      <td>eh9</td>\n",
       "      <td>Korean</td>\n",
       "      <td>Male</td>\n",
       "      <td>118.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>w</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>Younghun is my best friend. His facial appeara...</td>\n",
       "      <td>Younghun is my best friend. His facial appeara...</td>\n",
       "      <td>Younghun is my best friend. His facial appeara...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1807</th>\n",
       "      <td>Y</td>\n",
       "      <td>C3207</td>\n",
       "      <td>48246.0</td>\n",
       "      <td>bv8</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>1043.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>g</td>\n",
       "      <td>6105.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>The quote that talks about a true friend is so...</td>\n",
       "      <td>The quote that talks about a true friend is so...</td>\n",
       "      <td>The quote that talks about a true friend is so...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1808</th>\n",
       "      <td>Y</td>\n",
       "      <td>K3559</td>\n",
       "      <td>48254.0</td>\n",
       "      <td>dr8</td>\n",
       "      <td>Korean</td>\n",
       "      <td>Female</td>\n",
       "      <td>1043.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>g</td>\n",
       "      <td>6105.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>I think this means that home is not just a pla...</td>\n",
       "      <td>I think this means that home is not just a pla...</td>\n",
       "      <td>I think this means that home is not just a pla...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1809</th>\n",
       "      <td>Y</td>\n",
       "      <td>S781</td>\n",
       "      <td>48252.0</td>\n",
       "      <td>bl3</td>\n",
       "      <td>Spanish</td>\n",
       "      <td>Female</td>\n",
       "      <td>1043.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>g</td>\n",
       "      <td>6105.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>This quotation means that the majority of peop...</td>\n",
       "      <td>This quotation means that the majority of peop...</td>\n",
       "      <td>This quotation means that the majority of peop...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1810</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1811</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1812 rows Ã— 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     3Langs   Item  answer_id anon_id       L1   gender  course_id  level_id  \\\n",
       "0         Y    C12      141.0     aj8  Chinese     Male      118.0       5.0   \n",
       "1         Y    C13      143.0     az8  Chinese   Female      118.0       5.0   \n",
       "2         Y     K9      133.0     az2   Korean     Male      118.0       5.0   \n",
       "3         Y    K11      135.0     at8   Korean   Female      118.0       5.0   \n",
       "4         Y    K20      188.0     eh9   Korean     Male      118.0       5.0   \n",
       "...     ...    ...        ...     ...      ...      ...        ...       ...   \n",
       "1807      Y  C3207    48246.0     bv8  Chinese  Unknown     1043.0       4.0   \n",
       "1808      Y  K3559    48254.0     dr8   Korean   Female     1043.0       4.0   \n",
       "1809      Y   S781    48252.0     bl3  Spanish   Female     1043.0       4.0   \n",
       "1810    NaN    NaN        NaN     NaN      NaN      NaN        NaN       NaN   \n",
       "1811    NaN    NaN        NaN     NaN      NaN      NaN        NaN       NaN   \n",
       "\n",
       "     class_id  question_id  version  text1_len  text2_len  text3_len  \\\n",
       "0           w         17.0      1.0      121.0      114.0      114.0   \n",
       "1           w         17.0      1.0       96.0       95.0       95.0   \n",
       "2           w         17.0      1.0      130.0      128.0      128.0   \n",
       "3           w         17.0      3.0      104.0      105.0      105.0   \n",
       "4           w         17.0      1.0       98.0       97.0       97.0   \n",
       "...       ...          ...      ...        ...        ...        ...   \n",
       "1807        g       6105.0      1.0      133.0      131.0      131.0   \n",
       "1808        g       6105.0      1.0      175.0      162.0      162.0   \n",
       "1809        g       6105.0      1.0      157.0      146.0      146.0   \n",
       "1810      NaN          NaN      NaN        NaN        NaN        NaN   \n",
       "1811      NaN          NaN      NaN        NaN        NaN        NaN   \n",
       "\n",
       "                                                  text1  \\\n",
       "0     \\n\\n\\n Today, I am going to describe one of my...   \n",
       "1     My niece is 3 years old who is my younger brot...   \n",
       "2     When I was in Germany, I met a friend who was ...   \n",
       "3     my friend is ANON_NAME_0. she is a my ELI frie...   \n",
       "4     Younghun is my best friend. His facial appeara...   \n",
       "...                                                 ...   \n",
       "1807  The quote that talks about a true friend is so...   \n",
       "1808  I think this means that home is not just a pla...   \n",
       "1809  This quotation means that the majority of peop...   \n",
       "1810                                                NaN   \n",
       "1811                                                NaN   \n",
       "\n",
       "     text2 (line breaks/extra spaces removed, spaces added to reach 60)  \\\n",
       "0     Today, I am going to describe one of my classm...                   \n",
       "1     My niece is 3 years old who is my younger brot...                   \n",
       "2     When I was in Germany, I met a friend who was ...                   \n",
       "3     my friend is ANON_NAME_0. she is a my ELI frie...                   \n",
       "4     Younghun is my best friend. His facial appeara...                   \n",
       "...                                                 ...                   \n",
       "1807  The quote that talks about a true friend is so...                   \n",
       "1808  I think this means that home is not just a pla...                   \n",
       "1809  This quotation means that the majority of peop...                   \n",
       "1810                                                NaN                   \n",
       "1811                                                NaN                   \n",
       "\n",
       "                  text3 (edits made to fix word counts)  Judgement Notes  \n",
       "0     Today, I am going to describe one of my classm...        1.0   NaN  \n",
       "1     My niece is 3 years old who is my younger brot...        1.0   NaN  \n",
       "2     When I was in Germany, I met a friend who was ...        1.0   NaN  \n",
       "3     my friend is ANON_NAME_0. she is a my ELI frie...        1.0   NaN  \n",
       "4     Younghun is my best friend. His facial appeara...        1.0   NaN  \n",
       "...                                                 ...        ...   ...  \n",
       "1807  The quote that talks about a true friend is so...        3.0   NaN  \n",
       "1808  I think this means that home is not just a pla...        3.0   NaN  \n",
       "1809  This quotation means that the majority of peop...        3.0   NaN  \n",
       "1810                                                NaN        NaN   NaN  \n",
       "1811                                                NaN        NaN   NaN  \n",
       "\n",
       "[1812 rows x 19 columns]"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anon_id</th>\n",
       "      <th>native_language</th>\n",
       "      <th>answer_id</th>\n",
       "      <th>text_len</th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>level_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>do6</td>\n",
       "      <td>Russian</td>\n",
       "      <td>150</td>\n",
       "      <td>299</td>\n",
       "      <td>Some people prefer eat out and some like doing...</td>\n",
       "      <td>['Some', 'people', 'prefer', 'eat', 'out', 'an...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>do6</td>\n",
       "      <td>Russian</td>\n",
       "      <td>1221</td>\n",
       "      <td>288</td>\n",
       "      <td>My opinion is that a person does need educatio...</td>\n",
       "      <td>['My', 'opinion', 'is', 'that', 'a', 'person',...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>do6</td>\n",
       "      <td>Russian</td>\n",
       "      <td>1957</td>\n",
       "      <td>321</td>\n",
       "      <td>There are two national rooms in the Cathedral ...</td>\n",
       "      <td>['There', 'are', 'two', 'national', 'rooms', '...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>do6</td>\n",
       "      <td>Russian</td>\n",
       "      <td>2164</td>\n",
       "      <td>464</td>\n",
       "      <td>There are two nation rooms in the Cathedral of...</td>\n",
       "      <td>['There', 'are', 'two', 'nation', 'rooms', 'in...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bv5</td>\n",
       "      <td>Arabic</td>\n",
       "      <td>151</td>\n",
       "      <td>315</td>\n",
       "      <td>\"Not all learning takes place in the classroom...</td>\n",
       "      <td>['``', 'Not', 'all', 'learning', 'takes', 'pla...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46225</th>\n",
       "      <td>cy7</td>\n",
       "      <td>Korean</td>\n",
       "      <td>47682</td>\n",
       "      <td>10</td>\n",
       "      <td>1. emphasis\\n2. appropriate\\n3. requires\\n4. a...</td>\n",
       "      <td>['1', '.', 'emphasis', '2', '.', 'appropriate'...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46226</th>\n",
       "      <td>fp7</td>\n",
       "      <td>Turkish</td>\n",
       "      <td>47823</td>\n",
       "      <td>10</td>\n",
       "      <td>1.emphasis \\n2.appropriate\\n3.requires\\n4.anal...</td>\n",
       "      <td>['1', '.', 'emphasis', '2', '.', 'appropriate'...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46227</th>\n",
       "      <td>fq6</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>47824</td>\n",
       "      <td>10</td>\n",
       "      <td>1.emphasis\\n2.appropriate\\n3.requires\\n4.analy...</td>\n",
       "      <td>['1', '.', 'emphasis', '2', '.', 'appropriate'...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46228</th>\n",
       "      <td>di6</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>47787</td>\n",
       "      <td>10</td>\n",
       "      <td>1 emphasis\\n2 normal\\n3 requires\\n4 analyze\\n5...</td>\n",
       "      <td>['1', 'emphasis', '2', 'normal', '3', 'require...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46229</th>\n",
       "      <td>fm3</td>\n",
       "      <td>Arabic</td>\n",
       "      <td>47725</td>\n",
       "      <td>10</td>\n",
       "      <td>1- emphasis\\n2- appropriate\\n3- requires\\n4- a...</td>\n",
       "      <td>['1', '-', 'emphasis', '2', '-', 'appropriate'...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>46230 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      anon_id native_language answer_id text_len  \\\n",
       "0         do6         Russian       150      299   \n",
       "1         do6         Russian      1221      288   \n",
       "2         do6         Russian      1957      321   \n",
       "3         do6         Russian      2164      464   \n",
       "4         bv5          Arabic       151      315   \n",
       "...       ...             ...       ...      ...   \n",
       "46225     cy7          Korean     47682       10   \n",
       "46226     fp7         Turkish     47823       10   \n",
       "46227     fq6         Chinese     47824       10   \n",
       "46228     di6         Chinese     47787       10   \n",
       "46229     fm3          Arabic     47725       10   \n",
       "\n",
       "                                                    text  \\\n",
       "0      Some people prefer eat out and some like doing...   \n",
       "1      My opinion is that a person does need educatio...   \n",
       "2      There are two national rooms in the Cathedral ...   \n",
       "3      There are two nation rooms in the Cathedral of...   \n",
       "4      \"Not all learning takes place in the classroom...   \n",
       "...                                                  ...   \n",
       "46225  1. emphasis\\n2. appropriate\\n3. requires\\n4. a...   \n",
       "46226  1.emphasis \\n2.appropriate\\n3.requires\\n4.anal...   \n",
       "46227  1.emphasis\\n2.appropriate\\n3.requires\\n4.analy...   \n",
       "46228  1 emphasis\\n2 normal\\n3 requires\\n4 analyze\\n5...   \n",
       "46229  1- emphasis\\n2- appropriate\\n3- requires\\n4- a...   \n",
       "\n",
       "                                                  tokens  level_id  \n",
       "0      ['Some', 'people', 'prefer', 'eat', 'out', 'an...         5  \n",
       "1      ['My', 'opinion', 'is', 'that', 'a', 'person',...         5  \n",
       "2      ['There', 'are', 'two', 'national', 'rooms', '...         5  \n",
       "3      ['There', 'are', 'two', 'nation', 'rooms', 'in...         5  \n",
       "4      ['``', 'Not', 'all', 'learning', 'takes', 'pla...         5  \n",
       "...                                                  ...       ...  \n",
       "46225  ['1', '.', 'emphasis', '2', '.', 'appropriate'...         3  \n",
       "46226  ['1', '.', 'emphasis', '2', '.', 'appropriate'...         3  \n",
       "46227  ['1', '.', 'emphasis', '2', '.', 'appropriate'...         3  \n",
       "46228  ['1', 'emphasis', '2', 'normal', '3', 'require...         3  \n",
       "46229  ['1', '-', 'emphasis', '2', '-', 'appropriate'...         3  \n",
       "\n",
       "[46230 rows x 7 columns]"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test=stu_ans_crs.drop(columns=['course_id','age','version','question_id','gender'])\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1- emphasis\n",
      "2- appropriate\n",
      "3- requires\n",
      "4- analyze\n",
      "5- authority\n",
      "6- significant\n",
      "7- flexible\n",
      "8- challenge\n",
      "9- normal\n",
      "10- contact\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
