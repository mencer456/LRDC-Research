{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Data analysis for Lexical Richness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import os\n",
    "import nltk\n",
    "import numpy as np\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#binary search for strings\n",
    "def binarySearchArr(arr, x):\n",
    "    l = 0\n",
    "    r = len(arr)\n",
    "    while (l <= r):\n",
    "        m = l + ((r - l) // 2)\n",
    " \n",
    "        res = (x == arr[m])\n",
    "        # Check if x is present at mid\n",
    "        if (res == True):\n",
    "            return m\n",
    " \n",
    "        # If x greater, ignore left half\n",
    "    #problem is here\n",
    "        elif (res == False):\n",
    "            if (x>arr[m]):\n",
    "                l = m+1\n",
    "            elif (x<arr[m]):\n",
    "                r=m-1\n",
    "        # If x is smaller, ignore right half\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function removes all of the rows that contain a string in the passed column\n",
    "def rmStr (df, col):\n",
    "    row_index=0\n",
    "    row_ind=[]\n",
    "    for i in df[col]:\n",
    "        try:\n",
    "            int(i)\n",
    "        except:\n",
    "            row_ind.append(row_index)\n",
    "        row_index+=1\n",
    "    return df.drop(labels=row_ind,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reference code from previous research, tokinizes essays\n",
    "# NEEDS UPDATING TO FIT CSV FILES\n",
    "\n",
    "#function that does this\n",
    "def calculate_tokens(file):\n",
    "    essay = ''\n",
    "\n",
    "    with open(file, 'r') as f: #used bc it's a file\n",
    "        essay = f.read().lower()\n",
    "        \n",
    "    tokenizer = RegexpTokenizer(r'[0-9a-zA-Z_\\-]+')\n",
    "    tokenized = tokenizer.tokenize(essay)\n",
    "    unique = np.unique(tokenized)\n",
    "    \n",
    "    return {\n",
    "        'total': len(tokenized),\n",
    "        'unique': len(unique)\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding DFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "loose=pd.read_csv('original-sheets\\Responses-Loose.csv')\n",
    "student_info=pd.read_csv('corpus-files\\student_information.csv')\n",
    "course=pd.read_csv('corpus-files\\course.csv')\n",
    "answer_df=pd.read_csv('answer.csv',index_col = 'answer_id', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "course_=course.drop(columns=['class_id','semester','section'])\n",
    "\n",
    "student=student_info.drop(columns=['birth_year','language_used_at_home','non_native_language_1','yrs_of_study_lang1',\n",
    "                                  'study_in_classroom_lang1','ways_of_study_lang1','non_native_language_2','study_in_classroom_lang2',\n",
    "                                  'ways_of_study_lang2','non_native_language_3','yrs_of_study_lang3','study_in_classroom_lang3',\n",
    "                                  'ways_of_study_lang3','yrs_of_english_learning','yrs_in_english_environment','yrs_of_study_lang2'])\n",
    "answer_=answer_df[['question_id','anon_id','course_id','version','text_len','text','tokens']].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>3Langs</th>\n",
       "      <th>Item</th>\n",
       "      <th>answer_id</th>\n",
       "      <th>anon_id</th>\n",
       "      <th>L1</th>\n",
       "      <th>gender</th>\n",
       "      <th>course_id</th>\n",
       "      <th>level_id</th>\n",
       "      <th>class_id</th>\n",
       "      <th>question_id</th>\n",
       "      <th>version</th>\n",
       "      <th>text1_len</th>\n",
       "      <th>text2_len</th>\n",
       "      <th>text3_len</th>\n",
       "      <th>text1</th>\n",
       "      <th>text2 (line breaks/extra spaces removed, spaces added to reach 60)</th>\n",
       "      <th>text3 (edits made to fix word counts)</th>\n",
       "      <th>Judgement</th>\n",
       "      <th>Notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Y</td>\n",
       "      <td>C12</td>\n",
       "      <td>141.0</td>\n",
       "      <td>aj8</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>Male</td>\n",
       "      <td>118.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>w</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>\\n\\n\\n Today, I am going to describe one of my...</td>\n",
       "      <td>Today, I am going to describe one of my classm...</td>\n",
       "      <td>Today, I am going to describe one of my classm...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Y</td>\n",
       "      <td>C13</td>\n",
       "      <td>143.0</td>\n",
       "      <td>az8</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>Female</td>\n",
       "      <td>118.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>w</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>My niece is 3 years old who is my younger brot...</td>\n",
       "      <td>My niece is 3 years old who is my younger brot...</td>\n",
       "      <td>My niece is 3 years old who is my younger brot...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Y</td>\n",
       "      <td>K9</td>\n",
       "      <td>133.0</td>\n",
       "      <td>az2</td>\n",
       "      <td>Korean</td>\n",
       "      <td>Male</td>\n",
       "      <td>118.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>w</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>When I was in Germany, I met a friend who was ...</td>\n",
       "      <td>When I was in Germany, I met a friend who was ...</td>\n",
       "      <td>When I was in Germany, I met a friend who was ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Y</td>\n",
       "      <td>K11</td>\n",
       "      <td>135.0</td>\n",
       "      <td>at8</td>\n",
       "      <td>Korean</td>\n",
       "      <td>Female</td>\n",
       "      <td>118.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>w</td>\n",
       "      <td>17.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>my friend is ANON_NAME_0. she is a my ELI frie...</td>\n",
       "      <td>my friend is ANON_NAME_0. she is a my ELI frie...</td>\n",
       "      <td>my friend is ANON_NAME_0. she is a my ELI frie...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Y</td>\n",
       "      <td>K20</td>\n",
       "      <td>188.0</td>\n",
       "      <td>eh9</td>\n",
       "      <td>Korean</td>\n",
       "      <td>Male</td>\n",
       "      <td>118.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>w</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>Younghun is my best friend. His facial appeara...</td>\n",
       "      <td>Younghun is my best friend. His facial appeara...</td>\n",
       "      <td>Younghun is my best friend. His facial appeara...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  3Langs Item  answer_id anon_id       L1  gender  course_id  level_id  \\\n",
       "0      Y  C12      141.0     aj8  Chinese    Male      118.0       5.0   \n",
       "1      Y  C13      143.0     az8  Chinese  Female      118.0       5.0   \n",
       "2      Y   K9      133.0     az2   Korean    Male      118.0       5.0   \n",
       "3      Y  K11      135.0     at8   Korean  Female      118.0       5.0   \n",
       "4      Y  K20      188.0     eh9   Korean    Male      118.0       5.0   \n",
       "\n",
       "  class_id  question_id  version  text1_len  text2_len  text3_len  \\\n",
       "0        w         17.0      1.0      121.0      114.0      114.0   \n",
       "1        w         17.0      1.0       96.0       95.0       95.0   \n",
       "2        w         17.0      1.0      130.0      128.0      128.0   \n",
       "3        w         17.0      3.0      104.0      105.0      105.0   \n",
       "4        w         17.0      1.0       98.0       97.0       97.0   \n",
       "\n",
       "                                               text1  \\\n",
       "0  \\n\\n\\n Today, I am going to describe one of my...   \n",
       "1  My niece is 3 years old who is my younger brot...   \n",
       "2  When I was in Germany, I met a friend who was ...   \n",
       "3  my friend is ANON_NAME_0. she is a my ELI frie...   \n",
       "4  Younghun is my best friend. His facial appeara...   \n",
       "\n",
       "  text2 (line breaks/extra spaces removed, spaces added to reach 60)  \\\n",
       "0  Today, I am going to describe one of my classm...                   \n",
       "1  My niece is 3 years old who is my younger brot...                   \n",
       "2  When I was in Germany, I met a friend who was ...                   \n",
       "3  my friend is ANON_NAME_0. she is a my ELI frie...                   \n",
       "4  Younghun is my best friend. His facial appeara...                   \n",
       "\n",
       "               text3 (edits made to fix word counts)  Judgement Notes  \n",
       "0  Today, I am going to describe one of my classm...        1.0   NaN  \n",
       "1  My niece is 3 years old who is my younger brot...        1.0   NaN  \n",
       "2  When I was in Germany, I met a friend who was ...        1.0   NaN  \n",
       "3  my friend is ANON_NAME_0. she is a my ELI frie...        1.0   NaN  \n",
       "4  Younghun is my best friend. His facial appeara...        1.0   NaN  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loose.head()\n",
    "#use text3 for word count?\n",
    "#use text3_len for number of tokes, but doesn't actually get the tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleaning the answer df\n",
    "col='course_id'\n",
    "answer=rmStr(answer_, col) #removes strings from answer_.course_id "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging the datasets\n",
    "\n",
    "merge_ans=answer[['anon_id','course_id']] #sets answer df up for merging \n",
    "student_merge=student.drop(columns=['course_history']) #set student df up for merging\n",
    "\n",
    "student_ans=student_merge.merge(answer,on='anon_id').astype({'course_id':'int64'}) #merges student and answers\n",
    "\n",
    "stu_ans_crs=student_ans.merge(course_, on='course_id') #merges the student-answers df with course df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anon_id</th>\n",
       "      <th>gender</th>\n",
       "      <th>native_language</th>\n",
       "      <th>age</th>\n",
       "      <th>answer_id</th>\n",
       "      <th>question_id</th>\n",
       "      <th>course_id</th>\n",
       "      <th>version</th>\n",
       "      <th>text_len</th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>level_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>do6</td>\n",
       "      <td>Female</td>\n",
       "      <td>Russian</td>\n",
       "      <td>31.0</td>\n",
       "      <td>150</td>\n",
       "      <td>4</td>\n",
       "      <td>117</td>\n",
       "      <td>1</td>\n",
       "      <td>299</td>\n",
       "      <td>Some people prefer eat out and some like doing...</td>\n",
       "      <td>['Some', 'people', 'prefer', 'eat', 'out', 'an...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>do6</td>\n",
       "      <td>Female</td>\n",
       "      <td>Russian</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1221</td>\n",
       "      <td>97</td>\n",
       "      <td>117</td>\n",
       "      <td>1</td>\n",
       "      <td>288</td>\n",
       "      <td>My opinion is that a person does need educatio...</td>\n",
       "      <td>['My', 'opinion', 'is', 'that', 'a', 'person',...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>do6</td>\n",
       "      <td>Female</td>\n",
       "      <td>Russian</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1957</td>\n",
       "      <td>189</td>\n",
       "      <td>117</td>\n",
       "      <td>1</td>\n",
       "      <td>321</td>\n",
       "      <td>There are two national rooms in the Cathedral ...</td>\n",
       "      <td>['There', 'are', 'two', 'national', 'rooms', '...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>do6</td>\n",
       "      <td>Female</td>\n",
       "      <td>Russian</td>\n",
       "      <td>31.0</td>\n",
       "      <td>2164</td>\n",
       "      <td>190</td>\n",
       "      <td>117</td>\n",
       "      <td>1</td>\n",
       "      <td>464</td>\n",
       "      <td>There are two nation rooms in the Cathedral of...</td>\n",
       "      <td>['There', 'are', 'two', 'nation', 'rooms', 'in...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bv5</td>\n",
       "      <td>Male</td>\n",
       "      <td>Arabic</td>\n",
       "      <td>21.0</td>\n",
       "      <td>151</td>\n",
       "      <td>4</td>\n",
       "      <td>117</td>\n",
       "      <td>1</td>\n",
       "      <td>315</td>\n",
       "      <td>\"Not all learning takes place in the classroom...</td>\n",
       "      <td>['``', 'Not', 'all', 'learning', 'takes', 'pla...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46225</th>\n",
       "      <td>cy7</td>\n",
       "      <td>Female</td>\n",
       "      <td>Korean</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47682</td>\n",
       "      <td>6066</td>\n",
       "      <td>1034</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1. emphasis\\n2. appropriate\\n3. requires\\n4. a...</td>\n",
       "      <td>['1', '.', 'emphasis', '2', '.', 'appropriate'...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46226</th>\n",
       "      <td>fp7</td>\n",
       "      <td>Female</td>\n",
       "      <td>Turkish</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47823</td>\n",
       "      <td>6066</td>\n",
       "      <td>1034</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1.emphasis \\n2.appropriate\\n3.requires\\n4.anal...</td>\n",
       "      <td>['1', '.', 'emphasis', '2', '.', 'appropriate'...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46227</th>\n",
       "      <td>fq6</td>\n",
       "      <td>Male</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47824</td>\n",
       "      <td>6066</td>\n",
       "      <td>1034</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1.emphasis\\n2.appropriate\\n3.requires\\n4.analy...</td>\n",
       "      <td>['1', '.', 'emphasis', '2', '.', 'appropriate'...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46228</th>\n",
       "      <td>di6</td>\n",
       "      <td>Male</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47787</td>\n",
       "      <td>6066</td>\n",
       "      <td>1034</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1 emphasis\\n2 normal\\n3 requires\\n4 analyze\\n5...</td>\n",
       "      <td>['1', 'emphasis', '2', 'normal', '3', 'require...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46229</th>\n",
       "      <td>fm3</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Arabic</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47725</td>\n",
       "      <td>6066</td>\n",
       "      <td>1034</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1- emphasis\\n2- appropriate\\n3- requires\\n4- a...</td>\n",
       "      <td>['1', '-', 'emphasis', '2', '-', 'appropriate'...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>46230 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      anon_id   gender native_language   age answer_id question_id  course_id  \\\n",
       "0         do6   Female         Russian  31.0       150           4        117   \n",
       "1         do6   Female         Russian  31.0      1221          97        117   \n",
       "2         do6   Female         Russian  31.0      1957         189        117   \n",
       "3         do6   Female         Russian  31.0      2164         190        117   \n",
       "4         bv5     Male          Arabic  21.0       151           4        117   \n",
       "...       ...      ...             ...   ...       ...         ...        ...   \n",
       "46225     cy7   Female          Korean   NaN     47682        6066       1034   \n",
       "46226     fp7   Female         Turkish   NaN     47823        6066       1034   \n",
       "46227     fq6     Male         Chinese   NaN     47824        6066       1034   \n",
       "46228     di6     Male         Chinese   NaN     47787        6066       1034   \n",
       "46229     fm3  Unknown          Arabic   NaN     47725        6066       1034   \n",
       "\n",
       "      version text_len                                               text  \\\n",
       "0           1      299  Some people prefer eat out and some like doing...   \n",
       "1           1      288  My opinion is that a person does need educatio...   \n",
       "2           1      321  There are two national rooms in the Cathedral ...   \n",
       "3           1      464  There are two nation rooms in the Cathedral of...   \n",
       "4           1      315  \"Not all learning takes place in the classroom...   \n",
       "...       ...      ...                                                ...   \n",
       "46225       1       10  1. emphasis\\n2. appropriate\\n3. requires\\n4. a...   \n",
       "46226       1       10  1.emphasis \\n2.appropriate\\n3.requires\\n4.anal...   \n",
       "46227       1       10  1.emphasis\\n2.appropriate\\n3.requires\\n4.analy...   \n",
       "46228       1       10  1 emphasis\\n2 normal\\n3 requires\\n4 analyze\\n5...   \n",
       "46229       1       10  1- emphasis\\n2- appropriate\\n3- requires\\n4- a...   \n",
       "\n",
       "                                                  tokens  level_id  \n",
       "0      ['Some', 'people', 'prefer', 'eat', 'out', 'an...         5  \n",
       "1      ['My', 'opinion', 'is', 'that', 'a', 'person',...         5  \n",
       "2      ['There', 'are', 'two', 'national', 'rooms', '...         5  \n",
       "3      ['There', 'are', 'two', 'nation', 'rooms', 'in...         5  \n",
       "4      ['``', 'Not', 'all', 'learning', 'takes', 'pla...         5  \n",
       "...                                                  ...       ...  \n",
       "46225  ['1', '.', 'emphasis', '2', '.', 'appropriate'...         3  \n",
       "46226  ['1', '.', 'emphasis', '2', '.', 'appropriate'...         3  \n",
       "46227  ['1', '.', 'emphasis', '2', '.', 'appropriate'...         3  \n",
       "46228  ['1', 'emphasis', '2', 'normal', '3', 'require...         3  \n",
       "46229  ['1', '-', 'emphasis', '2', '-', 'appropriate'...         3  \n",
       "\n",
       "[46230 rows x 12 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stu_ans_crs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokinizing Essays for Loose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reference code from previous research\n",
    "\n",
    "#function that does this\n",
    "def calculate_tokens(file):\n",
    "    essay = ''\n",
    "\n",
    "    with open(file, 'r') as f:\n",
    "        essay = f.read().lower()\n",
    "        \n",
    "    tokenizer = RegexpTokenizer(r'[0-9a-zA-Z_\\-]+')\n",
    "    tokenized = tokenizer.tokenize(essay)\n",
    "    unique = np.unique(tokenized)\n",
    "    \n",
    "    return {\n",
    "        'total': len(tokenized),\n",
    "        'unique': len(unique)\n",
    "    }\n",
    "\n",
    "\n",
    "# don't show this code to anyone else, i'm a bad boy\n",
    "directories = ['limited', 'loose', 'strictest']\n",
    "tokenize_results = { 'filename': [], 'total_tokens': [], 'unique_tokens': [] }\n",
    "\n",
    "for directory in directories:\n",
    "    for file in os.listdir(f'./data/in/{directory}'):\n",
    "        results = calculate_tokens(f'./data/in/{directory}/{file}')\n",
    "        tokenize_results['filename'].append(file)\n",
    "        tokenize_results['total_tokens'].append(results['total'])\n",
    "        tokenize_results['unique_tokens'].append(results['unique'])\n",
    "\n",
    "pd.DataFrame(data=tokenize_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
